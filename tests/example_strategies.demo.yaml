#####
##### Unit Tests for the Demonstration Language
#####

# Note: some demonstrations feature errors or failing tests.
# Some demonstrations also contain an additional `expect` section
# describing parts of the expected demonstration interpreter feedback.


##### Used for testing the UI

- strategy: make_sum
  args:
    allowed: [9, 6, 2]
    goal: 11
  tests:
    - run
  queries: []


##### Testing standalone query demos


- demonstration: MakeSum_demo
  query: MakeSum
  args:
    allowed: [9, 6, 2]
    goal: 11
  answers:
    - answer: "[9, 2]"
    - label: "wrong_sum"
      answer: "[9, 6]"

- demonstration: Unknown_query
  query: Unknown
  args: {}
  answers: []


##### Testing make_sum


- demonstration: make_sum_demo
  strategy: make_sum
  args:
    allowed: [9, 6, 2]
    goal: 11
  tests:
    - run | success
    - take '' | success  # same result as above but more fragile
    - run 'wrong_sum' | success  # error
    - run 'alt_order'
    - take cands{'alt_order'} | success
    - failure | run  # error
  queries:
    - query: MakeSum
      args:
        allowed: [9, 6, 2]
        goal: 11
      answers:
        - answer: "[9, 2]"
        - label: "wrong_sum"
          answer: "[9, 6]"
        - label: "alt_order"
          answer: "[2, 9]"
  expect:
    trace:
      nodes:
        1: {kind: Branch}
        2: {kind: Success}
        3: {kind: Fail}
        4: {kind: Success}
    test_feedback:
      - node_id: 2
        diagnostics: __empty__
      - node_id: 2
        diagnostics: __empty__
      - node_id: 3
        diagnostics:
          - ["error", "Success check failed."]
      - node_id: 4
        diagnostics: __empty__
      - node_id: 4
        diagnostics: __empty__
      - node_id: 1
        diagnostics:
          - ["error", "Failure check failed."]


- demonstration: make_sum_selectors
  strategy: make_sum
  args:
    allowed: [9, 6, 2]
    goal: 11
  tests:
    - run 'wrong_sum'
    - run 'unknown_hint'
  queries:
    - query: MakeSum
      args:
        allowed: [9, 6, 2]
        goal: 11
      answers:
        - answer: "[9, 2]"
        - label: "wrong_sum"
          answer: "[9, 6]"
  expect:
    trace:
      nodes:
        1: {kind: Branch}
        2: {kind: Fail}
        3: {kind: Success}
    test_feedback:
      - node_id: 2
      - node_id: 3
        diagnostics:
          - ["warning", "Unused hints: 'unknown_hint'."]


- demonstration: make_sum_at
  strategy: make_sum
  args:
    allowed: [9, 6, 2]
    goal: 11
  tests:
    - at Unknown
    - at MakeSum | run
  queries:
    - query: MakeSum
      args:
        allowed: [9, 6, 2]
        goal: 11
      answers:
        - answer: "[9, 2]"
        - label: "wrong_sum"
          answer: "[9, 6]"
  expect:
    trace:
      nodes:
        1: {kind: Branch}
        2: {kind: Success}
    test_feedback:
      - node_id: 2
        diagnostics:
          - ["warning", "Leaf node reached before 'Unknown'."]
      - diagnostics: __empty__


- demonstration: make_sum_stuck
  strategy: make_sum
  args:
    allowed: [9, 6, 2]
    goal: 11
  tests:
    - run
  queries: []
  expect:
    trace:
      nodes: {1: {kind: Branch}}
    test_feedback:
      - diagnostics: [["warning", "Test is stuck."]]
        node_id: 1


- demonstration: make_sum_test_parse_error
  strategy: make_sum
  args:
    allowed: [9, 6, 2]
    goal: 11
  tests:
    - bad_command
  queries: []
  expect:
    test_feedback:
      - diagnostics: [["error", "Syntax error."]]


- demonstration: trivial_strategy
  strategy: trivial_strategy
  args: {}
  tests: [run]
  queries: []
  expect: {trace: {nodes: {1: {kind: Success}}}}


- demonstration: buggy_strategy
  strategy: buggy_strategy
  args: {}
  tests: [run]
  queries: []
  expect:
    global_diagnostics:
      - ["error"]


- demonstration: strategy_not_found
  strategy: unknown_strategy
  args: {}
  tests: [run]
  queries: []
  expect:
    global_diagnostics:
      - ["error"]


- demonstration: invalid_arguments
  strategy: make_sum
  args:
    bad_arg: "foo"
  tests: [run]
  queries: []
  expect:
    global_diagnostics:
      - ["error"]


- demonstration: unknown_query
  strategy: make_sum
  args:
    allowed: [9, 6, 2]
    goal: 11
  tests:
    - run
  queries:
    - query: MakeSum
      args:
        allowed: [9, 6, 2]
        goal: 11
      answers: []
    - query: UnknownQuery
      args: {}
      answers: []
  expect:
    query_diagnostics:
      - [1, ["error"]]


- demonstration: invalid_answer
  strategy: make_sum
  args:
    allowed: [9, 6, 2]
    goal: 11
  tests:
    - run
  queries:
    - query: MakeSum
      args:
        allowed: [9, 6, 2]
        goal: 11
      answers:
        - answer: "'foo'"
  expect:
    answer_diagnostics:
      - [[0, 0], ["error"]]


##### Testing synthetize_fun


- demonstration: synthetize_fun_demo
  strategy: synthetize_fun
  args:
    vars: &vars_1 ["x", "y"]
    prop: &prop_1 [["a", "b"], "F(a, b) == F(b, a) and F(0, 1) == 2"]
  tests:
    - run | success
    - run 'invalid' | failure
    - at conjecture_expr | go disprove('wrong1') | save wrong1
    - load wrong1 | run | success
    - load wrong1 | run 'bad_cex' | failure
    - load wrong1 | run 'malformed_cex' | failure
    - at conjecture_expr | go aggregate(['', 'wrong1', 'wrong2'])
    - at conjecture_expr | go aggregate(['', 'unknown', 'wrong2'])
    - at conjecture_expr | answer aggregate(['wrong1', 'wrong2'])
    - at conjecture_expr | answer aggregate(['', 'wrong1', 'wrong2'])
  queries:
    - query: ConjectureExpr
      args: {vars: *vars_1, prop: *prop_1}
      answers:
        - label: right
          answer: "2*(x + y)"
        - label: wrong1
          answer: "x + 2*y"
        - label: wrong2
          answer: "2*y + x"
        - label: invalid
          answer: "sys.exit()"
    - query: ProposeCex
      args: {prop: *prop_1, fun: [[x, y], "x + 2*y"]}
      answers:
        - answer: "{a: 0, b: 1}"
        - label: malformed_cex
          answer: "{x: 1, y: 1}"
        - label: bad_cex
          answer: "{a: 0, b: 0}"
    - query: RemoveDuplicates
      args:
        exprs: ["2*(x + y)", "x + 2*y", "2*y + x"]
      answers:
        - answer: '["2*(x + y)", "x + 2*y"]'
  expect:
    test_feedback:
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics:
        - - "error"
          - "Not a nested tree: aggregate(['', 'wrong1', 'wrong2'])."
      - diagnostics:
        - - "warning"
          - "Unused hints: 'unknown'."
      - diagnostics:
        - - "error"
      - diagnostics: __empty__

    global_diagnostics: __empty__
    saved_nodes: {wrong1: __any__}


##### Testing pick_nice_boy_name


- demonstration: test_iterate
  strategy: pick_nice_boy_name
  args:
    names: ["Adeline", "Noah", "Julia", "Jonathan"]
  tests:
    - run | success
    - run 'girl_name' | failure
    - run 'other_boy_name' | failure
    - go cands | go next(nil)
    - go cands | go next(next(nil){'other_boy_name'}[1]) | run | success
    - go cands | go next(next(next(nil){'other_boy_name'}[1]){''}[1]) | run | failure
    # Valid selectors
    - at iterate
    - at pick_boy_name  # synonym because `iterate` uses `inherit_tags`
    - at iterate&pick_boy_name
    - at iterate/pick_boy_name/PickBoyName
    # Invalid selectors
    - at iterate/pick_boy_name  # `Iteration` node has no tags or primary space

    # Mistakenly send the wrong value to `next` by using index 0 instead of 1. The strategy raises
    # an exception because it explicitly checks the type of its arguments but without this
    # assertion, we would get stuck on a query with ill-typed arguments.
    - go cands | go next(next(nil){'other_boy_name'}[0]) | run | success
  queries:
    - query: PickBoyName
      args:
        names: [Adeline, Noah, Julia, Jonathan]
        picked_already: []
      answers:
      - answer: "Jonathan"
      - label: girl_name
        answer: "Julia"
      - label: other_boy_name
        answer: "Noah"
    - query: PickBoyName
      args:
        names: [Adeline, Noah, Julia, Jonathan]
        picked_already: [Noah]
      answers:
        - answer: "Jonathan"
    - query: PickBoyName
      args:
        names: [Adeline, Noah, Julia, Jonathan]
        picked_already: [Noah, Jonathan]
      answers:
        - answer: "Sigmund"
          
  expect:
    test_feedback:
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics:
          - - "warning"
      - diagnostics:
          - - "error"


##### Testing generate_pairs and advanced selectors

- demonstration: test_generate_pairs
  strategy: generate_pairs
  args: {}
  tests:
    - run | success
    - at PickPositiveInteger#1
    - at PickPositiveInteger#2
    - at PickPositiveInteger#3  # error
  queries:
    - query: PickPositiveInteger
      args: {prev: null}
      answers:
        - answer: "1"
    - query: PickPositiveInteger
      args: {prev: 1}
      answers:
        - answer: "2"
  expect:
    test_feedback:
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics:
          - - "warning"


##### Testing cached computations

- demonstration: comp_result_in_cache
  strategy: test_cached_computations
  args: {n: 2}
  tests:
    - run | success
  queries:
    - query: __Computation__
      args:
        fun: expensive_computation
        args: {n: 2}
      answers:
        - answer: "[2, 3]"
    - query: __Computation__
      args:
        fun: expensive_computation
        args: {n: 3}
      answers:
        - answer: "[3, 4]"
  expect:
    test_feedback:
      - diagnostics: __empty__

- demonstration: comp_result_outside_cache
  strategy: test_cached_computations
  args: {n: 2}
  tests:
    - run | success
  queries: []
  expect:
    test_feedback:
      - diagnostics: __empty__
    implicit_answers:
      computations:
        - query_name: __Computation__
          query_args: {fun: expensive_computation}
        - query_name: __Computation__
          query_args: {fun: expensive_computation}


- demonstration: structured_output
  query: StructuredOutput
  args:
    topic: "Music"
  answers:
    - answer:
        title: "Understanding Bach"
        authors: ["Brigitte Mouterde"]


- demonstration: tool_use
  strategy: propose_article
  args:
    user_name: Jonathan
  tests:
    - run | success
  queries:
    - query: ProposeArticle
      args:
        user_name: Jonathan
        prefix: []
      answers:
        - answer: ""
          call:
            - tool: GetUserFavoriteTopic
              args: {user_name: Jonathan}
    - query: ProposeArticle
      args:
        user_name: Jonathan
        prefix:
          - kind: oracle
            answer:
              mode: null
              content: ""
              tool_calls:
                - name: GetUserFavoriteTopic
                  args:
                    user_name: Jonathan
          - kind: tool
            call:
              name: GetUserFavoriteTopic
              args:
                user_name: Jonathan
            result: Soccer
      answers:
      - answer: ""
        call: [{tool: Article, args: {title: "All about Messi", authors: ["Raf"]}}]
  expect:
    test_feedback:
      - diagnostics: __empty__


- demonstration: flags
  strategy: pick_flag
  args: {}
  tests:
    - run | success
    - run '#alt' | success
    - run '#unk'
  queries: []
  expect:
    test_feedback:
      - diagnostics: __empty__
      - diagnostics: __empty__
      - diagnostics:
        - - "warning"


- demonstration: flags_global
  strategy: pick_flag
  args: {}
  tests:
    - run | success
  queries:
    - query: MethodFlag
      args: {}
      answers: [answer: alt]
  expect:
    test_feedback:
      - diagnostics: __empty__


- demonstration: abduction
  strategy: obtain_item
  args:
    market: &market
      - name: Joe
        asked_items: [apple, cherry]
        offered_item: banana
      - name: Eric
        asked_items: []
        offered_item: apple
      - name: Alice
        asked_items: []
        offered_item: cherry
    goal: banana
  tests:
    - run | success
  queries: 
    - query: ObtainItem
      args:
        market: *market
        possessed_items: []
        item: banana
      answers:
        - answer: {items: [apple, cherry]}
  expect:
    test_feedback:
      - diagnostics: __empty__


- demonstration: trivial_untyped_strategy
  strategy: trivial_untyped_strategy
  args:
    string: "hello"
    integer: 42
  tests:
    - run | success
  queries: []
  expect:
    test_feedback:
      - diagnostics: __empty__


- demonstration: make_sum_fetched_answers
  strategy: make_sum
  args:
    allowed: [9, 6, 2]
    goal: 11
  tests:
    - run | success
  using:
    - command: "commands/run_make_sum"
  queries: []
  expect:
    test_feedback:
      - diagnostics: __empty__


# In this demonstration, we use the hindsight feedback from a command 
# to reach a success node using only one answer.
- demonstration: using_hindsight_feedback
  strategy: get_magic_number
  args: {}
  tests:
    - run | success
  using:
    - command: "commands/run_get_magic_number"
      backprop_with: [shortcut]
  queries: []
  expect:
    test_feedback:
      - diagnostics: __empty__
    implicit_answers:
      fetched:
        - answer_content: "83"


# This is a variant of `using_hindsight_feedback`, where this time
# hindsight feedback is explicitly excluded.
- demonstration: without_hindsight_feedback
  strategy: get_magic_number
  args: {}
  tests:
    - run | success
  using:
    - command: "commands/run_get_magic_number"
  queries: []
  expect:  # two implicit answers are used this time
    test_feedback:
      - diagnostics: __empty__
    implicit_answers:
      fetched:
        - query_name: AskNumber
        - query_name: AskNumber


- demonstration: loading_data
  strategy: strategy_loading_data
  args: {key: "yang25"}
  tests:
    - run | success
  queries: []
  expect:  # two implicit answers are used this time
    test_feedback:
      - diagnostics: __empty__
    implicit_answers:
      data: []


- demonstration: loading_bad_data
  strategy: strategy_loading_data
  args: {key: "bazin23"}
  tests:
    - run | success
  queries: []
  expect:  # two implicit answers are used this time
    test_feedback:
      - diagnostics:
        - - "error"
    implicit_answers:
      data: []