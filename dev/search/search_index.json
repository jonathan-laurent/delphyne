{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started","text":"<p>Delphyne is a programming framework for building reliable and modular LLM applications. It is based on a new paradigm named oracular programming, where high-level problem-solving strategies are expressed as nondeterministic programs whose choice points are annotated with examples and resolved by LLMs. Delphyne combines three languages:</p> <ul> <li>A strategy language embedded in Python that allows writing nondeterministic programs that can be reified into (modular) search trees.</li> <li>A policy language for specifying ways to navigate such trees (with LLM guidance) by composing reusable search primitives.</li> <li>A demonstration language for describing successful and unsuccessful search scenarios to be used as training or prompting examples. A dedicated language server allows writing demonstrations interactively and keeping them synchronized with evolving strategies.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>First, download the Delphyne repository and enter it:</p> <pre><code>git clone git@github.com:jonathan-laurent/delphyne.git\ncd delphyne\n</code></pre> <p>Then, to install the Delphyne library in your current Python environment:</p> <pre><code>pip install -e .\n</code></pre> <p>Note that Python 3.12 (or more recent) is required. Once this is done, it should be possible to run <code>import delphyne</code> inside a Python interpreter. Next, you should build the Delphyne vscode extension. For this, assuming you have Node.js installed (version 22 or later), run:</p> <pre><code>cd vscode-ui\nnpm install\nnpx vsce package\n</code></pre> <p>The last command should create a <code>delphyne-xxx.vsix</code> extensions archive, which can be installed in vscode using the <code>Extensions: Install from VSIX</code> command (use <code>Ctrl+Shift+P</code> to search for this command).</p>"},{"location":"#testing-your-installation","title":"Testing your installation","text":"<p>To test your installation, open VSCode and set the <code>examples/find_invariants</code> folder as your workspace root. Click on the Delphyne logo on the Activity Bar to start the Delphyne extension, and open the demonstration file <code>abduct_and_branch.demo.yaml</code>. Then, open the command palette (<code>Ctrl+Shift+P</code>) and run the command <code>Delphyne: Evaluate All Demonstrations in File</code>. Diagnostics should then appear to indicate that all tests passed (but no warning or error). Note that adding new demonstrations requires installing <code>why3py</code>, as explained in the example's README.</p>"},{"location":"how-to-guides/","title":"How-To Guides","text":""},{"location":"how-to-guides/#creating-a-new-delphyne-project","title":"Creating a New Delphyne Project","text":""},{"location":"how-to-guides/#running-an-oracular-program","title":"Running an Oracular Program","text":""},{"location":"how-to-guides/#debugging-an-oracular-program","title":"Debugging an Oracular Program","text":""},{"location":"how-to-guides/#defining-a-new-effect","title":"Defining a New Effect","text":""},{"location":"how-to-guides/#defining-a-new-policy","title":"Defining a New Policy","text":""},{"location":"how-to-guides/#writing-a-conversational-agent","title":"Writing a Conversational Agent","text":""},{"location":"how-to-guides/#performing-expensive-or-non-replicable-computations-in-strategies","title":"Performing Expensive Or Non-Replicable Computations in Strategies","text":""},{"location":"dev/test-markdown/","title":"MkDocs Tricks","text":"<p>Use <code>!!!</code> to introduce admonitions and <code>???</code> for collapsible admonitions (<code>???+</code> for collapsible but expanded by default). Supported kinds include: <code>note</code>, <code>abstract</code>, <code>info</code>, <code>tip</code>, <code>success</code>, <code>question</code>, <code>warning</code>, <code>failure</code>, <code>danger</code>, <code>bug</code>, <code>example</code>, <code>quote</code>.</p> <p>You need to learn stuff</p> <p>Here is an example.</p> You can expand this <pre><code>def fun(x):\n    return x + 1\n</code></pre> <p>I can display some code:</p> <pre><code>@strategy(dfs)\ndef my_strategy(spec): # (1)!\n    prog = yield from branch(AskProg(spec))\n</code></pre> <ol> <li>I am not using any return type here.</li> </ol> <p>I can show some math: \\[ \\int_0^1 F \\varphi(u) du. \\]</p> <p>I can display keyboard keys: Ctrl+Shift+Del or Ctrl+. or Cmd+..</p> <p>I can also include some snippets:</p> <pre><code>\"\"\"\nTypes for representing LLM chat histories.\n\"\"\"\n\nfrom collections.abc import Sequence\nfrom dataclasses import dataclass\nfrom typing import Any, Literal\n\nfrom delphyne.core.refs import Answer, Structured, ToolCall\n\n\n@dataclass(frozen=True)\nclass OracleMessage:\n    \"\"\"\n    Messge containing an oracle answer.\n    \"\"\"\n\n    kind: Literal[\"oracle\"]\n    answer: Answer\n\n\n@dataclass(frozen=True)\nclass FeedbackMessage:\n    \"\"\"\n    Message containing user feedback.\n    \"\"\"\n\n    kind: Literal[\"feedback\"]\n    category: str | None = None\n    description: str | None = None\n    arg: Any | None = None  # must be serializable\n\n\n@dataclass(frozen=True)\nclass ToolResult:\n    \"\"\"\n    User message containing the result of a tool call previously\n    initiated by an LLM.\n    \"\"\"\n\n    kind: Literal[\"tool\"]\n    call: ToolCall\n    result: str | Structured\n\n\ntype AnswerPrefixElement = OracleMessage | FeedbackMessage | ToolResult\n\"\"\"\nLLM chat history element.\n\"\"\"\n\n\ntype AnswerPrefix = Sequence[AnswerPrefixElement]\n\"\"\"\nAn LLM chat history, to be passed to a query as an answer prefix (see\n`Query.query_prefix`).\n\"\"\"\n</code></pre> <p>Content tabs:</p> CC++ <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre>"},{"location":"dev/test-mkdocs/","title":"Testing MkDocs","text":""},{"location":"dev/test-mkdocs/#resources-on-writing-good-docstrings","title":"Resources on Writing Good Docstrings","text":"<ul> <li>Pydantic Example</li> </ul>"},{"location":"dev/test-mkdocs/#tricks","title":"Tricks","text":"<ul> <li>In docstrings, both <code>[`AttachedQuery`][delphyne.core.AttachedQuery]</code> and <code>[delphyne.core.AttachedQuery][]</code> will work but the former is better style.</li> <li>The <code>\"rewrap.autoWrap.enabled\": true</code> option is pretty good for what I want to do. Also, always select before rewrapping and we should be good.</li> <li>Start documenting each field in uppercase.</li> </ul>"},{"location":"dev/test-mkdocs/#api-documentation-for-query","title":"API Documentation for Query","text":"<p>The <code>Query</code> class is the base class for all queries in Delphyne, providing convenient features and automatic type inference. Does it work to have partial paths (<code>Query</code>)?</p>"},{"location":"dev/test-mkdocs/#documenting-type-aliases","title":"Documenting Type Aliases","text":""},{"location":"dev/test-mkdocs/#delphyne.Stream","title":"Stream  <code>dataclass</code>","text":"<p>               Bases: <code>AbstractStream[Stream[T]]</code></p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>@dataclass(frozen=True)\nclass Stream[T](dp.AbstractStream[T]):\n    _generate: Callable[[], dp.StreamGen[T]]\n\n    def gen(self) -&gt; dp.StreamGen[T]:\n        return self._generate()\n\n    ## Collecting all elements\n\n    def collect(\n        self,\n        budget: dp.BudgetLimit | None = None,\n        num_generated: int | None = None,\n    ) -&gt; tuple[Sequence[dp.Solution[T]], dp.Budget]:\n        if budget is not None:\n            self = self.with_budget(budget)\n        if num_generated is not None:\n            self = self.take(num_generated)\n        return stream_collect(self.gen())\n\n    ## Transforming the stream\n\n    def with_budget(self, budget: dp.BudgetLimit):\n        return Stream(lambda: stream_with_budget(self.gen(), budget))\n\n    def take(self, num_generated: int, strict: bool = True):\n        return Stream(lambda: stream_take(self.gen(), num_generated, strict))\n\n    def loop(\n        self, n: int | None = None, *, stop_on_reject: bool = True\n    ) -&gt; \"Stream[T]\":\n        it = itertools.count() if n is None else range(n)\n        return Stream(\n            lambda: stream_sequence(\n                (self.gen for _ in it), stop_on_reject=stop_on_reject\n            )\n        )\n\n    def bind[T2](\n        self, f: Callable[[dp.Solution[T]], dp.StreamGen[T2]]\n    ) -&gt; \"Stream[T2]\":\n        return Stream(lambda: stream_bind(self.gen(), f))\n\n    ## Monadic Methods\n\n    def first(self) -&gt; dp.StreamContext[dp.Solution[T] | None]:\n        return stream_take_one(self.gen())\n\n    def all(self) -&gt; dp.StreamContext[Sequence[dp.Solution[T]]]:\n        return stream_take_all(self.gen())\n\n    def next(\n        self,\n    ) -&gt; dp.StreamContext[\n        \"tuple[Sequence[dp.Solution[T]], dp.Budget, Stream[T] | None]\"\n    ]:\n        gen, budg, rest = yield from stream_next(self.gen())\n        new_rest = None if rest is None else Stream(lambda: rest)\n        return gen, budg, new_rest\n\n    ## Static Methods\n\n    @staticmethod\n    def sequence[U](\n        streams: Iterable[\"Stream[U]\"], *, stop_on_reject: bool = True\n    ) -&gt; \"Stream[U]\":\n        return Stream(\n            lambda: stream_sequence(\n                (s.gen for s in streams), stop_on_reject=stop_on_reject\n            )\n        )\n\n    @staticmethod\n    def parallel[U](streams: Sequence[\"Stream[U]\"]) -&gt; \"Stream[U]\":\n        return Stream(lambda: stream_parallel([s.gen() for s in streams]))\n</code></pre>"},{"location":"dev/test-mkdocs/#delphyne.AnswerPrefix","title":"AnswerPrefix","text":"<pre><code>AnswerPrefix: Sequence[AnswerPrefixElement]\n</code></pre> <p>An LLM chat history, to be passed to a query as an answer prefix (see <code>Query.query_prefix</code>).</p>"},{"location":"dev/test-mkdocs/#delphyne.Tag","title":"Tag","text":"<pre><code>Tag: str\n</code></pre> <p>String tags for nodes and spaces.</p> <p>Nodes and spaces can be assigned string identifiers, which may be referenced in demonstration tests or when defining inner policies (e.g., <code>IPDict</code>). Tags should contain only alphanumeric characters, underscores, dots, and dashes.</p>"},{"location":"dev/test-mkdocs/#delphyne.IPDict","title":"IPDict","text":"<pre><code>IPDict: Mapping[str, Policy[Any, Any] | PromptingPolicy]\n</code></pre> <p>Type of an Inner-Policy Dictionary.</p> <p>Inner-Policy dictionaries allow to define strategies in a more concise way in exchange for less static type safety.</p> <p>Normally, an inner policy type must be defined for every strategy, and opaque spaces are created from queries or strategy by passing the <code>using</code> method a mapping from the ambient inner policy to a proper sub-policy, often in the form of an anonymous function:</p> <pre><code>@dataclass class MyInnerPolicy:\n    foo: PromptingPolicy # etc\n\ndef my_strategy() -&gt; Strategy[Branch, MyInnerPolicy, str]:\n    x = yield from branch(Foo().using(lambda p: p.foo)) # etc\n</code></pre> <p>As an alternative, one can have a strategy use an inner policy dictionary, by passing ellipses (<code>...</code>) to the <code>using</code> method:</p> <pre><code>def my_strategy() -&gt; Strategy[Branch, IPDict, str]:\n    x = yield from branch(Foo().using(...)) # etc\n</code></pre> <p>When doing so, a simple Python dictionary can be used as an inner policy, whose keys are space tags (the same tags can be referenced in demonstration tests). In the example above, and since a spaces induced by a query inherits its name as a tag by default, one can define an inner policy for <code>my_strategy</code> as:</p> <pre><code>{\"Foo\": foo_prompting_policy, ...}\n</code></pre> <p>A conjunction of tags can also be specified, separated by <code>&amp;</code> (without spaces). For example, <code>{\"tag1&amp;tag2\": pp, ...}</code> associates prompting policies <code>pp</code> to spaces with both tags <code>tag1</code> and <code>tag2</code>. New tags can be added to a space builder using the <code>SpaceBuilder.tagged</code> method.</p> <p>Info</p> <p>If several entries of the inner policy dictionary apply for a given instance of <code>.using(...)</code>, a runtime error is raised.</p> <p>See <code>tests/example_strategies:generate_number</code> for another example.</p>"},{"location":"dev/test-mkdocs/#documenting-a-class","title":"Documenting a Class","text":""},{"location":"dev/test-mkdocs/#delphyne.Query","title":"Query","text":"<p>               Bases: <code>AbstractQuery[Query[T]]</code></p> <p>Base class for queries.</p> <p>This class adds standard convenience features on top of [<code>AbstractQuery</code>][delphyne.AbstractQuery], using reflection to allow queries to be defined with maximal concision.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>class Query[T](dp.AbstractQuery[T]):\n    \"\"\"\n    Base class for queries.\n\n    This class adds standard convenience features on top of\n    `AbstractQuery`, using reflection to allow queries to be defined\n    with maximal concision.\n    \"\"\"\n\n    __modes__: ClassVar[Sequence[dp.AnswerMode] | None] = None\n    __parser__: ClassVar[ParserSpec | ParserSpecDict | None] = None\n    __config__: ClassVar[QueryConfig | QueryConfigDict | None] = None\n\n    ### Inspection methods\n\n    def query_config(self, mode: dp.AnswerMode) -&gt; QueryConfig | None:\n        \"\"\"\n        By default, we obtain the configuration by looking for a\n        `__config__` field, which might be either a single configuration\n        or a dictionary mapping modes to configurations. Instead, if\n        only the parser is specified, we can use `__parser__`.\n        \"\"\"\n        cls = type(self)\n        parse_overriden = dpi.is_method_overridden(Query, cls, \"parse\")\n        if parse_overriden:\n            assert cls.__config__ is None\n            assert cls.__parser__ is None\n            return None\n        if cls.__config__ is not None:\n            assert self.__parser__ is None, (\n                \"Cannot have both __config__ and __parser__ attributes.\"\n            )\n            config_attr = cls.__config__\n            if isinstance(config_attr, QueryConfig):\n                return config_attr\n            else:\n                assert isinstance(config_attr, Mapping)\n                return cast(Any, config_attr)[mode]\n        elif cls.__parser__ is not None:\n            parser_attr: Any = cls.__parser__\n            if isinstance(parser_attr, Mapping):\n                parser = cast(Any, parser_attr)[mode]\n            else:\n                parser = parser_attr\n            _check_valid_parser_spec(parser)\n            return QueryConfig(parser)\n        else:\n            return QueryConfig(\"structured\")\n\n    @classmethod\n    def _decomposed_answer_type(cls) -&gt; _DecomposedAnswerType:\n        return _DecomposedAnswerType(cls._answer_type())\n\n    ### Parsing Answers\n\n    @override\n    def parse_answer(self, answer: dp.Answer) -&gt; T | dp.ParseError:\n        assert answer.mode in self.query_modes()\n        try:\n            return self.parse(answer)\n        except dp.ParseError as e:\n            return e\n\n    def parse(self, answer: Answer) -&gt; T:\n        \"\"\"\n        A more convenient method to override instead of `parse_answer`.\n\n        Raises dp.ParseError\n        \"\"\"\n\n        # Decompose the specified answer type\n        config = self.query_config(answer.mode)\n        assert config is not None\n        attr = config.parser\n        ans_type = self._decomposed_answer_type()\n\n        # Compute base parsing function `parser`\n        parser: _ParsingFunction[Any]\n        if attr == \"structured\":\n            parser = _from_structured(ans_type.to_parse)\n        elif attr == \"final_tool_call\":\n            assert isinstance(ans_type.to_parse, type)\n            parser = _from_final_tool_call(cast(type[Any], ans_type.to_parse))\n        else:\n            assert callable(attr)\n            attr = cast(Callable[..., Any], attr)\n            sig = inspect.signature(attr)\n            nargs = len(sig.parameters)\n            assert nargs == 1 or nargs == 2\n            if nargs == 1:\n                parser = _from_text_parser(attr)\n            else:\n                parser = _from_generic_text_parser(attr, ans_type.to_parse)\n\n        if ans_type.wrap_parse_errors():\n            parser = _wrap_parse_errors(parser)\n\n        # If the answer type has form `Response[..., ...]`\n        if ans_type.resp:\n            if _has_final_tool_call(ans_type, answer):\n                tcs = []\n            else:\n                tcs = [\n                    _parse_tool_call(ans_type.resp.tools, tc)\n                    for tc in answer.tool_calls\n                ]\n            if tcs:\n                return cast(T, Response(answer, ToolRequests(tcs)))\n            else:\n                return cast(T, Response(answer, FinalAnswer(parser(answer))))\n\n        return parser(answer)\n\n    ### Query Settings\n\n    @override\n    def query_settings(self, mode: dp.AnswerMode) -&gt; dp.QuerySettings:\n        config = self.query_config(mode)\n        assert config is not None\n        structured_output = None\n        if config.parser == \"structured\":\n            type = self._decomposed_answer_type().final\n            structured_output = dp.StructuredOutputSettings(type)\n        tools = None\n        if tool_types := self._query_tools(config.parser):\n            tools = dp.ToolSettings(\n                tool_types, force_tool_call=config.parser == \"final_tool_call\"\n            )\n        return dp.QuerySettings(\n            structured_output=structured_output,\n            tools=tools,\n        )\n\n    def _structured_output_type(self) -&gt; TypeAnnot[Any] | ty.NoTypeInfo:\n        decomposed = self._decomposed_answer_type()\n        return decomposed.final\n\n    def _query_tools(self, parser: ParserSpec) -&gt; Sequence[type[Any]]:\n        ans_type = self._decomposed_answer_type()\n        tools: list[type[Any]] = []\n        if ans_type.resp is not None:\n            tools = [*ans_type.resp.tools]\n        if parser == \"final_tool_call\":\n            assert isinstance(ans_type.final, type)\n            tools.append(ans_type.final)\n        return tools\n\n    ### Query Prefixes\n\n    @classmethod\n    def _has_special_prefix_attr(cls):\n        annots = typing.get_type_hints(cls)\n        return \"prefix\" in annots and annots[\"prefix\"] is ct.AnswerPrefix\n\n    @override\n    def query_prefix(self) -&gt; ct.AnswerPrefix | None:\n        \"\"\"\n        Return the value of the `prefix` attribute if it has type\n        annotation `AnswerPrefix` or return `None`.\n        \"\"\"\n        if self._has_special_prefix_attr():\n            return getattr(self, \"prefix\")\n        return None\n\n    ### Producing Prompts\n\n    @override\n    def generate_prompt(\n        self,\n        *,\n        kind: Literal[\"system\", \"instance\"] | str,\n        mode: dp.AnswerMode,\n        params: dict[str, object],\n        extra_args: dict[str, object] | None = None,\n        env: dp.TemplatesManager | None = None,\n    ) -&gt; str:\n        assert env is not None, _no_prompt_manager_error()\n        args: dict[str, object] = {\n            \"query\": self,\n            \"mode\": mode,\n            \"params\": params,\n        }\n        if extra_args:\n            args.update(extra_args)\n        if (glob := self.globals()) is not None:\n            args[\"globals\"] = glob\n        return env.prompt(\n            query_name=self.query_name(),\n            prompt_kind=kind,\n            template_args=args,\n            default_template=self._default_prompt(kind),\n        )\n\n    @classmethod\n    def _default_prompt(\n        cls, kind: Literal[\"system\", \"instance\"] | str\n    ) -&gt; str | None:\n        attr_name = f\"__{kind}_prompt__\"\n        if hasattr(cls, attr_name):\n            res = getattr(cls, attr_name)\n            assert isinstance(res, str)\n            return textwrap.dedent(res).strip()\n        if kind == \"instance\":\n            if cls._has_special_prefix_attr():\n                return \"{{query | yaml(exclude_fields=['prefix']) | trim}}\"\n            else:\n                return \"{{query | yaml | trim}}\"\n        if kind == \"system\" and (doc := inspect.getdoc(cls)) is not None:\n            return doc\n        if kind == \"feedback\":\n            return DEFAULT_FEEDBACK_PROMPT\n        return None\n\n    def globals(self) -&gt; dict[str, object] | None:\n        return None\n\n    ### Other Simple Overrides\n\n    @override\n    def serialize_args(self) -&gt; dict[str, object]:\n        return cast(dict[str, object], ty.pydantic_dump(type(self), self))\n\n    @classmethod\n    def _answer_type(cls) -&gt; TypeAnnot[T]:\n        return dpi.first_parameter_of_base_class(cls)\n\n    @override\n    def answer_type(self) -&gt; TypeAnnot[T]:\n        return self._answer_type()\n\n    @override\n    def finite_answer_set(self) -&gt; Sequence[dp.Answer] | None:\n        # We handle the special case where the return type is a literal\n        # type that is a subtype of str.\n        ans = self.answer_type()\n        if (res := _match_string_literal_type(ans)) is not None:\n            return [dp.Answer(None, v) for v in res]\n        return None\n\n    @override\n    def query_modes(self) -&gt; Sequence[dp.AnswerMode]:\n        if self.__modes__ is not None:\n            return self.__modes__\n        return [None]\n\n    ### Generating Opaque Spaces\n\n    @overload\n    def using(self, get_policy: EllipsisType, /) -&gt; Opaque[IPDict, T]: ...\n\n    @overload\n    def using[P2](\n        self,\n        get_policy: Callable[[P2], pol.PromptingPolicy] | EllipsisType,\n        /,\n        inner_policy_type: type[P2] | None = None,\n    ) -&gt; Opaque[P2, T]: ...\n\n    def using[P](\n        self,\n        get_policy: Callable[[P], pol.PromptingPolicy] | EllipsisType,\n        /,\n        inner_policy_type: type[P] | None = None,\n    ) -&gt; Opaque[P, T]:\n        \"\"\"\n        Turn a strategy instance into an opaque space by providing a\n        mapping from the ambient inner policy to a prompting policy.\n\n        The optional `inner_policy_type` argument is ignored at runtime\n        and can be used to help type checkers infer the type of the\n        ambient inner policy.\n        \"\"\"\n        if isinstance(get_policy, EllipsisType):\n            return OpaqueSpace[P, T].from_query(\n                self, cast(Any, pol.dict_subpolicy)\n            )\n        return OpaqueSpace[P, T].from_query(self, lambda p, _: get_policy(p))\n\n    def run_toplevel(\n        self,\n        env: dp.PolicyEnv,\n        policy: pol.PromptingPolicy,\n    ) -&gt; Stream[T]:\n        attached = dp.spawn_standalone_query(self)\n        return policy(attached, env)\n</code></pre>"},{"location":"dev/test-mkdocs/#delphyne.Query.parse","title":"parse","text":"<pre><code>parse(answer: Answer) -&gt; Query[T]\n</code></pre> <p>A more convenient method to override instead of <code>parse_answer</code>.</p> <p>Raises dp.ParseError</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def parse(self, answer: Answer) -&gt; T:\n    \"\"\"\n    A more convenient method to override instead of `parse_answer`.\n\n    Raises dp.ParseError\n    \"\"\"\n\n    # Decompose the specified answer type\n    config = self.query_config(answer.mode)\n    assert config is not None\n    attr = config.parser\n    ans_type = self._decomposed_answer_type()\n\n    # Compute base parsing function `parser`\n    parser: _ParsingFunction[Any]\n    if attr == \"structured\":\n        parser = _from_structured(ans_type.to_parse)\n    elif attr == \"final_tool_call\":\n        assert isinstance(ans_type.to_parse, type)\n        parser = _from_final_tool_call(cast(type[Any], ans_type.to_parse))\n    else:\n        assert callable(attr)\n        attr = cast(Callable[..., Any], attr)\n        sig = inspect.signature(attr)\n        nargs = len(sig.parameters)\n        assert nargs == 1 or nargs == 2\n        if nargs == 1:\n            parser = _from_text_parser(attr)\n        else:\n            parser = _from_generic_text_parser(attr, ans_type.to_parse)\n\n    if ans_type.wrap_parse_errors():\n        parser = _wrap_parse_errors(parser)\n\n    # If the answer type has form `Response[..., ...]`\n    if ans_type.resp:\n        if _has_final_tool_call(ans_type, answer):\n            tcs = []\n        else:\n            tcs = [\n                _parse_tool_call(ans_type.resp.tools, tc)\n                for tc in answer.tool_calls\n            ]\n        if tcs:\n            return cast(T, Response(answer, ToolRequests(tcs)))\n        else:\n            return cast(T, Response(answer, FinalAnswer(parser(answer))))\n\n    return parser(answer)\n</code></pre>"},{"location":"dev/test-mkdocs/#delphyne.Query.query_config","title":"query_config","text":"<pre><code>query_config(mode: AnswerMode) -&gt; QueryConfig | None\n</code></pre> <p>By default, we obtain the configuration by looking for a <code>__config__</code> field, which might be either a single configuration or a dictionary mapping modes to configurations. Instead, if only the parser is specified, we can use <code>__parser__</code>.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def query_config(self, mode: dp.AnswerMode) -&gt; QueryConfig | None:\n    \"\"\"\n    By default, we obtain the configuration by looking for a\n    `__config__` field, which might be either a single configuration\n    or a dictionary mapping modes to configurations. Instead, if\n    only the parser is specified, we can use `__parser__`.\n    \"\"\"\n    cls = type(self)\n    parse_overriden = dpi.is_method_overridden(Query, cls, \"parse\")\n    if parse_overriden:\n        assert cls.__config__ is None\n        assert cls.__parser__ is None\n        return None\n    if cls.__config__ is not None:\n        assert self.__parser__ is None, (\n            \"Cannot have both __config__ and __parser__ attributes.\"\n        )\n        config_attr = cls.__config__\n        if isinstance(config_attr, QueryConfig):\n            return config_attr\n        else:\n            assert isinstance(config_attr, Mapping)\n            return cast(Any, config_attr)[mode]\n    elif cls.__parser__ is not None:\n        parser_attr: Any = cls.__parser__\n        if isinstance(parser_attr, Mapping):\n            parser = cast(Any, parser_attr)[mode]\n        else:\n            parser = parser_attr\n        _check_valid_parser_spec(parser)\n        return QueryConfig(parser)\n    else:\n        return QueryConfig(\"structured\")\n</code></pre>"},{"location":"dev/test-mkdocs/#delphyne.Query.query_prefix","title":"query_prefix","text":"<pre><code>query_prefix() -&gt; AnswerPrefix | None\n</code></pre> <p>Return the value of the <code>prefix</code> attribute if it has type annotation <code>AnswerPrefix</code> or return <code>None</code>.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@override\ndef query_prefix(self) -&gt; ct.AnswerPrefix | None:\n    \"\"\"\n    Return the value of the `prefix` attribute if it has type\n    annotation `AnswerPrefix` or return `None`.\n    \"\"\"\n    if self._has_special_prefix_attr():\n        return getattr(self, \"prefix\")\n    return None\n</code></pre>"},{"location":"dev/test-mkdocs/#delphyne.Query.using","title":"using","text":"<pre><code>using(get_policy: EllipsisType) -&gt; Opaque[IPDict, Query[T]]\n</code></pre><pre><code>using(get_policy: Callable[[P2], PromptingPolicy] | EllipsisType, /, inner_policy_type: type[P2] | None = None) -&gt; Opaque[P2, Query[T]]\n</code></pre> <pre><code>using(get_policy: Callable[[using[P]], PromptingPolicy] | EllipsisType, /, inner_policy_type: type[using[P]] | None = None) -&gt; Opaque[using[P], Query[T]]\n</code></pre> <p>Turn a strategy instance into an opaque space by providing a mapping from the ambient inner policy to a prompting policy.</p> <p>The optional <code>inner_policy_type</code> argument is ignored at runtime and can be used to help type checkers infer the type of the ambient inner policy.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def using[P](\n    self,\n    get_policy: Callable[[P], pol.PromptingPolicy] | EllipsisType,\n    /,\n    inner_policy_type: type[P] | None = None,\n) -&gt; Opaque[P, T]:\n    \"\"\"\n    Turn a strategy instance into an opaque space by providing a\n    mapping from the ambient inner policy to a prompting policy.\n\n    The optional `inner_policy_type` argument is ignored at runtime\n    and can be used to help type checkers infer the type of the\n    ambient inner policy.\n    \"\"\"\n    if isinstance(get_policy, EllipsisType):\n        return OpaqueSpace[P, T].from_query(\n            self, cast(Any, pol.dict_subpolicy)\n        )\n    return OpaqueSpace[P, T].from_query(self, lambda p, _: get_policy(p))\n</code></pre>"},{"location":"dev/test-mkdocs/#documenting-a-class-without-members","title":"Documenting a Class without Members","text":""},{"location":"dev/test-mkdocs/#delphyne.Query","title":"Query","text":"<p>               Bases: <code>AbstractQuery[Query[T]]</code></p> <p>Base class for queries.</p> <p>This class adds standard convenience features on top of [<code>AbstractQuery</code>][delphyne.AbstractQuery], using reflection to allow queries to be defined with maximal concision.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>class Query[T](dp.AbstractQuery[T]):\n    \"\"\"\n    Base class for queries.\n\n    This class adds standard convenience features on top of\n    `AbstractQuery`, using reflection to allow queries to be defined\n    with maximal concision.\n    \"\"\"\n\n    __modes__: ClassVar[Sequence[dp.AnswerMode] | None] = None\n    __parser__: ClassVar[ParserSpec | ParserSpecDict | None] = None\n    __config__: ClassVar[QueryConfig | QueryConfigDict | None] = None\n\n    ### Inspection methods\n\n    def query_config(self, mode: dp.AnswerMode) -&gt; QueryConfig | None:\n        \"\"\"\n        By default, we obtain the configuration by looking for a\n        `__config__` field, which might be either a single configuration\n        or a dictionary mapping modes to configurations. Instead, if\n        only the parser is specified, we can use `__parser__`.\n        \"\"\"\n        cls = type(self)\n        parse_overriden = dpi.is_method_overridden(Query, cls, \"parse\")\n        if parse_overriden:\n            assert cls.__config__ is None\n            assert cls.__parser__ is None\n            return None\n        if cls.__config__ is not None:\n            assert self.__parser__ is None, (\n                \"Cannot have both __config__ and __parser__ attributes.\"\n            )\n            config_attr = cls.__config__\n            if isinstance(config_attr, QueryConfig):\n                return config_attr\n            else:\n                assert isinstance(config_attr, Mapping)\n                return cast(Any, config_attr)[mode]\n        elif cls.__parser__ is not None:\n            parser_attr: Any = cls.__parser__\n            if isinstance(parser_attr, Mapping):\n                parser = cast(Any, parser_attr)[mode]\n            else:\n                parser = parser_attr\n            _check_valid_parser_spec(parser)\n            return QueryConfig(parser)\n        else:\n            return QueryConfig(\"structured\")\n\n    @classmethod\n    def _decomposed_answer_type(cls) -&gt; _DecomposedAnswerType:\n        return _DecomposedAnswerType(cls._answer_type())\n\n    ### Parsing Answers\n\n    @override\n    def parse_answer(self, answer: dp.Answer) -&gt; T | dp.ParseError:\n        assert answer.mode in self.query_modes()\n        try:\n            return self.parse(answer)\n        except dp.ParseError as e:\n            return e\n\n    def parse(self, answer: Answer) -&gt; T:\n        \"\"\"\n        A more convenient method to override instead of `parse_answer`.\n\n        Raises dp.ParseError\n        \"\"\"\n\n        # Decompose the specified answer type\n        config = self.query_config(answer.mode)\n        assert config is not None\n        attr = config.parser\n        ans_type = self._decomposed_answer_type()\n\n        # Compute base parsing function `parser`\n        parser: _ParsingFunction[Any]\n        if attr == \"structured\":\n            parser = _from_structured(ans_type.to_parse)\n        elif attr == \"final_tool_call\":\n            assert isinstance(ans_type.to_parse, type)\n            parser = _from_final_tool_call(cast(type[Any], ans_type.to_parse))\n        else:\n            assert callable(attr)\n            attr = cast(Callable[..., Any], attr)\n            sig = inspect.signature(attr)\n            nargs = len(sig.parameters)\n            assert nargs == 1 or nargs == 2\n            if nargs == 1:\n                parser = _from_text_parser(attr)\n            else:\n                parser = _from_generic_text_parser(attr, ans_type.to_parse)\n\n        if ans_type.wrap_parse_errors():\n            parser = _wrap_parse_errors(parser)\n\n        # If the answer type has form `Response[..., ...]`\n        if ans_type.resp:\n            if _has_final_tool_call(ans_type, answer):\n                tcs = []\n            else:\n                tcs = [\n                    _parse_tool_call(ans_type.resp.tools, tc)\n                    for tc in answer.tool_calls\n                ]\n            if tcs:\n                return cast(T, Response(answer, ToolRequests(tcs)))\n            else:\n                return cast(T, Response(answer, FinalAnswer(parser(answer))))\n\n        return parser(answer)\n\n    ### Query Settings\n\n    @override\n    def query_settings(self, mode: dp.AnswerMode) -&gt; dp.QuerySettings:\n        config = self.query_config(mode)\n        assert config is not None\n        structured_output = None\n        if config.parser == \"structured\":\n            type = self._decomposed_answer_type().final\n            structured_output = dp.StructuredOutputSettings(type)\n        tools = None\n        if tool_types := self._query_tools(config.parser):\n            tools = dp.ToolSettings(\n                tool_types, force_tool_call=config.parser == \"final_tool_call\"\n            )\n        return dp.QuerySettings(\n            structured_output=structured_output,\n            tools=tools,\n        )\n\n    def _structured_output_type(self) -&gt; TypeAnnot[Any] | ty.NoTypeInfo:\n        decomposed = self._decomposed_answer_type()\n        return decomposed.final\n\n    def _query_tools(self, parser: ParserSpec) -&gt; Sequence[type[Any]]:\n        ans_type = self._decomposed_answer_type()\n        tools: list[type[Any]] = []\n        if ans_type.resp is not None:\n            tools = [*ans_type.resp.tools]\n        if parser == \"final_tool_call\":\n            assert isinstance(ans_type.final, type)\n            tools.append(ans_type.final)\n        return tools\n\n    ### Query Prefixes\n\n    @classmethod\n    def _has_special_prefix_attr(cls):\n        annots = typing.get_type_hints(cls)\n        return \"prefix\" in annots and annots[\"prefix\"] is ct.AnswerPrefix\n\n    @override\n    def query_prefix(self) -&gt; ct.AnswerPrefix | None:\n        \"\"\"\n        Return the value of the `prefix` attribute if it has type\n        annotation `AnswerPrefix` or return `None`.\n        \"\"\"\n        if self._has_special_prefix_attr():\n            return getattr(self, \"prefix\")\n        return None\n\n    ### Producing Prompts\n\n    @override\n    def generate_prompt(\n        self,\n        *,\n        kind: Literal[\"system\", \"instance\"] | str,\n        mode: dp.AnswerMode,\n        params: dict[str, object],\n        extra_args: dict[str, object] | None = None,\n        env: dp.TemplatesManager | None = None,\n    ) -&gt; str:\n        assert env is not None, _no_prompt_manager_error()\n        args: dict[str, object] = {\n            \"query\": self,\n            \"mode\": mode,\n            \"params\": params,\n        }\n        if extra_args:\n            args.update(extra_args)\n        if (glob := self.globals()) is not None:\n            args[\"globals\"] = glob\n        return env.prompt(\n            query_name=self.query_name(),\n            prompt_kind=kind,\n            template_args=args,\n            default_template=self._default_prompt(kind),\n        )\n\n    @classmethod\n    def _default_prompt(\n        cls, kind: Literal[\"system\", \"instance\"] | str\n    ) -&gt; str | None:\n        attr_name = f\"__{kind}_prompt__\"\n        if hasattr(cls, attr_name):\n            res = getattr(cls, attr_name)\n            assert isinstance(res, str)\n            return textwrap.dedent(res).strip()\n        if kind == \"instance\":\n            if cls._has_special_prefix_attr():\n                return \"{{query | yaml(exclude_fields=['prefix']) | trim}}\"\n            else:\n                return \"{{query | yaml | trim}}\"\n        if kind == \"system\" and (doc := inspect.getdoc(cls)) is not None:\n            return doc\n        if kind == \"feedback\":\n            return DEFAULT_FEEDBACK_PROMPT\n        return None\n\n    def globals(self) -&gt; dict[str, object] | None:\n        return None\n\n    ### Other Simple Overrides\n\n    @override\n    def serialize_args(self) -&gt; dict[str, object]:\n        return cast(dict[str, object], ty.pydantic_dump(type(self), self))\n\n    @classmethod\n    def _answer_type(cls) -&gt; TypeAnnot[T]:\n        return dpi.first_parameter_of_base_class(cls)\n\n    @override\n    def answer_type(self) -&gt; TypeAnnot[T]:\n        return self._answer_type()\n\n    @override\n    def finite_answer_set(self) -&gt; Sequence[dp.Answer] | None:\n        # We handle the special case where the return type is a literal\n        # type that is a subtype of str.\n        ans = self.answer_type()\n        if (res := _match_string_literal_type(ans)) is not None:\n            return [dp.Answer(None, v) for v in res]\n        return None\n\n    @override\n    def query_modes(self) -&gt; Sequence[dp.AnswerMode]:\n        if self.__modes__ is not None:\n            return self.__modes__\n        return [None]\n\n    ### Generating Opaque Spaces\n\n    @overload\n    def using(self, get_policy: EllipsisType, /) -&gt; Opaque[IPDict, T]: ...\n\n    @overload\n    def using[P2](\n        self,\n        get_policy: Callable[[P2], pol.PromptingPolicy] | EllipsisType,\n        /,\n        inner_policy_type: type[P2] | None = None,\n    ) -&gt; Opaque[P2, T]: ...\n\n    def using[P](\n        self,\n        get_policy: Callable[[P], pol.PromptingPolicy] | EllipsisType,\n        /,\n        inner_policy_type: type[P] | None = None,\n    ) -&gt; Opaque[P, T]:\n        \"\"\"\n        Turn a strategy instance into an opaque space by providing a\n        mapping from the ambient inner policy to a prompting policy.\n\n        The optional `inner_policy_type` argument is ignored at runtime\n        and can be used to help type checkers infer the type of the\n        ambient inner policy.\n        \"\"\"\n        if isinstance(get_policy, EllipsisType):\n            return OpaqueSpace[P, T].from_query(\n                self, cast(Any, pol.dict_subpolicy)\n            )\n        return OpaqueSpace[P, T].from_query(self, lambda p, _: get_policy(p))\n\n    def run_toplevel(\n        self,\n        env: dp.PolicyEnv,\n        policy: pol.PromptingPolicy,\n    ) -&gt; Stream[T]:\n        attached = dp.spawn_standalone_query(self)\n        return policy(attached, env)\n</code></pre>"},{"location":"dev/test-mkdocs/#documenting-a-class-with-selected-members","title":"Documenting a Class With Selected Members","text":""},{"location":"dev/test-mkdocs/#delphyne.Query","title":"Query","text":"<p>               Bases: <code>AbstractQuery[Query[T]]</code></p> <p>Base class for queries.</p> <p>This class adds standard convenience features on top of [<code>AbstractQuery</code>][delphyne.AbstractQuery], using reflection to allow queries to be defined with maximal concision.</p> <p>Methods:</p> Name Description <code>parse_answer</code> <code>query_config</code> <p>By default, we obtain the configuration by looking for a</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>class Query[T](dp.AbstractQuery[T]):\n    \"\"\"\n    Base class for queries.\n\n    This class adds standard convenience features on top of\n    `AbstractQuery`, using reflection to allow queries to be defined\n    with maximal concision.\n    \"\"\"\n\n    __modes__: ClassVar[Sequence[dp.AnswerMode] | None] = None\n    __parser__: ClassVar[ParserSpec | ParserSpecDict | None] = None\n    __config__: ClassVar[QueryConfig | QueryConfigDict | None] = None\n\n    ### Inspection methods\n\n    def query_config(self, mode: dp.AnswerMode) -&gt; QueryConfig | None:\n        \"\"\"\n        By default, we obtain the configuration by looking for a\n        `__config__` field, which might be either a single configuration\n        or a dictionary mapping modes to configurations. Instead, if\n        only the parser is specified, we can use `__parser__`.\n        \"\"\"\n        cls = type(self)\n        parse_overriden = dpi.is_method_overridden(Query, cls, \"parse\")\n        if parse_overriden:\n            assert cls.__config__ is None\n            assert cls.__parser__ is None\n            return None\n        if cls.__config__ is not None:\n            assert self.__parser__ is None, (\n                \"Cannot have both __config__ and __parser__ attributes.\"\n            )\n            config_attr = cls.__config__\n            if isinstance(config_attr, QueryConfig):\n                return config_attr\n            else:\n                assert isinstance(config_attr, Mapping)\n                return cast(Any, config_attr)[mode]\n        elif cls.__parser__ is not None:\n            parser_attr: Any = cls.__parser__\n            if isinstance(parser_attr, Mapping):\n                parser = cast(Any, parser_attr)[mode]\n            else:\n                parser = parser_attr\n            _check_valid_parser_spec(parser)\n            return QueryConfig(parser)\n        else:\n            return QueryConfig(\"structured\")\n\n    @classmethod\n    def _decomposed_answer_type(cls) -&gt; _DecomposedAnswerType:\n        return _DecomposedAnswerType(cls._answer_type())\n\n    ### Parsing Answers\n\n    @override\n    def parse_answer(self, answer: dp.Answer) -&gt; T | dp.ParseError:\n        assert answer.mode in self.query_modes()\n        try:\n            return self.parse(answer)\n        except dp.ParseError as e:\n            return e\n\n    def parse(self, answer: Answer) -&gt; T:\n        \"\"\"\n        A more convenient method to override instead of `parse_answer`.\n\n        Raises dp.ParseError\n        \"\"\"\n\n        # Decompose the specified answer type\n        config = self.query_config(answer.mode)\n        assert config is not None\n        attr = config.parser\n        ans_type = self._decomposed_answer_type()\n\n        # Compute base parsing function `parser`\n        parser: _ParsingFunction[Any]\n        if attr == \"structured\":\n            parser = _from_structured(ans_type.to_parse)\n        elif attr == \"final_tool_call\":\n            assert isinstance(ans_type.to_parse, type)\n            parser = _from_final_tool_call(cast(type[Any], ans_type.to_parse))\n        else:\n            assert callable(attr)\n            attr = cast(Callable[..., Any], attr)\n            sig = inspect.signature(attr)\n            nargs = len(sig.parameters)\n            assert nargs == 1 or nargs == 2\n            if nargs == 1:\n                parser = _from_text_parser(attr)\n            else:\n                parser = _from_generic_text_parser(attr, ans_type.to_parse)\n\n        if ans_type.wrap_parse_errors():\n            parser = _wrap_parse_errors(parser)\n\n        # If the answer type has form `Response[..., ...]`\n        if ans_type.resp:\n            if _has_final_tool_call(ans_type, answer):\n                tcs = []\n            else:\n                tcs = [\n                    _parse_tool_call(ans_type.resp.tools, tc)\n                    for tc in answer.tool_calls\n                ]\n            if tcs:\n                return cast(T, Response(answer, ToolRequests(tcs)))\n            else:\n                return cast(T, Response(answer, FinalAnswer(parser(answer))))\n\n        return parser(answer)\n\n    ### Query Settings\n\n    @override\n    def query_settings(self, mode: dp.AnswerMode) -&gt; dp.QuerySettings:\n        config = self.query_config(mode)\n        assert config is not None\n        structured_output = None\n        if config.parser == \"structured\":\n            type = self._decomposed_answer_type().final\n            structured_output = dp.StructuredOutputSettings(type)\n        tools = None\n        if tool_types := self._query_tools(config.parser):\n            tools = dp.ToolSettings(\n                tool_types, force_tool_call=config.parser == \"final_tool_call\"\n            )\n        return dp.QuerySettings(\n            structured_output=structured_output,\n            tools=tools,\n        )\n\n    def _structured_output_type(self) -&gt; TypeAnnot[Any] | ty.NoTypeInfo:\n        decomposed = self._decomposed_answer_type()\n        return decomposed.final\n\n    def _query_tools(self, parser: ParserSpec) -&gt; Sequence[type[Any]]:\n        ans_type = self._decomposed_answer_type()\n        tools: list[type[Any]] = []\n        if ans_type.resp is not None:\n            tools = [*ans_type.resp.tools]\n        if parser == \"final_tool_call\":\n            assert isinstance(ans_type.final, type)\n            tools.append(ans_type.final)\n        return tools\n\n    ### Query Prefixes\n\n    @classmethod\n    def _has_special_prefix_attr(cls):\n        annots = typing.get_type_hints(cls)\n        return \"prefix\" in annots and annots[\"prefix\"] is ct.AnswerPrefix\n\n    @override\n    def query_prefix(self) -&gt; ct.AnswerPrefix | None:\n        \"\"\"\n        Return the value of the `prefix` attribute if it has type\n        annotation `AnswerPrefix` or return `None`.\n        \"\"\"\n        if self._has_special_prefix_attr():\n            return getattr(self, \"prefix\")\n        return None\n\n    ### Producing Prompts\n\n    @override\n    def generate_prompt(\n        self,\n        *,\n        kind: Literal[\"system\", \"instance\"] | str,\n        mode: dp.AnswerMode,\n        params: dict[str, object],\n        extra_args: dict[str, object] | None = None,\n        env: dp.TemplatesManager | None = None,\n    ) -&gt; str:\n        assert env is not None, _no_prompt_manager_error()\n        args: dict[str, object] = {\n            \"query\": self,\n            \"mode\": mode,\n            \"params\": params,\n        }\n        if extra_args:\n            args.update(extra_args)\n        if (glob := self.globals()) is not None:\n            args[\"globals\"] = glob\n        return env.prompt(\n            query_name=self.query_name(),\n            prompt_kind=kind,\n            template_args=args,\n            default_template=self._default_prompt(kind),\n        )\n\n    @classmethod\n    def _default_prompt(\n        cls, kind: Literal[\"system\", \"instance\"] | str\n    ) -&gt; str | None:\n        attr_name = f\"__{kind}_prompt__\"\n        if hasattr(cls, attr_name):\n            res = getattr(cls, attr_name)\n            assert isinstance(res, str)\n            return textwrap.dedent(res).strip()\n        if kind == \"instance\":\n            if cls._has_special_prefix_attr():\n                return \"{{query | yaml(exclude_fields=['prefix']) | trim}}\"\n            else:\n                return \"{{query | yaml | trim}}\"\n        if kind == \"system\" and (doc := inspect.getdoc(cls)) is not None:\n            return doc\n        if kind == \"feedback\":\n            return DEFAULT_FEEDBACK_PROMPT\n        return None\n\n    def globals(self) -&gt; dict[str, object] | None:\n        return None\n\n    ### Other Simple Overrides\n\n    @override\n    def serialize_args(self) -&gt; dict[str, object]:\n        return cast(dict[str, object], ty.pydantic_dump(type(self), self))\n\n    @classmethod\n    def _answer_type(cls) -&gt; TypeAnnot[T]:\n        return dpi.first_parameter_of_base_class(cls)\n\n    @override\n    def answer_type(self) -&gt; TypeAnnot[T]:\n        return self._answer_type()\n\n    @override\n    def finite_answer_set(self) -&gt; Sequence[dp.Answer] | None:\n        # We handle the special case where the return type is a literal\n        # type that is a subtype of str.\n        ans = self.answer_type()\n        if (res := _match_string_literal_type(ans)) is not None:\n            return [dp.Answer(None, v) for v in res]\n        return None\n\n    @override\n    def query_modes(self) -&gt; Sequence[dp.AnswerMode]:\n        if self.__modes__ is not None:\n            return self.__modes__\n        return [None]\n\n    ### Generating Opaque Spaces\n\n    @overload\n    def using(self, get_policy: EllipsisType, /) -&gt; Opaque[IPDict, T]: ...\n\n    @overload\n    def using[P2](\n        self,\n        get_policy: Callable[[P2], pol.PromptingPolicy] | EllipsisType,\n        /,\n        inner_policy_type: type[P2] | None = None,\n    ) -&gt; Opaque[P2, T]: ...\n\n    def using[P](\n        self,\n        get_policy: Callable[[P], pol.PromptingPolicy] | EllipsisType,\n        /,\n        inner_policy_type: type[P] | None = None,\n    ) -&gt; Opaque[P, T]:\n        \"\"\"\n        Turn a strategy instance into an opaque space by providing a\n        mapping from the ambient inner policy to a prompting policy.\n\n        The optional `inner_policy_type` argument is ignored at runtime\n        and can be used to help type checkers infer the type of the\n        ambient inner policy.\n        \"\"\"\n        if isinstance(get_policy, EllipsisType):\n            return OpaqueSpace[P, T].from_query(\n                self, cast(Any, pol.dict_subpolicy)\n            )\n        return OpaqueSpace[P, T].from_query(self, lambda p, _: get_policy(p))\n\n    def run_toplevel(\n        self,\n        env: dp.PolicyEnv,\n        policy: pol.PromptingPolicy,\n    ) -&gt; Stream[T]:\n        attached = dp.spawn_standalone_query(self)\n        return policy(attached, env)\n</code></pre>"},{"location":"dev/test-mkdocs/#delphyne.Query.parse_answer","title":"parse_answer","text":"<pre><code>parse_answer(answer: Answer) -&gt; Query[T] | ParseError\n</code></pre> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@override\ndef parse_answer(self, answer: dp.Answer) -&gt; T | dp.ParseError:\n    assert answer.mode in self.query_modes()\n    try:\n        return self.parse(answer)\n    except dp.ParseError as e:\n        return e\n</code></pre>"},{"location":"dev/test-mkdocs/#delphyne.Query.query_config","title":"query_config","text":"<pre><code>query_config(mode: AnswerMode) -&gt; QueryConfig | None\n</code></pre> <p>By default, we obtain the configuration by looking for a <code>__config__</code> field, which might be either a single configuration or a dictionary mapping modes to configurations. Instead, if only the parser is specified, we can use <code>__parser__</code>.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def query_config(self, mode: dp.AnswerMode) -&gt; QueryConfig | None:\n    \"\"\"\n    By default, we obtain the configuration by looking for a\n    `__config__` field, which might be either a single configuration\n    or a dictionary mapping modes to configurations. Instead, if\n    only the parser is specified, we can use `__parser__`.\n    \"\"\"\n    cls = type(self)\n    parse_overriden = dpi.is_method_overridden(Query, cls, \"parse\")\n    if parse_overriden:\n        assert cls.__config__ is None\n        assert cls.__parser__ is None\n        return None\n    if cls.__config__ is not None:\n        assert self.__parser__ is None, (\n            \"Cannot have both __config__ and __parser__ attributes.\"\n        )\n        config_attr = cls.__config__\n        if isinstance(config_attr, QueryConfig):\n            return config_attr\n        else:\n            assert isinstance(config_attr, Mapping)\n            return cast(Any, config_attr)[mode]\n    elif cls.__parser__ is not None:\n        parser_attr: Any = cls.__parser__\n        if isinstance(parser_attr, Mapping):\n            parser = cast(Any, parser_attr)[mode]\n        else:\n            parser = parser_attr\n        _check_valid_parser_spec(parser)\n        return QueryConfig(parser)\n    else:\n        return QueryConfig(\"structured\")\n</code></pre>"},{"location":"dev/test-mkdocs/#documenting-a-dataclass","title":"Documenting a Dataclass","text":""},{"location":"dev/test-mkdocs/#delphyne.core.AttachedQuery","title":"AttachedQuery  <code>dataclass</code>","text":"<p>Wrapper for a query attached to a specific space.</p> <p>Attributes:</p> Name Type Description <code>query</code> <code>AbstractQuery[AttachedQuery[T]]</code> <p>The wrapped query.</p> <code>ref</code> <code>GlobalSpacePath</code> <p>A global reference to the space to which the query is attached.</p> <code>parse_answer</code> <code>Callable[[Answer], Tracked[AttachedQuery[T]] | ParseError]</code> <p>A wrapper around <code>self.query.parse_answer</code>, which attaches proper tracking information to answers.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass(frozen=True)\nclass AttachedQuery[T]:\n    \"\"\"\n    Wrapper for a query attached to a specific space.\n\n    Attributes:\n        query: The wrapped query.\n        ref: A global reference to the space to which the query is\n            attached.\n        parse_answer: A wrapper around `self.query.parse_answer`,\n            which attaches proper tracking information to answers.\n    \"\"\"\n\n    query: AbstractQuery[T]\n    ref: refs.GlobalSpacePath\n    parse_answer: Callable[[refs.Answer], Tracked[T] | ParseError]\n</code></pre>"},{"location":"dev/test-mkdocs/#documenting-a-function","title":"Documenting a Function","text":"<p>The standard few-shot prompting sequential prompting policy.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>AttachedQuery[few_shot[T]]</code> <p>The query to answer.</p> required <code>env</code> <code>PolicyEnv</code> <p>The policy environment.</p> required <p>If <code>iterative_mode</code> is <code>False</code>, then the prompt is always the same and different answers are sampled. If <code>iterative_mode</code> is <code>True</code>, everything happens within a single big chat. Every parse error leads to some feedback while every correctly parsed answer leads to a message inviting the system to generate another different solution.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@prompting_policy\ndef few_shot[T](\n    query: dp.AttachedQuery[T],\n    env: dp.PolicyEnv,\n    model: md.LLM,\n    params: dict[str, object] | None = None,\n    select_examples: Sequence[ExampleSelector] = (),\n    mode: dp.AnswerMode = None,\n    enable_logging: bool = True,\n    temperature: float | None = None,\n    num_concurrent: int = 1,\n    iterative_mode: bool = False,\n    max_requests: int | None = None,\n    no_wrap_parse_errors: bool = False,\n) -&gt; dp.StreamGen[T]:\n    \"\"\"\n    The standard few-shot prompting sequential prompting policy.\n\n    Arguments:\n        query: The query to answer.\n        env: The policy environment.\n\n    If `iterative_mode` is `False`, then the prompt is always the same\n    and different answers are sampled. If `iterative_mode` is `True`,\n    everything happens within a single big chat. Every parse error leads\n    to some feedback while every correctly parsed answer leads to a\n    message inviting the system to generate another different solution.\n\n    \"\"\"\n    assert not iterative_mode or num_concurrent == 1\n    assert max_requests is None or max_requests &gt; 0\n    env.tracer.trace_query(query.ref)\n    examples = fetch_examples(env.examples, query.query, select_examples)\n    mngr = env.templates\n    if params is None:\n        params = {}\n    prompt = create_prompt(query.query, examples, params, mode, mngr)\n    settings = query.query.query_settings(mode)\n    options: md.RequestOptions = {}\n    if temperature is not None:\n        options[\"temperature\"] = temperature\n    structured_output = None\n    if settings.structured_output is not None:\n        out_type = settings.structured_output.type\n        structured_output = md.Schema.make(out_type)\n    tools = []\n    if settings.tools is not None:\n        if settings.tools.force_tool_call:\n            options[\"tool_choice\"] = \"required\"\n        tools = [md.Schema.make(t) for t in settings.tools.tool_types]\n    num_reqs = 0\n    while max_requests is None or num_reqs &lt; max_requests:\n        num_reqs += 1\n        req = md.LLMRequest(\n            prompt,\n            num_completions=num_concurrent,\n            options=options,\n            tools=tools,\n            structured_output=structured_output,\n        )\n        resp = yield from _send_request(model, req, env)\n        if isinstance(resp, SpendingDeclined):\n            return\n        log_oracle_response(env, query, req, resp, verbose=enable_logging)\n        if not resp.outputs:\n            log(env, \"llm_no_output\", loc=query)\n            continue\n        elements: list[dp.Tracked[T] | dp.ParseError] = []\n        answers: list[dp.Answer] = []\n        for output in resp.outputs:\n            answer = dp.Answer(mode, output.content, tuple(output.tool_calls))\n            answers.append(answer)\n            element = query.parse_answer(answer)\n            if no_wrap_parse_errors:\n                element = _unwrap_parse_error(element)\n            env.tracer.trace_answer(query.ref, answer)\n            if isinstance(element, dp.ParseError):\n                log(env, \"parse_error\", {\"error\": element}, loc=query)\n            elements.append(element)\n        for element in elements:\n            if not isinstance(element, dp.ParseError):\n                yield dp.Solution(element)\n        # In iterative mode, we want to keep the conversation going\n        if iterative_mode:\n            assert len(elements) == 1 and len(answers) == 1\n            element = elements[0]\n            if isinstance(element, dp.ParseError):\n                try:\n                    repair = query.query.generate_prompt(\n                        kind=REPAIR_PROMPT,\n                        mode=mode,\n                        params={\"params\": params, \"error\": element},\n                        env=mngr,\n                    )\n                except dp.TemplateFileMissing:\n                    repair = (\n                        \"Invalid answer. Please consider the following\"\n                        + f\" feedback and try again:\\n\\n{element}\"\n                    )\n                new_message = md.UserMessage(repair)\n            else:\n                try:\n                    gen_new = query.query.generate_prompt(\n                        kind=REQUEST_OTHER_PROMPT,\n                        mode=mode,\n                        params={\"params\": params},\n                        env=mngr,\n                    )\n                except dp.TemplateFileMissing:\n                    gen_new = \"Good! Can you generate a different answer now?\"\n                new_message = md.UserMessage(gen_new)\n\n            prompt = (*prompt, md.AssistantMessage(answers[0]), new_message)\n</code></pre>"},{"location":"dev/test-mkdocs/#documenting-a-whole-module","title":"Documenting a whole module","text":""},{"location":"dev/test-mkdocs/#delphyne.stdlib.queries","title":"queries","text":"<p>Standard queries and building blocks for prompting policies.</p>"},{"location":"dev/test-mkdocs/#delphyne.stdlib.queries.ProbInfo","title":"ProbInfo  <code>dataclass</code>","text":"<p>               Bases: <code>SearchMeta</code></p> <p>Distribution probability, guaranteed to be nonempty and to sum to 1.</p>"},{"location":"dev/test-mkdocs/#delphyne.stdlib.queries.Query","title":"Query","text":"<p>               Bases: <code>AbstractQuery[Query[T]]</code></p> <p>Base class for queries.</p> <p>This class adds standard convenience features on top of [<code>AbstractQuery</code>][delphyne.AbstractQuery], using reflection to allow queries to be defined with maximal concision.</p>"},{"location":"dev/test-mkdocs/#delphyne.stdlib.queries.Query.parse","title":"parse","text":"<pre><code>parse(answer: Answer) -&gt; Query[T]\n</code></pre> <p>A more convenient method to override instead of <code>parse_answer</code>.</p> <p>Raises dp.ParseError</p>"},{"location":"dev/test-mkdocs/#delphyne.stdlib.queries.Query.query_config","title":"query_config","text":"<pre><code>query_config(mode: AnswerMode) -&gt; QueryConfig | None\n</code></pre> <p>By default, we obtain the configuration by looking for a <code>__config__</code> field, which might be either a single configuration or a dictionary mapping modes to configurations. Instead, if only the parser is specified, we can use <code>__parser__</code>.</p>"},{"location":"dev/test-mkdocs/#delphyne.stdlib.queries.Query.query_prefix","title":"query_prefix","text":"<pre><code>query_prefix() -&gt; AnswerPrefix | None\n</code></pre> <p>Return the value of the <code>prefix</code> attribute if it has type annotation <code>AnswerPrefix</code> or return <code>None</code>.</p>"},{"location":"dev/test-mkdocs/#delphyne.stdlib.queries.Query.using","title":"using","text":"<pre><code>using(get_policy: EllipsisType) -&gt; Opaque[IPDict, Query[T]]\n</code></pre><pre><code>using(get_policy: Callable[[P2], PromptingPolicy] | EllipsisType, /, inner_policy_type: type[P2] | None = None) -&gt; Opaque[P2, Query[T]]\n</code></pre> <pre><code>using(get_policy: Callable[[using[P]], PromptingPolicy] | EllipsisType, /, inner_policy_type: type[using[P]] | None = None) -&gt; Opaque[using[P], Query[T]]\n</code></pre> <p>Turn a strategy instance into an opaque space by providing a mapping from the ambient inner policy to a prompting policy.</p> <p>The optional <code>inner_policy_type</code> argument is ignored at runtime and can be used to help type checkers infer the type of the ambient inner policy.</p>"},{"location":"dev/test-mkdocs/#delphyne.stdlib.queries.Response","title":"Response  <code>dataclass</code>","text":"<p>Answer type for queries that allow follow-ups, giving access to both the raw LLM response (to be passed pass in <code>AnswerPrefix</code>) and to tool eventual tool calls.</p>"},{"location":"dev/test-mkdocs/#delphyne.stdlib.queries.classify","title":"classify","text":"<pre><code>classify(query: AttachedQuery[classify[T]], env: PolicyEnv, model: LLM, params: dict[str, object] | None = None, select_examples: Sequence[ExampleSelector] = (), mode: AnswerMode = None, enable_logging: bool = True, top_logprobs: int = 20, temperature: float = 1.0, bias: tuple[str, float] | None = None) -&gt; StreamGen[classify[T]]\n</code></pre> <p>Execute a classification query, attaching a probability distribution to the attached answer.</p> <p>When <code>bias=(e, p)</code> is provided, then the final distribution <code>D</code> is transformed into <code>(1-p)*D + p*dirac(e)</code></p>"},{"location":"dev/test-mkdocs/#delphyne.stdlib.queries.few_shot","title":"few_shot","text":"<pre><code>few_shot(query: AttachedQuery[few_shot[T]], env: PolicyEnv, model: LLM, params: dict[str, object] | None = None, select_examples: Sequence[ExampleSelector] = (), mode: AnswerMode = None, enable_logging: bool = True, temperature: float | None = None, num_concurrent: int = 1, iterative_mode: bool = False, max_requests: int | None = None, no_wrap_parse_errors: bool = False) -&gt; StreamGen[few_shot[T]]\n</code></pre> <p>The standard few-shot prompting sequential prompting policy.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>AttachedQuery[few_shot[T]]</code> <p>The query to answer.</p> required <code>env</code> <code>PolicyEnv</code> <p>The policy environment.</p> required <p>If <code>iterative_mode</code> is <code>False</code>, then the prompt is always the same and different answers are sampled. If <code>iterative_mode</code> is <code>True</code>, everything happens within a single big chat. Every parse error leads to some feedback while every correctly parsed answer leads to a message inviting the system to generate another different solution.</p>"},{"location":"dev/test-mkdocs/#delphyne.stdlib.queries.first_word","title":"first_word","text":"<pre><code>first_word(type: TypeAnnot[first_word[T]], res: str) -&gt; first_word[T]\n</code></pre> <p>Parse the first word of the answer and turn it into an object of type T=Literal[s1,...,sn]</p>"},{"location":"manual/demos/","title":"Demonstrations","text":"<p>This page is under construction. In the meantime, you can read about Delphyne's key concepts in the paper Oracular Programming: A Modular Foundation for Building LLM-Enabled Software.</p>"},{"location":"manual/extension/","title":"VSCode Extension","text":"<p>A Visual Studio Code extension is available for interactively writing demonstrations, navigating strategy trees, and running oracular programs.</p> <p> </p>"},{"location":"manual/extension/#setting-up-the-extension","title":"Setting up the extension","text":"<p>After installing the Delphyne extension and opening a workspace containing a Delphyne project (whose root features a <code>delphyne.yaml</code> file), you can start the Delphyne extension by clicking on the Delphyne icon on the VSCode activity bar. Doing so will spawn a Delphyne language server if one is not running already. You can confirm that the language server is running by looking at the <code>Delphyne</code> output channel (from the <code>Output</code> tab in the panel). See the Troubleshooting section if you encounter any problem.</p> <p>Locating the language server</p> <p>The Delphyne extension uses the Python distribution currently selected for the workspace by Pylance to launch the language server. If no such distribution is configured, you can set it via the <code>Python: Select Interpreter</code> command and then restart VSCode.</p> <p>Once this is done, you can open a demonstration file and start evaluating demonstrations.</p>"},{"location":"manual/extension/#recommended-editor-configuration","title":"Recommended Editor Configuration","text":"<p>For the best experience, we recommend also installing the following VSCode extensions:</p> <ul> <li>YAML Language Support</li> <li>Better Jinja</li> </ul> <p>In addition, for optimal readability of demonstration files, line wrapping should be activated for YAML files. We recommend doing the same for Jinja files. Finally, we recommend associating the <code>*.jinja</code> extension with the <code>jinja-md</code> file format. See below for the recommended JSON configuration, which you can copy to your VSCode settings.</p> .vscode/settings.json <pre><code>\"[yaml]\": {\n    \"editor.wrappingIndent\": \"indent\",\n    \"editor.wordWrap\": \"wordWrapColumn\",\n    \"editor.indentSize\": 2,\n    \"editor.wordWrapColumn\": 100,\n    \"editor.rulers\": [100],\n},\n// Wrap template files for readability.\n\"[jinja-md]\": {\n    \"editor.wrappingIndent\": \"indent\",\n    \"editor.wordWrap\": \"wordWrapColumn\",\n    \"editor.wordWrapColumn\": 80,\n    \"editor.indentSize\": 2,\n    \"editor.rulers\": [80],\n},\n// Indicate that the Jinja templates are written in Markdown\n\"files.associations\": {\n    \"*.jinja\": \"jinja-md\"\n}\n</code></pre>"},{"location":"manual/extension/#delphyne-workspace-file","title":"The Delphyne Workspace File","text":"<p>A Delphyne workspace must have a <code>delphyne.yaml</code> file as its roots:</p> <pre><code>strategy_dirs: [\".\"]\nmodules: [\"module_1\", \"module_2\"]\ndemo_files: [\"demo_1\", \"demo_2\"]\n</code></pre> <p>This files features the following information:</p> <ul> <li>A list of directories within which strategy files can be found, relative to the root of the workspace.</li> <li>A list of module (i.e. file names without extensions) containing those strategies, to be found within those directories. For hot reloading to work, a module should alwways be listed after its dependencies.</li> <li>A list of demonstration files, to be passed implicitly to all commands (e.g. when running an oracular program).</li> </ul>"},{"location":"manual/extension/#editing-demonstrations","title":"Editing Demonstrations","text":"<p>Once activated, the Delphyne extension recognizes demonstration files via their extension <code>*.demo.yaml</code>. A proper YAML schema is automatically loaded and syntax errors are displayed within the editor. To quickly add a new demonstration, you can use the <code>demo</code> snippet (by typing <code>demo</code> and clicking on Tab). All available snippets are listed in <code>vscode-ui/snippets.json</code>.</p> <p>To evaluate a demonstration, put your cursor anywhere in its scope. A light bulb should then appear, suggesting that code actions are available. Use Cmd+. to see available code actions and select <code>Evaluate Demonstration</code>. Diagnostics should then appear, possibly after a moment of waiting (in which case a pending task should be displayed in Delphyne's <code>Tasks</code> view). If the demonstration was successfully evaluated, an <code>info</code> diagnostic should be shown for every test. Otherwise, warnings and errors can be displayed. These diagnostics will stay displayed until the demo file ir closed or the demonstration gets updated. Note that adding comments or modifying other demonstrations does not invalidate them.</p> <p>Each test in a demonstration, even a failing one, describes a path through the underlying search tree. In order to visualize the endpoint of this path, you can put your cursor on the test and select the <code>View Test Destination</code> code action. The resulting node and its context will then be displayed in Delphyne's <code>Tree</code>, <code>Node</code> and <code>Actions</code> view. In the typical case where the test is stuck on a query that is unanswered in the demonstration, one can then click on the <code>+</code> icon next to its description (within the <code>Node</code> view) to add it to the demonstration (if the query exists already, a <code>Jump To</code> icon will be shown instead). The standard workflow is then to add an answer to this query and evaluate the demonstration again.</p> <p>To evaluate all demonstrations within a file, you can use the <code>Delphyne: Evaluate All Demonstrations in File</code> command (use Cmd+Shift+P to open the command palette). To see the prompt associated to a query, put your cursor on this query and use the <code>See Prompt</code> code action. Doing so will create and run the appropriate command in a new tab.</p> <p>Automatic Reloading of Strategies</p> <p>The language server reloads all modules listed in <code>delphyne.yaml</code> for every query, using <code>importlib.reload</code>. This way, strategies can be updated interactively without effort. Note that modules are reloaded in the order in which they are listed. Thus, a module should always be listed after its dependencies.</p>"},{"location":"manual/extension/#commands","title":"Running Commands","text":"<p>Many interactions with Delphyne can be performed by executing commands. A command can be invoked via a YAML file specifying its name and arguments, starting with header <code># delphyne-command</code>. A standard command is the <code>run_strategy</code> command that can be used to run an oracular program by specifying a strategy along with a policy (demonstrations are automatically extracted from the files listed in delphyne.yaml). To create a new tab with a template for invoking the <code>run_strategy</code> command, you can use <code>Delphyne: Run Strategy</code> from the VSCode command palette.</p> A Command Example <pre><code># delphyne-command\n\ncommand: run_strategy\nargs:\n  strategy: prove_program\n  args:\n    prog: |\n      use int.Int\n\n      let main () diverges =\n        let ref a = any int in\n        let ref b = a * a + 2 in\n        let ref x = 0 in\n        while b &lt; 50 do\n          x &lt;- x * (b - 1) + 1;\n          b &lt;- b + 1;\n        done;\n        assert { x &gt;= 0 }\n  policy: prove_program_policy\n  policy_args: {}\n  num_generated: 1\n  budget:\n    num_requests: 60\n</code></pre> <p>To execute a command, one can put the cursor over it and use the <code>Execute Command</code> code action. Doing so will launch a new task that can be viewed in the Delphyne <code>Task</code> view. When the task terminates (successfully or with an error), the command's result is appended at the end of the command file (and can be discarded using the <code>Clear Output</code> code action). When a command returns a trace, the latter can be inspected via the <code>Show Trace</code> code action.</p> <p>The progress of commands can be supervised while they are running through the <code>Tasks</code> view. This view lists all currently running commands and maps each one to a set of actions. For example, a command can be cancelled or its progress indicator shown on the status bar. In addition, the <code>Update Source</code> action (pen icon) allows dumping the command's current partial result to the command file. In the case of the <code>run_strategy</code> command, this allows inspecting the current trace at any point in time while search is still undergoing.</p> <p>Note</p> <p>In the future, Delphyne will allow adding new commands by registering command scripts. </p>"},{"location":"manual/extension/#navigating-trees","title":"Navigating Strategy Trees","text":"<p>Traces can be inspected using the <code>Tree</code>, <code>Node</code> and <code>Actions</code> views (see screenshot at the top of this page). These views are synchronized together and display information about a single node at a time. The <code>Tree</code> view indicates a path from the root to the current node and allows jumping to every intermediate node on this path. The <code>Node</code> view shows the node type and all associated spaces. For each space, it shows the underlying query or allows jumping to the underlying tree. Finally, the <code>Actions</code> view lists all children of the current node that belong to the trace. Actions leading to subtrees containing success nodes are indicated by small checkmarks.</p> <p>Navigation operations can be undone by clicking on the <code>Undo</code> icon on the header of the tree view or by using shortcut Cmd+D followed by Cmd+Z. </p>"},{"location":"manual/extension/#tips-and-shortcuts","title":"Tips and Shortcuts","text":"<ul> <li>Folding is very useful to keep demonstration readable. You should learn the standard VSCode shortcuts for controlling folding (Cmd+K+Cmd+L for toggling folding under the cursor, Cmd+K+Cmd+0 for folding everything, Cmd+K+Cmd+3 for folding everything at depth 3, Cmd+K+Cmd+J for unfolding everything...). In addition, the custom Delphyne shortcut Cmd+D+Cmd+K can be used to fold all strategy and query arguments outside of the cursor's scope.</li> <li>Shortcut Cmd+D+Cmd+V can be used to focus on Delphyne's views.</li> <li>The Github Copilot Code Actions can get in the way of using Delphyne and can be disabled with the <code>\"github.copilot.editor.enableCodeActions\": false</code> setting.</li> <li>When editing YAML files (and demonstration files in particular), VSCode allows semantically expanding and shrinking the selection with respect to the underlying syntax tree via Cmd+Ctrl+Shift+Left and Cmd+Ctrl+Shift+Right.</li> <li>To close a tab (and in particular a command tab), you can use shortcut Cmd+W, followed by Cmd+D to decline saving the tab's content if prompted.</li> </ul>"},{"location":"manual/extension/#troubleshooting","title":"Troubleshooting","text":""},{"location":"manual/extension/#accessing-log-information","title":"Accessing log information","text":"<p>The Delphyne extension outputs logging information in three different output channels:</p> <ul> <li><code>Delphyne</code>: main logging channel</li> <li><code>Delphyne Server</code>: the output of the language server is redirected here (only when the server was started by the extension)</li> <li><code>Delphyne Tasks</code>: displays the logging information produced by commands such as <code>run_strategy</code></li> </ul> <p>You should consult those channels if anything goes wrong. Also, to output more information, you can ask the extension to log more information by raising the log level to <code>Debug</code> or <code>Trace</code> via the <code>Developer: Set Log Level</code> command.</p>"},{"location":"manual/extension/#killing-a-server-instance-still-running-in-the-background","title":"Killing a server instance still running in the background","text":"<p>After VSCode quitted unexpectedly, the language server may still be running in background, which may cause problem when trying to restart the extension. On Unix systems, the language server can be killed by killing the program listening to port 8000:</p> <pre><code>sudo kill -9 $(sudo lsof -t -i :8000)\n</code></pre>"},{"location":"manual/extension/#debug-server","title":"Debugging the language server","text":"<p>To debug the language server or even specific strategies, it is useful to attach a debugger to the language server. To do so, you should open VSCode at the root of the Delphyne repository and use the <code>Debug Server</code> debugging profile. This will start the server in debug mode (on port 8000). Starting the Delphyne extension when a server instance is running already will cause the extension to use this instance (as confirmed by the log output in the <code>Delphyne</code> channel). You can then put arbitrary breakpoints in the server source code or even in strategy code.</p>"},{"location":"manual/policies/","title":"Policies","text":"<p>This page is under construction. In the meantime, you can read about Delphyne's key concepts in the paper Oracular Programming: A Modular Foundation for Building LLM-Enabled Software.</p>"},{"location":"manual/strategies/","title":"Strategies and Trees","text":"<p>This page is under construction. In the meantime, you can read about Delphyne's key concepts in the paper Oracular Programming: A Modular Foundation for Building LLM-Enabled Software.</p>"},{"location":"reference/demos/definitions/","title":"Definition of Demonstrations","text":""},{"location":"reference/demos/interpreter/","title":"Evaluating Demonstrations","text":""},{"location":"reference/policies/definitions/","title":"Policy Types","text":""},{"location":"reference/policies/envs/","title":"Policy Environments","text":""},{"location":"reference/policies/streams/","title":"Search Streams","text":""},{"location":"reference/stdlib/algorithms/","title":"Search Algorithms and Utilities","text":""},{"location":"reference/stdlib/basic/","title":"Basic Definitions","text":""},{"location":"reference/stdlib/commands/","title":"Commands","text":""},{"location":"reference/stdlib/effects/","title":"Standard Nodes and Effects","text":""},{"location":"reference/stdlib/experiments/","title":"Experiments","text":""},{"location":"reference/stdlib/queries/","title":"Queries and Prompting Policies","text":""},{"location":"reference/stdlib/streams/","title":"Stream Combinators","text":""},{"location":"reference/strategies/misc/","title":"Miscellaneous","text":""},{"location":"reference/strategies/queries/","title":"Queries","text":""},{"location":"reference/strategies/traces/","title":"Traces and References","text":""},{"location":"reference/strategies/trees/","title":"Strategies and Trees","text":""}]}