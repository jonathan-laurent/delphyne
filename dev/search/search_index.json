{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started","text":"<p>Delphyne is a programming framework for building reliable and modular LLM applications. It is based on a new paradigm named oracular programming, where high-level problem-solving strategies are expressed as nondeterministic programs whose choice points are annotated with examples and resolved by LLMs. Delphyne combines three languages:</p> <ul> <li>A strategy language embedded in Python that allows writing nondeterministic programs that can be reified into (modular) search trees.</li> <li>A policy language for specifying ways to navigate such trees (with LLM guidance) by composing reusable search primitives.</li> <li>A demonstration language for describing successful and unsuccessful search scenarios to be used as training or prompting examples. A dedicated language server allows writing demonstrations interactively and keeping them synchronized with evolving strategies.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>First, download the Delphyne repository and enter it:</p> <pre><code>git clone git@github.com:jonathan-laurent/delphyne.git\ncd delphyne\ngit checkout v0.7.0  # latest stable version\n</code></pre> <p>Then, to install the Delphyne library in your current Python environment:</p> <pre><code>pip install -e .\n</code></pre> <p>Note that Python 3.12 (or more recent) is required. Once this is done, it should be possible to run <code>import delphyne</code> inside a Python interpreter. Next, you should build the Delphyne vscode extension. For this, assuming you have Node.js installed (version 22 or later), run:</p> <pre><code>cd vscode-ui\nnpm install\nnpx vsce package\n</code></pre> <p>The last command should create a <code>delphyne-xxx.vsix</code> extensions archive, which can be installed in vscode using the <code>Extensions: Install from VSIX</code> command (use <code>Ctrl+Shift+P</code> to search for this command).</p>"},{"location":"#testing-your-installation","title":"Testing your installation","text":"<p>To test your installation, open VSCode and set the <code>examples/find_invariants</code> folder as your workspace root. Click on the Delphyne logo on the Activity Bar to start the Delphyne extension, and open the demonstration file <code>abduct_and_branch.demo.yaml</code>. Then, open the command palette (<code>Ctrl+Shift+P</code>) and run the command <code>Delphyne: Evaluate All Demonstrations in File</code>. Diagnostics should then appear to indicate that all tests passed (but no warning or error). Note that adding new demonstrations requires installing <code>why3py</code>, as explained in the example's README.</p>"},{"location":"how-to-guides/","title":"How-To Guides","text":""},{"location":"how-to-guides/#new-project","title":"Creating a New Delphyne Project","text":"<p>To start a new Delphyne project, we recommend taking the following steps:</p> <ol> <li>Ensure Delphyne is properly installed.</li> <li>Create a new folder for your project.</li> <li>Add an initially empty <code>delphyne.yaml</code> file in this folder.</li> <li>Ensure that your local or global VSCode settings are right.</li> <li>Create a Python file and define a strategy inside it.</li> <li>Register this file in the <code>modules</code> section of <code>delphyne.yaml</code>.</li> <li>To benefit from typechecking, ensure that Pyright is running in strict mode.</li> <li>Optionally, create a <code>prompts</code> folder for storing Jinja prompt templates.</li> <li>Create a demonstration file with extension <code>.demo.yaml</code>.</li> <li>As your project matures, consider adding tests along with a <code>pyproject.toml</code> file.</li> </ol>"},{"location":"how-to-guides/#running","title":"Running an Oracular Program","text":"<p>There are mostly two ways to run oracular programs:</p> <ul> <li>Using <code>StrategyInstance.run_toplevel</code>: As demonstrated in the Overview, one can manually create a policy environment and extract a search stream from a pair of a strategy instance and of a policy. This can be done within any Python script, but offers by default no support for exporting logs and traces, displaying progress, caching LLM requests, handling interruption, etc... Enabling all these features requires substantial additional setup.</li> <li>Running a command: Instead, a command file can be created that specifies a strategy instance, a policy, some search budget along with extra information. The specified command can be launched from within VSCode or from the shell, using the Delphyne CLI (e.g. <code>run my_command.exec.yaml --cache --update</code>).</li> </ul>"},{"location":"how-to-guides/#debugging","title":"Debugging an Oracular Program","text":"<p>Here are some various tips for debugging oracular programs:</p> <ul> <li>Strategies can be debugged before associated policies are defined by writing demonstrations, for which the Delphyne VSCode extension provides rich feedback.</li> <li>For VSCode to stop at breakpoints in strategies while evaluating demonstrations, the Delphyne server must be started with a debugger attached. See the box below for how to do this. Instructions for killing and starting Delphyne servers is available here. </li> <li>Debugging messages can be included in strategy trees using the <code>message</code> function.</li> <li>When running oracular programs via commands, the command output features various useful debugging information by default, in the form of policy logs (including a log of all LLM requests, parsing errors, etc...) and of an inspectable trace.</li> <li>If request caching is enabled (by specifying the <code>cache_dir</code> argument in the command file or passing the <code>--cache</code> option in the CLI), then any run of a command can be replayed identically with a debugger attached (see information below), unless a nondeterministic policy is used (e.g. most policies that use multiple threads).</li> </ul> <p>Attaching a Debugger to the Delphyne CLI</p> <p>For debugging purposes, it is useful to attach a Python debugger to the Delphyne CLI. To do so, we recommend defining the following <code>debug-delphyne</code> alias:</p> <pre><code>alias debug-delphyne='python -m debugpy --listen 5678 --wait-for-client -m delphyne'\n</code></pre> <p>In addition, you should add the following to your <code>.vscode/launch.json</code> file.</p> <p><pre><code>\"name\": \"Attach\",\n\"type\": \"debugpy\",\n\"request\": \"attach\",\n\"connect\": {\n    \"host\": \"localhost\",\n    \"port\": 5678\n    }\n}\n</code></pre> You can then run the Delphyne CLI with a debugger attached by simply substituting <code>delphyne</code> with <code>debug-delphyne</code>. For example, <code>debug-delphyne serve</code> launches a Delphyne server with a debugger attached. Note that the server does not immediately start after running this command, which waits for the user to launch the <code>Attach</code> debugging profile from inside VSCode.</p>"},{"location":"how-to-guides/#tuning","title":"Tuning an Oracular Program","text":""},{"location":"how-to-guides/#conversational","title":"Writing a Conversational Agent","text":""},{"location":"how-to-guides/#compute","title":"Performing Expensive Computations in Strategies","text":""},{"location":"manual/demos/","title":"Demonstration Language","text":"<p>Delphyne includes a demonstration language for writing and maintaining few-shot prompting examples, in the form of coherent scenarios of navigating search trees. The demonstration language is amenable to a test-driven development workflow. This workflow is supported by a dedicated VSCode extension, which is described in the next chapter.</p>"},{"location":"manual/demos/#demonstration-files","title":"Demonstration Files","text":"<p>Demonstrations can be written in demonstration files with a <code>.demo.yaml</code> extension. A demonstration file features a list of demonstrations (<code>Demo</code>). Each demonstration can be separately evaluated. Many short examples can be found in the demonstation file from the Delphyne's test suite:</p> Source for <code>tests/example_strategies.demo.yaml</code> <pre><code>#####\n##### Unit Tests for the Demonstration Language\n#####\n\n# Note: some demonstrations feature errors or failing tests.\n# Some demonstrations also contain an additional `expect` section\n# describing parts of the expected demonstration interpreter feedback.\n\n\n##### Used for testing the UI\n\n- strategy: make_sum\n  args:\n    allowed: [9, 6, 2]\n    goal: 11\n  tests:\n    - run\n  queries: []\n\n\n##### Testing standalone query demos\n\n\n- demonstration: MakeSum_demo\n  query: MakeSum\n  args:\n    allowed: [9, 6, 2]\n    goal: 11\n  answers:\n    - answer: \"[9, 2]\"\n    - label: \"wrong_sum\"\n      answer: \"[9, 6]\"\n\n- demonstration: Unknown_query\n  query: Unknown\n  args: {}\n  answers: []\n\n\n##### Testing make_sum\n\n\n- demonstration: make_sum_demo\n  strategy: make_sum\n  args:\n    allowed: [9, 6, 2]\n    goal: 11\n  tests:\n    - run | success\n    - run 'wrong_sum' | success  # error\n    - run 'alt_order'\n    - failure | run\n  queries:\n    - query: MakeSum\n      args:\n        allowed: [9, 6, 2]\n        goal: 11\n      answers:\n        - answer: \"[9, 2]\"\n        - label: \"wrong_sum\"\n          answer: \"[9, 6]\"\n        - label: \"alt_order\"\n          answer: \"[2, 9]\"\n  expect:\n    trace:\n      nodes:\n        1: {kind: Branch}\n        2: {kind: Success}\n        3: {kind: Fail}\n        4: {kind: Success}\n    test_feedback:\n      - node_id: 2\n        diagnostics: __empty__\n      - node_id: 3\n        diagnostics:\n          - [\"error\", \"Success check failed.\"]\n      - node_id: 4\n        diagnostics: __empty__\n      - node_id: 1\n        diagnostics:\n          - [\"error\", \"Failure check failed.\"]\n\n\n- demonstration: make_sum_selectors\n  strategy: make_sum\n  args:\n    allowed: [9, 6, 2]\n    goal: 11\n  tests:\n    - run 'wrong_sum'\n    - run 'unknown_hint'\n  queries:\n    - query: MakeSum\n      args:\n        allowed: [9, 6, 2]\n        goal: 11\n      answers:\n        - answer: \"[9, 2]\"\n        - label: \"wrong_sum\"\n          answer: \"[9, 6]\"\n  expect:\n    trace:\n      nodes:\n        1: {kind: Branch}\n        2: {kind: Fail}\n        3: {kind: Success}\n    test_feedback:\n      - node_id: 2\n      - node_id: 3\n        diagnostics:\n          - [\"warning\", \"Unused hints: 'unknown_hint'.\"]\n\n\n- demonstration: make_sum_at\n  strategy: make_sum\n  args:\n    allowed: [9, 6, 2]\n    goal: 11\n  tests:\n    - at Unknown\n    - at MakeSum | run\n  queries:\n    - query: MakeSum\n      args:\n        allowed: [9, 6, 2]\n        goal: 11\n      answers:\n        - answer: \"[9, 2]\"\n        - label: \"wrong_sum\"\n          answer: \"[9, 6]\"\n  expect:\n    trace:\n      nodes:\n        1: {kind: Branch}\n        2: {kind: Success}\n    test_feedback:\n      - node_id: 2\n        diagnostics:\n          - [\"warning\", \"Leaf node reached before 'Unknown'.\"]\n      - diagnostics: __empty__\n\n\n- demonstration: make_sum_stuck\n  strategy: make_sum\n  args:\n    allowed: [9, 6, 2]\n    goal: 11\n  tests:\n    - run\n  queries: []\n  expect:\n    trace:\n      nodes: {1: {kind: Branch}}\n    test_feedback:\n      - diagnostics: [[\"warning\", \"Test is stuck.\"]]\n        node_id: 1\n\n\n- demonstration: make_sum_test_parse_error\n  strategy: make_sum\n  args:\n    allowed: [9, 6, 2]\n    goal: 11\n  tests:\n    - bad_command\n  queries: []\n  expect:\n    test_feedback:\n      - diagnostics: [[\"error\", \"Syntax error.\"]]\n\n\n- demonstration: trivial_strategy\n  strategy: trivial_strategy\n  args: {}\n  tests: [run]\n  queries: []\n  expect: {trace: {nodes: {1: {kind: Success}}}}\n\n\n- demonstration: buggy_strategy\n  strategy: buggy_strategy\n  args: {}\n  tests: [run]\n  queries: []\n  expect:\n    global_diagnostics:\n      - [\"error\"]\n\n\n- demonstration: strategy_not_found\n  strategy: unknown_strategy\n  args: {}\n  tests: [run]\n  queries: []\n  expect:\n    global_diagnostics:\n      - [\"error\"]\n\n\n- demonstration: invalid_arguments\n  strategy: make_sum\n  args:\n    bad_arg: \"foo\"\n  tests: [run]\n  queries: []\n  expect:\n    global_diagnostics:\n      - [\"error\"]\n\n\n- demonstration: unknown_query\n  strategy: make_sum\n  args:\n    allowed: [9, 6, 2]\n    goal: 11\n  tests:\n    - run\n  queries:\n    - query: MakeSum\n      args:\n        allowed: [9, 6, 2]\n        goal: 11\n      answers: []\n    - query: UnknownQuery\n      args: {}\n      answers: []\n  expect:\n    query_diagnostics:\n      - [1, [\"error\"]]\n\n\n- demonstration: invalid_answer\n  strategy: make_sum\n  args:\n    allowed: [9, 6, 2]\n    goal: 11\n  tests:\n    - run\n  queries:\n    - query: MakeSum\n      args:\n        allowed: [9, 6, 2]\n        goal: 11\n      answers:\n        - answer: \"'foo'\"\n  expect:\n    answer_diagnostics:\n      - [[0, 0], [\"error\"]]\n\n\n##### Testing synthetize_fun\n\n\n- demonstration: synthetize_fun_demo\n  strategy: synthetize_fun\n  args:\n    vars: &amp;vars_1 [\"x\", \"y\"]\n    prop: &amp;prop_1 [[\"a\", \"b\"], \"F(a, b) == F(b, a) and F(0, 1) == 2\"]\n  tests:\n    - run | success\n    - run 'invalid' | failure\n    - at conjecture_expr | go disprove('wrong1') | save wrong1\n    - load wrong1 | run | success\n    - load wrong1 | run 'bad_cex' | failure\n    - load wrong1 | run 'malformed_cex' | failure\n    - at conjecture_expr | go aggregate(['', 'wrong1', 'wrong2'])\n    - at conjecture_expr | go aggregate(['', 'unknown', 'wrong2'])\n    - at conjecture_expr | answer aggregate(['wrong1', 'wrong2'])\n    - at conjecture_expr | answer aggregate(['', 'wrong1', 'wrong2'])\n  queries:\n    - query: ConjectureExpr\n      args: {vars: *vars_1, prop: *prop_1}\n      answers:\n        - label: right\n          answer: \"2*(x + y)\"\n        - label: wrong1\n          answer: \"x + 2*y\"\n        - label: wrong2\n          answer: \"2*y + x\"\n        - label: invalid\n          answer: \"sys.exit()\"\n    - query: ProposeCex\n      args: {prop: *prop_1, fun: [[x, y], \"x + 2*y\"]}\n      answers:\n        - answer: \"{a: 0, b: 1}\"\n        - label: malformed_cex\n          answer: \"{x: 1, y: 1}\"\n        - label: bad_cex\n          answer: \"{a: 0, b: 0}\"\n    - query: RemoveDuplicates\n      args:\n        exprs: [\"2*(x + y)\", \"x + 2*y\", \"2*y + x\"]\n      answers:\n        - answer: '[\"2*(x + y)\", \"x + 2*y\"]'\n  expect:\n    test_feedback:\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics:\n        - - \"error\"\n          - \"Not a nested tree: aggregate(['', 'wrong1', 'wrong2']).\"\n      - diagnostics:\n        - - \"warning\"\n          - \"Unused hints: 'unknown'.\"\n      - diagnostics:\n        - - \"error\"\n      - diagnostics: __empty__\n\n    global_diagnostics: __empty__\n    saved_nodes: {wrong1: __any__}\n\n\n##### Testing pick_nice_boy_name\n\n\n- demonstration: test_iterate\n  strategy: pick_nice_boy_name\n  args:\n    names: [\"Adeline\", \"Noah\", \"Julia\", \"Jonathan\"]\n  tests:\n    - run | success\n    - run 'girl_name' | failure\n    - run 'other_boy_name' | failure\n    - go cands | go next(nil)\n    - go cands | go next(next(nil){'other_boy_name'}[1]) | run | success\n    - go cands | go next(next(next(nil){'other_boy_name'}[1]){''}[1]) | run | failure\n    # Valid selectors\n    - at iterate\n    - at pick_boy_name  # synonym because `iterate` uses `inherit_tags`\n    - at iterate&amp;pick_boy_name\n    - at iterate/pick_boy_name/PickBoyName\n    # Invalid selectors\n    - at iterate/pick_boy_name  # `Iteration` node has no tags or primary space\n\n    # Mistakenly send the wrong value to `next` by using index 0 instead of 1. The strategy raises\n    # an exception because it explicitly checks the type of its arguments but without this\n    # assertion, we would get stuck on a query with ill-typed arguments.\n    - go cands | go next(next(nil){'other_boy_name'}[0]) | run | success\n  queries:\n    - query: PickBoyName\n      args:\n        names: [Adeline, Noah, Julia, Jonathan]\n        picked_already: []\n      answers:\n      - answer: \"Jonathan\"\n      - label: girl_name\n        answer: \"Julia\"\n      - label: other_boy_name\n        answer: \"Noah\"\n    - query: PickBoyName\n      args:\n        names: [Adeline, Noah, Julia, Jonathan]\n        picked_already: [Noah]\n      answers:\n        - answer: \"Jonathan\"\n    - query: PickBoyName\n      args:\n        names: [Adeline, Noah, Julia, Jonathan]\n        picked_already: [Noah, Jonathan]\n      answers:\n        - answer: \"Sigmund\"\n\n  expect:\n    test_feedback:\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics:\n          - - \"warning\"\n      - diagnostics:\n          - - \"error\"\n\n\n##### Testing generate_pairs and advanced selectors\n\n- demonstration: test_generate_pairs\n  strategy: generate_pairs\n  args: {}\n  tests:\n    - run | success\n    - at PickPositiveInteger#1\n    - at PickPositiveInteger#2\n    - at PickPositiveInteger#3  # error\n  queries:\n    - query: PickPositiveInteger\n      args: {prev: null}\n      answers:\n        - answer: \"1\"\n    - query: PickPositiveInteger\n      args: {prev: 1}\n      answers:\n        - answer: \"2\"\n  expect:\n    test_feedback:\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics:\n          - - \"warning\"\n\n\n##### Testing cached computations\n\n- demonstration: comp_result_in_cache\n  strategy: test_cached_computations\n  args: {n: 2}\n  tests:\n    - run | success\n  queries:\n    - query: __Computation__\n      args:\n        fun: expensive_computation\n        args: {n: 2}\n      answers:\n        - answer: \"[2, 3]\"\n    - query: __Computation__\n      args:\n        fun: expensive_computation\n        args: {n: 3}\n      answers:\n        - answer: \"[3, 4]\"\n  expect:\n    test_feedback:\n      - diagnostics: __empty__\n\n- demonstration: comp_result_outside_cache\n  strategy: test_cached_computations\n  args: {n: 2}\n  tests:\n    - run | success\n  queries: []\n  expect:\n    test_feedback:\n      - diagnostics: __empty__\n    implicit_answers:\n      - query_name: __Computation__\n        query_args: {fun: expensive_computation}\n      - query_name: __Computation__\n        query_args: {fun: expensive_computation}\n\n\n- demonstration: structured_output\n  query: StructuredOutput\n  args:\n    topic: \"Music\"\n  answers:\n    - answer:\n        title: \"Understanding Bach\"\n        authors: [\"Brigitte Mouterde\"]\n\n\n- demonstration: tool_use\n  strategy: propose_article\n  args:\n    user_name: Jonathan\n  tests:\n    - run | success\n  queries:\n    - query: ProposeArticle\n      args:\n        user_name: Jonathan\n        prefix: []\n      answers:\n        - answer: \"\"\n          call:\n            - tool: GetUserFavoriteTopic\n              args: {user_name: Jonathan}\n    - query: ProposeArticle\n      args:\n        user_name: Jonathan\n        prefix:\n          - kind: oracle\n            answer:\n              mode: null\n              content: \"\"\n              tool_calls:\n                - name: GetUserFavoriteTopic\n                  args:\n                    user_name: Jonathan\n          - kind: tool\n            call:\n              name: GetUserFavoriteTopic\n              args:\n                user_name: Jonathan\n            result: Soccer\n      answers:\n      - answer: \"\"\n        call: [{tool: Article, args: {title: \"All about Messi\", authors: [\"Raf\"]}}]\n  expect:\n    test_feedback:\n      - diagnostics: __empty__\n\n\n- demonstration: flags\n  strategy: pick_flag\n  args: {}\n  tests:\n    - run | success\n    - run '#alt' | success\n    - run '#unk'\n  queries: []\n  expect:\n    test_feedback:\n      - diagnostics: __empty__\n      - diagnostics: __empty__\n      - diagnostics:\n        - - \"warning\"\n\n\n- demonstration: flags_global\n  strategy: pick_flag\n  args: {}\n  tests:\n    - run | success\n  queries:\n    - query: MethodFlag\n      args: {}\n      answers: [answer: alt]\n  expect:\n    test_feedback:\n      - diagnostics: __empty__\n\n\n- demonstration: abduction\n  strategy: obtain_item\n  args:\n    market: &amp;market\n      - name: Joe\n        asked_items: [apple, cherry]\n        offered_item: banana\n      - name: Eric\n        asked_items: []\n        offered_item: apple\n      - name: Alice\n        asked_items: []\n        offered_item: cherry\n    goal: banana\n  tests:\n    - run | success\n  queries: \n    - query: ObtainItem\n      args:\n        market: *market\n        possessed_items: []\n        item: banana\n      answers:\n        - answer: {items: [apple, cherry]}\n  expect:\n    test_feedback:\n      - diagnostics: __empty__\n\n\n- demonstration: trivial_untyped_strategy\n  strategy: trivial_untyped_strategy\n  args:\n    string: \"hello\"\n    integer: 42\n  tests:\n    - run | success\n  queries: []\n  expect:\n    test_feedback:\n      - diagnostics: __empty__\n</code></pre> <p>On Reading Demonstration Files</p> <p>Demonstration files are much easier to read and understand using Delphyne's VSCode extension. Standard shortcuts can be used to fold and unfold sections. The additional Cmd+D+Cmd+K shortcut can be used to automatically fold all large sections. Demonstrations can be evaluated and the path followed by each test inspected in the extension's Tree View.</p> <p>A demonstration is either a standalone query demonstration<sup>1</sup> or a strategy demonstration. A query demonstration describes a query instance along with one or several associated answers. A strategy demonstration bundles multiple query demonstrations with unit tests that describe tree navigation scenarios.</p> <p>Warning</p> <p>It is possible to specify few shot examples using one standalone query demonstration per example and nothing else. However, doing so is not recommended. Indeed, such demonstrations are harder to write since tooling cannot be leveraged to generate query descriptions automatically. More importantly, they are harder to read and maintain because individual examples are presented without proper context. Strategy demonstrations allow grounding examples in concrete scenarios, while enforcing this relationship through unit tests.</p> <p>Strategy demonstrations have the following shape:</p> <pre><code>- demonstration: ...    # optional demonstration name\n  strategy: ...         # name of a strategy function decorated with @strategy\n  args: ...             # dictionary of arguments to pass to this strategy\n  tests:\n    - ...\n    - ...\n  queries:\n    - query: ...       # Query name\n      args: ...        # Query arguments\n      answers:\n        - label: ...   # Optional label (to be referenced in tests)\n          example: ... # Whether to use as an example (optional boolean) \n          tags: ...    # Optional set of tags\n          answer: |\n            ...\n        - ...\n</code></pre> <p>The Delphyne VSCode extension automatically checks the syntactic well-formedness of demonstrations (in addition of allowing their evaluation). For explanations on specific fields, see the API Reference. Tests are expressed using a custom DSL that we describe below.</p>"},{"location":"manual/demos/#demonstration-tests","title":"Demonstration Tests","text":"<p>Evaluating a demonstration consists in evaluating all its tests in sequence. Each test describes a path through the tree, starting from the root. The Delphyne VSCode extension allows visualizing this path. A test can succeed, fail, or be stuck. A test is said to be stuck if it cannot terminate due to a missing query answer. In this case  (and as demonstrated in the Overview), the extension allows locating such a query and adding it to the demonstration.</p> <p>Each test is composed of a sequence of instructions separated by <code>|</code>. The most common sequence by far is <code>run | success</code>, which we describe next.</p>"},{"location":"manual/demos/#walking-through-the-tree","title":"Walking through the Tree","text":"<p>Starting at the current node, the <code>run</code> instruction uses answers from the <code>queries</code> section to walk through the tree until either a leaf node is reached or an answer is missing (in which case the test is declared as stuck). Each node type (e.g. <code>Branch</code>) defines a navigation function that describes how the node should be traversed.</p> Navigation Functions <p>A node's navigation function returns a generator that yields local spaces, receives corresponding elements and ultimately returns an action. This is best understood through examples:</p> Example: Navigation function for <code>Branch</code> nodes <pre><code>@dataclass(frozen=True)\nclass Branch(dp.Node):\n    cands: OpaqueSpace[Any, Any]\n\n    @override\n    def navigate(self):\n        return (yield self.cands)\n</code></pre> Example: Navigation function for <code>Join</code> nodes <pre><code>@dataclass(frozen=True)\nclass Join(dp.Node):\n    subs: Sequence[dp.EmbeddedTree[Any, Any, Any]]\n\n    @override\n    def navigate(self):\n        ret: list[Any] = []\n        for sub in self.subs:\n            ret.append((yield sub))\n        return tuple(ret)\n</code></pre> <p>Whenever <code>run</code> needs to select an element from a space defined by a query, it looks for this query in the demonstration\u2019s <code>queries</code> section and picks the first provided answer. If no answer is found, it gets stuck at the current node. When <code>run</code> encounters a space defined by a tree, it recursively navigates this tree. The <code>run</code> command stops when a leaf is reached. It is often composed with the <code>success</code> command, which ensures that the current node is a success leaf.</p> <p>Nothing more than <code>run | success</code> is needed to demonstrate taking a direct path to a solution. The more advanced instructions we discuss next are useful to describe more complex scenarios.</p>"},{"location":"manual/demos/#advanced-tests","title":"Advanced Tests","text":"<p>This section describes more advanced test instructions. In addition to the examples from the test suite, demonstrations with advanced tests are featured in the <code>find_invariants</code> example:</p> Extract from <code>examples/find_invariants/abduct_and_branch.demo.yaml</code> <pre><code>- strategy: prove_program_via_abduction_and_branching\n  args:\n    prog: ... # (1)!\n  tests:\n    - run | success\n    - run 'partial' | success\n    # Demonstrating `EvaluateProofState`\n    - at EvaluateProofState#1 'partial' | answer eval\n    - at EvaluateProofState#2 'partial propose_same' | answer eval\n    # Demonstrating `IsProposalNovel`\n    - at iterate#1 | go cands | go next(next(nil){'partial'}[1]) | save second_attempt\n    - load second_attempt | at IsProposalNovel 'blacklisted' | answer cands\n    - load second_attempt | at IsProposalNovel 'not_blacklisted' | answer cands\n  queries: ... # (2)!\n</code></pre> <ol> <li>See details in original file.</li> <li>See details in original file.</li> </ol>"},{"location":"manual/demos/#exploring-alternative-paths-with-hints","title":"Exploring alternative paths with hints","text":"<p>The <code>run</code> function can be passed a sequence of answer labels as hints, specifying alternate paths through the tree. Whenever a query is encountered, it checks if an answer is available whose label matches the first provided hint. If so, this answer is used and the hint is consumed. For example, instruction <code>run 'foo bar'</code> can be interpreted as:</p> <p>Walk through the tree, using answer <code>foo</code> whenever applicable and then <code>bar</code>.<sup>2</sup></p> <p>This design allows describing paths concisely, by only specifying the few places in which they differ from a default path. This works well for demonstrations, which typically describe shallow traces centered around a successful scenario, with side explorations (e.g., showing how a bad decision leads to a low value score, or demonstrating how redundant candidates can be removed at a particular step).</p>"},{"location":"manual/demos/#stopping-at-particular-nodes","title":"Stopping at particular nodes","text":"<p>The <code>at</code> instruction works like <code>run</code>, except that it takes as an additional argument a node selector that specifies a node at which the walk must stop. The simplest form of node selector consists in a tag to match. For example, instruction <code>at EvalProg 'wrong'</code> behaves similarly to <code>run 'wrong'</code>, except that it stops when encountering a node tagged with <code>EvalProg</code>. By default, all spaces are tagged with the name of the associated query or strategy, and each node inherits the tags of its primary space if it has one. Custom space tags can be added using the <code>SpaceBuilder.tagged</code> method<sup>3</sup>. Finally, the <code>#n</code> operator can be used to match the \\(n^{th}\\) instance of a tag. For example, <code>at PickPositiveInteger#2</code> stops at the second encountered node tagged with <code>PickPositiveInteger</code><sup>4</sup>.</p> <p>Warning</p> <p>Importantly, <code>at</code> can only stop within the same tree that it started in, and not inside a nested tree. In order to stop at a node tagged with <code>bar</code> within a space tagged with <code>foo</code>, you can use <code>at foo/bar</code>. This design choice is mandated by modularity: individual strategies can be made responsible for setting unambiguous tags for nodes that they control, but cannot ensure the absence of clashing tags in other strategies.</p>"},{"location":"manual/demos/#entering-nested-spaces","title":"Entering nested spaces","text":"<p>The <code>go</code> instruction allows entering a tree nested within the current node. For example, if the current node is a <code>Conjecture</code> node (defined in <code>tests/example_strategies.py</code>), <code>go cands</code> enters the tree that defines the <code>cands</code> space or errors if <code>cands</code> is defined by a query. This instruction can be shortened as <code>go</code>, since <code>cands</code> is the primary space of <code>Conjecture</code> nodes.</p> <p>More interestingly, suppose the demonstration already explores two paths within <code>cands</code> that reach different success leaves and thus correspond to two different candidates. Each of these paths can be described through a sequence of hints: the first candidate is identified by <code>''</code> (i.e. default path) and the second by <code>'foo'</code> (i.e. use answer <code>'foo'</code> when appropriate). Then, instruction <code>go aggregate([cands{''}, cands{'foo'}])</code> can be used to enter the strategy tree comparing those two candidates. It can be shortened to <code>go aggregate(['', 'foo'])</code> since <code>cands</code> is a primary space.</p> <p>In general, any element of a local space can be referenced via a (possibly empty) sequence of hints. For spaces defined by queries, at most one hint is expected that indicates which answer to use. For spaces defined by trees, a sequence of hints is expected that leads to a success leaf by calling <code>run</code> recursively.</p> <p>The <code>answer</code> instruction is similar to <code>go</code>. It takes a space selector as an argument but expects to find a query instead of a tree when entering this space. It succeeds if the corresponding query is answered in the demonstration and fails otherwise.</p> <ol> <li> <p>An example of a standalone query demonstration is <code>MakeSum_demo</code> in <code>tests/example_strategies.demo.yaml</code>.\u00a0\u21a9</p> </li> <li> <p>A warning is issued if the <code>run</code> command reaches a leaf node while unused hints remain.\u00a0\u21a9</p> </li> <li> <p>See <code>tests/example_strategies.py:dual_number_generation</code> for an example.\u00a0\u21a9</p> </li> <li> <p>See <code>tests/example_strategies.demo.yaml:test_generate_pairs</code>.\u00a0\u21a9</p> </li> </ol>"},{"location":"manual/extension/","title":"VSCode Extension","text":"<p>A Visual Studio Code extension is available for interactively writing demonstrations, navigating strategy trees, and running oracular programs.</p> <p> </p>"},{"location":"manual/extension/#setting-up-the-extension","title":"Setting Up The Extension","text":""},{"location":"manual/extension/#editor-config","title":"Recommended Editor Configuration","text":"<p>We provide instructions for installing the Delphyne extension on the documentation home page. For the best experience, we recommend also installing the following VSCode extensions:</p> <ul> <li>YAML Language Support</li> <li>Better Jinja</li> </ul> <p>In addition, for optimal readability of demonstration files, line wrapping should be activated for YAML files. We recommend doing the same for Jinja files. Finally, we recommend associating the <code>*.jinja</code> extension with the <code>jinja-md</code> file format. See below for the recommended JSON configuration, which you can copy to your VSCode settings.</p> .vscode/settings.json <pre><code>\"[yaml]\": {\n    \"editor.wrappingIndent\": \"indent\",\n    \"editor.wordWrap\": \"wordWrapColumn\",\n    \"editor.indentSize\": 2,\n    \"editor.wordWrapColumn\": 100,\n    \"editor.rulers\": [100],\n},\n// Wrap template files for readability.\n\"[jinja-md]\": {\n    \"editor.wrappingIndent\": \"indent\",\n    \"editor.wordWrap\": \"wordWrapColumn\",\n    \"editor.wordWrapColumn\": 80,\n    \"editor.indentSize\": 2,\n    \"editor.rulers\": [80],\n},\n// Indicate that the Jinja templates are written in Markdown\n\"files.associations\": {\n    \"*.jinja\": \"jinja-md\"\n}\n</code></pre>"},{"location":"manual/extension/#starting-server","title":"Starting The Delphyne Server","text":"<p>The Delphyne extension relies on Delphyne's language server to evaluate demonstrations and run commands. The language server is automatically started in the background when the Delphyne extension is activated (by clicking on the Delphyne icon on the VSCode activity bar), if it is not running already (listening on port 3008).</p> <p>Locating the language server</p> <p>The Delphyne extension uses the Python distribution currently selected for the workspace by Pylance to launch the language server. If no such distribution is configured, you can set it via the <code>Python: Select Interpreter</code> command and then try again using the <code>Delphyne: Start Server Command</code>.</p> <p>The background server process can be shut down using the <code>Delphyne: Kill Server</code> command. The <code>Delphyne: Start Server Command</code> can be used to restart it, if it is not running already. The server can be launched outside VSCode using the <code>delphyne serve</code> shell command. Since the server is stateless, it can be restarted at any time. One reason for running the server outside VSCode is to attach a debugger to it, which allows setting breakpoints inside strategies, policies, or even inside the demonstration interpreter.</p> <p>You can confirm that the language server is running by looking at the <code>Delphyne</code> output channel (from the <code>Output</code> tab in the panel). See Troubleshooting if you encounter any problem.</p>"},{"location":"manual/extension/#project-root","title":"Detecting Project Root Directories","text":"<p>When evaluating a demonstration or running a command, the Delphyne extension locates the corresponding project root directory as follows:</p> <ol> <li>If a transitive parent directory for the current demonstration or command file contains a <code>delphyne.yaml</code> configuration file, it is selected.</li> <li>If the current editor is not attached to an existing file<sup>1</sup> or no <code>delphyne.yaml</code> file can be found, the current VSCode's workspace directory is used.</li> </ol> <p>The <code>Delphyne: Show Root Directory for Current File</code> command can be used to show the current project root. The rules above allow browsing and editing multiple Delphyne projects within a single VSCode workspace.</p>"},{"location":"manual/extension/#config","title":"Global and Local Configuration","text":"<p>Both demonstration and command files are evaluated in the context of a given configuration record, which specifies information such as the location and names of Python modules in which strategies can be found, the location of prompting templates and demonstration files, etc... This information can be stored in the project's <code>delphyne.yaml</code> file, whose content may look like:</p> <pre><code>strategy_dirs: [\".\"]\nmodules: [\"module_1\", \"module_2\"]\ndemo_files: [\"demo_1\", \"demo_2\"]\n</code></pre> <p>See the Reference for the list and description of all available settings. All settings have default values so empty <code>delphyne.yaml</code> files are allowed (or no file at all if the project root coincides with the VSCode workspace). In addition, any subset of global settings from the <code>delphyne.yaml</code> file can be locally overriden in individual demonstration or command files by prefixing it with a <code>@config</code> comment block.</p>"},{"location":"manual/extension/#editing-demonstrations","title":"Editing Demonstrations","text":"<p>Once activated, the Delphyne extension recognizes demonstration files via their extension <code>*.demo.yaml</code>. A proper YAML schema is automatically loaded and syntax errors are displayed within the editor. To quickly add a new demonstration, you can use the <code>demo</code> snippet (by typing <code>demo</code> and clicking on Tab). All available snippets are listed in <code>vscode-ui/snippets.json</code>.</p> <p>To evaluate a demonstration, put your cursor anywhere in its scope. A light bulb should then appear, suggesting that code actions are available. Use Cmd+. to see available code actions and select <code>Evaluate Demonstration</code>. Diagnostics should then appear, possibly after a moment of waiting (in which case a pending task should be displayed in Delphyne's <code>Tasks</code> view). If the demonstration was successfully evaluated, an <code>info</code> diagnostic should be shown for every test. Otherwise, warnings and errors can be displayed. These diagnostics will stay displayed until the demo file ir closed or the demonstration gets updated. Note that adding comments or modifying other demonstrations does not invalidate them.</p> <p>Each test in a demonstration, even a failing one, describes a path through the underlying search tree. In order to visualize the endpoint of this path, you can put your cursor on the test and select the <code>View Test Destination</code> code action. The resulting node and its context will then be displayed in Delphyne's <code>Tree</code>, <code>Node</code> and <code>Actions</code> view. In the typical case where the test is stuck on a query that is unanswered in the demonstration, one can then click on the <code>+</code> icon next to its description (within the <code>Node</code> view) to add it to the demonstration (if the query exists already, a <code>Jump To</code> icon will be shown instead). The standard workflow is then to add an answer to this query and evaluate the demonstration again.</p> <p>To evaluate all demonstrations within a file, you can use the <code>Delphyne: Evaluate All Demonstrations in File</code> command (use Cmd+Shift+P to open the command palette). To see the prompt associated to a query, put your cursor on this query and use the <code>See Prompt</code> code action. Doing so will create and run the appropriate command in a new tab.</p> <p>Automatic Reloading of Strategies</p> <p>The language server reloads all modules listed in <code>delphyne.yaml</code> for every query, using <code>importlib.reload</code>. This way, strategies can be updated interactively without effort. Note that modules are reloaded in the order in which they are listed. Thus, a module should always be listed after its dependencies.</p> <p>Evaluating Demonstrations using the CLI</p> <p>Demonstrations can also be evaluated from the shell, using the Delphyne CLI. However, the CLI provides much more limited feedback so it is mainly useful for testing and continuous integration.</p>"},{"location":"manual/extension/#commands","title":"Running Commands","text":"<p>Many interactions with Delphyne can be performed by executing commands.Commands can be specified in YAML files with extension <code>.exec.yaml</code>. Unnamed documents are also recognized as command files if they start with line <code># delphyne-command</code>, possibly following other YAML comments. Commands can emit diagnostics and intermediate status updates, output a stream of partial results and be safely interrupted. The Delphyne extension provides editor support for these features, via its <code>Task View</code>. Commands can also be run from the Delphyne CLI, which is useful for specifying test suites or launching a large number of commands. </p> <p>A standard command is <code>run_strategy</code>, which can be used to run an oracular program by specifying a strategy along with a policy (demonstrations are automatically extracted from the files listed in delphyne.yaml). To create a new tab with a template for invoking the <code>run_strategy</code> command, you can use <code>Delphyne: Run Strategy</code> from the VSCode command palette.</p> A Command Example <pre><code># delphyne-command\n\ncommand: run_strategy\nargs:\n  strategy: prove_program\n  args:\n    prog: |\n      use int.Int\n\n      let main () diverges =\n        let ref a = any int in\n        let ref b = a * a + 2 in\n        let ref x = 0 in\n        while b &lt; 50 do\n          x &lt;- x * (b - 1) + 1;\n          b &lt;- b + 1;\n        done;\n        assert { x &gt;= 0 }\n  policy: prove_program_policy\n  policy_args: {}\n  num_generated: 1\n  budget:\n    num_requests: 60\n</code></pre> <p>To execute a command, one can put the cursor over it and use the <code>Execute Command</code> code action. Doing so will launch a new task that can be viewed in the Delphyne <code>Task</code> view. When the task terminates (successfully or with an error), the command's result is appended at the end of the command file (and can be discarded using the <code>Clear Output</code> code action). When a command returns a trace, the latter can be inspected via the <code>Show Trace</code> code action.</p> <p>The progress of commands can be supervised while they are running through the <code>Tasks</code> view. This view lists all currently running commands and maps each one to a set of actions. For example, a command can be cancelled or its progress indicator shown on the status bar. In addition, the <code>Update Source</code> action (pen icon) allows dumping the command's current partial result to the command file. In the case of the <code>run_strategy</code> command, this allows inspecting the current trace (i.e. the set of all visited tree nodes and spaces) at any point in time while search is still undergoing.</p> <p>Note</p> <p>In the future, Delphyne will allow adding new commands by registering command scripts. </p>"},{"location":"manual/extension/#navigating-trees","title":"Navigating Strategy Trees","text":"<p>Whether they originate from evaluating demonstrations or running commands, traces can be inspected using the <code>Tree</code>, <code>Node</code> and <code>Actions</code> views (see screenshot at the top of this page). These views are synchronized together and display information about a single node at a time. The <code>Tree</code> view indicates a path from the root to the current node and allows jumping to every intermediate node on this path. The <code>Node</code> view shows the node type and all associated spaces. For each space, it shows the underlying query or allows jumping to the underlying tree. Finally, the <code>Actions</code> view lists all children of the current node that belong to the trace. Actions leading to subtrees containing success nodes are indicated by small checkmarks.</p> <p>Navigation operations can be undone by clicking on the <code>Undo</code> icon on the header of the tree view or by using shortcut Cmd+D followed by Cmd+Z. </p>"},{"location":"manual/extension/#tips-and-shortcuts","title":"Tips and Shortcuts","text":"<ul> <li>Folding is very useful to keep demonstration readable. You should learn the standard VSCode shortcuts for controlling folding (Cmd+K+Cmd+L for toggling folding under the cursor, Cmd+K+Cmd+0 for folding everything, Cmd+K+Cmd+3 for folding everything at depth 3, Cmd+K+Cmd+J for unfolding everything...). In addition, the custom Delphyne shortcut Cmd+D+Cmd+K can be used to fold all strategy and query arguments outside of the cursor's scope.</li> <li>Shortcut Cmd+D+Cmd+V can be used to focus on Delphyne's views.</li> <li>The Github Copilot Code Actions can get in the way of using Delphyne and can be disabled with the <code>\"github.copilot.editor.enableCodeActions\": false</code> setting.</li> <li>When editing YAML files (and demonstration files in particular), VSCode allows semantically expanding and shrinking the selection with respect to the underlying syntax tree via Cmd+Ctrl+Shift+Left and Cmd+Ctrl+Shift+Right.</li> <li>To close a tab (and in particular a command tab), you can use shortcut Cmd+W, followed by Cmd+D to decline saving the tab's content if prompted.</li> <li>Since command outputs can be verbose, it is recommended to start folding sections starting at level 4 (using Cmd+K+Cmd+4) and then unfolding sections as needed.</li> </ul>"},{"location":"manual/extension/#troubleshooting","title":"Troubleshooting","text":""},{"location":"manual/extension/#accessing-log-information","title":"Accessing log information","text":"<p>The Delphyne extension outputs logging information in three different output channels:</p> <ul> <li><code>Delphyne</code>: main logging channel</li> <li><code>Delphyne Server</code>: the output of the language server is redirected here (only when the server was started by the extension)</li> <li><code>Delphyne Tasks</code>: displays the logging information produced by commands such as <code>run_strategy</code></li> </ul> <p>You should consult those channels if anything goes wrong. Also, to output more information, you can ask the extension to log more information by raising the log level to <code>Debug</code> or <code>Trace</code> via the <code>Developer: Set Log Level</code> command.</p>"},{"location":"manual/extension/#killing-a-server-instance-still-running-in-the-background","title":"Killing a server instance still running in the background","text":"<p>After VSCode quitted unexpectedly, the language server may still be running in background, which may cause problem when trying to restart the extension. On Unix systems, the language server can be killed by killing the program listening to port 3008:</p> <pre><code>sudo kill -9 $(sudo lsof -t -i :3008)\n</code></pre> <ol> <li> <p>For example, it may contain an unsaved command specification.\u00a0\u21a9</p> </li> </ol>"},{"location":"manual/overview/","title":"Overview","text":"<p>Let us illustrate the Delphyne framework using a simple example that is also featured in the Getting Started section. The task being solved in this example is, given a mathematical expression featuring real variables \\(x\\) and \\(n\\), to find an integer value for \\(n\\) for which the expression is nonnegative for all values of \\(x\\). We first propose a more verbose solution that better illustrates Delphyne's fundamental abstractions, and then demonstrate a shorter one. All code for these examples is available in <code>examples/small/find_param_value.py</code> and <code>examples/small/find_param_value_universal.py</code></p>"},{"location":"manual/overview/#writing-a-strategy","title":"Writing a Strategy","text":"<p>Delphyne lets you combine prompting with traditional programming to solve problems. The first step is defining a strategy. A strategy provides a high-level sketch for solving a problem. It consists in a program with unresolved choice points, which are determined by LLMs at runtime. For example, here is an example of a strategy for the problem defined above (finding a value for integer parameter \\(n\\) that makes a mathematical expression nonnegative for all \\(x\\)):</p> <pre><code>import sympy as sp\nfrom typing import assert_never\nimport delphyne as dp # (1)!\nfrom delphyne import Branch, Fail, Strategy, strategy\n\n@strategy\ndef find_param_value(\n    expr: str\n) -&gt; Strategy[Branch | Fail, FindParamValueIP, int]: # (2)!\n    x, n = sp.Symbol(\"x\", real=True), sp.Symbol(\"n\")\n    symbs = {\"x\": x, \"n\": n}\n    try:\n        n_val = yield from dp.branch(\n            FindParamValue(expr)\n              .using(lambda p: p.guess, FindParamValueIP)) # (3)!\n        expr_sp = sp.parse_expr(expr, symbs).subs({n: n_val})\n        equiv = yield from dp.branch(\n            RewriteExpr(str(expr_sp))\n              .using(lambda p: p.prove, FindParamValueIP))\n        equiv_sp = sp.parse_expr(equiv, symbs)\n        equivalent = (expr_sp - equiv_sp).simplify() == 0\n        yield from dp.ensure(equivalent, \"not_equivalent\")\n        yield from dp.ensure(equiv_sp.is_nonnegative, \"not_nonneg\")\n        return n_val\n    except Exception as e: # (4)!\n        assert_never((yield from dp.fail(\"sympy_error\", message=str(e))))\n</code></pre> <ol> <li>We recommend importing Delphyne under alias <code>dp</code>, which is a convention we use in most examples. Most symbols from Delphyne's core or standard library can be accessed in this way. </li> <li>This return type can be ignored on first reading. The first type parameter passed to <code>Strategy</code> is the strategy's signature (the list of effects it can trigger or, equivalently, the types of tree nodes that can appear in the induced tree), the second parameter is the strategy's associated inner policy type (see explanations in Writing a Policy), and the third parameter is the type of returned values (here, an integer denoting the value of <code>n</code>).</li> <li>The <code>using</code> method can be ignored on first reading. It takes as an argument a mapping from the ambient inner policy (of type <code>FindParamValueIP</code>, as specified in the strategy's return type) to a prompting policy for handling the <code>FindParamValue</code> query).</li> <li>If a SymPy expression fails to parse or <code>simplify</code> raises an exception, the whole strategy fails.</li> </ol> <p>The strategy above proceeds in three steps. First, it prompts an LLM to conjecture a value for \\(n\\) (Lines 13-15). Then, it substitutes \\(n\\) with the provided value and asks an LLM for a proof that the resulting expression is positive for all \\(x\\), in the form of an equivalent expression for which this fact obvious, in the sense that it can be derived from simple interval arithmetic (Lines 16-19). For example, expression \\(x^2 - 2x + 3\\) can be rewritten into \\((x - 1)^2 + 2.\\) Finally, SymPy is used to check the validity of this proof (Lines 20-23) and the value of \\(n\\) is returned if the proof is valid. The two aforementioned LLM queries are defined as follows:</p> <pre><code>@dataclass\nclass FindParamValue(dp.Query[int]): # (1)!\n    \"\"\"\n    Given a sympy expression featuring a real variable `x` and an\n    integer parameter `n`, find an integer value for `n` such that the\n    expression is non-negative for all real `x`. Terminate your answer\n    with a code block delimited by triple backquotes containing an integer.\n    \"\"\" # (2)!\n\n    expr: str\n    __parser__ = dp.last_code_block.yaml\n\n\n@dataclass\nclass RewriteExpr(dp.Query[str]):\n    \"\"\"\n    Given a sympy expression featuring variable `x`, rewrite it into an\n    equivalent form that makes it clear that the expression is\n    nonnegative for all real values of `x`. Terminate your answer with a\n    code block delimited by triple backquotes. This block must contain a\n    new sympy expression, or nothing if no rewriting could be found.\n    \"\"\"\n\n    expr: str\n    __parser__ = dp.last_code_block.trim\n</code></pre> <ol> <li>The type argument passed to <code>Query</code> is the answer type for this query. Custom datatypes are also allowed as long as they are serializable using Pydantic.</li> <li>Short system prompts can be specified in docstrings but longer prompts are often more conveniently specified in separate Jinja files. Custom instance prompts can also be specified. By default, a YAML dumping of all query fields is used.</li> </ol> <p>LLM requests are represented by queries. Queries are stratified by type. A query type can be defined by inheriting the <code>Query</code> class and is defined by:</p> <ol> <li>A name (e.g., <code>FindParamValue</code>).</li> <li>An answer type (e.g., <code>int</code>).</li> <li>A system prompt that describes the underlying family of tasks (i.e., the docstring).</li> <li>A series of fields describing specific task instances.</li> <li>A parser that specifies how to parse LLM answers into the answer type.</li> </ol> <p>Few-Shot Prompting</p> <p>As we discuss later, organizing queries into types is especially useful for implementing few-shot prompting. Indeed, to answer a query of a given type, one can build a prompt that concatenates (1) the system prompt associated with the query's type, (2) a sequence of examples that each consist in a query of the same type along with the expected answer, and (3) the query to be answered.</p> <p>Going back to the above definition of the <code>find_param_value</code> strategy, one can branch over possible answers to a query using the <code>branch</code> operator. In addition, one can ensure that a property holds using the <code>ensure</code> operator, or fail straight using <code>fail</code>. Strategies can be reified (i.e., compiled) into search trees that feature success leaves (corresponding to reaching a <code>return</code> statement), failure leaves (corresponding to failing an <code>ensure</code> statement or reaching a <code>fail</code> statement), and internal branching nodes (corresponding to reaching a <code>branch</code> statement). How such trees must be navigated at runtime (using LLM guidance) is defined by separate policies, which is the topic of the next section.</p> Difference between <code>ensure</code> and <code>assert</code> <p>Strategies can also feature Python assertions (<code>assert</code> statements) but these serve a different purpose from <code>ensure</code>. An <code>assert</code> statement failing means that an internal error happened, either indicating a bug in the strategy code or invalid toplevel inputs. In contrast, an <code>ensure</code> statement can fail following incorrect LLM answers (and thereby induce a failure leaf), as a normal part of performing search.</p> Modularity and Extensibility <p>As we explain in the next chapter, the <code>branch</code> operator can be used to branch over answers of a query but also over results of another strategy. In this way, any query in a strategy can be later refined into a dedicated strategy if more guidance is needed. Allowing such composition is one of the key language design challenges solved by Delphyne. In addition, the strategy language can be easily extended with new effects (i.e., new types of tree nodes). Examples from the Delphyne standard library include: <code>value</code>, <code>join</code>, <code>compute</code>, <code>message</code>, <code>get_flag</code>...</p> Leveraging Typing <p>Strategies can be precisely typed, and their types statically checked using Pyright in strict mode.</p>"},{"location":"manual/overview/#writing-a-policy","title":"Writing a Policy","text":"<p>Crucially, Delphyne allows fully separating the definition of search spaces (induced by strategies) from the algorithms used to navigate them (i.e., policies). This separation serves multiple practical purposes:</p> <ol> <li>Many different policies can be implemented for any given strategy without modifying it, realizing different tradeoffs in terms of latency, budget consumption, reliability...</li> <li>Policies can be tuned independently without changing strategy code. In addition, demonstrations are query-agnostic and so tuning policies is guaranteed not to break demonstrations either (see next section).</li> </ol> <p>In practice, policies tend to require more tuning and faster iteration cycles than strategies, since they often feature search hyperparameters for which good values are hard to guess a priori. Thus, they tend to evolve on a shorter time-scale and keeping them independent is valuable.</p> <p>Below, we show a possible (parametric) policy for the <code>find_param_value</code> strategy.</p> <pre><code>@dp.ensure_compatible(find_param_value) # (1)!\ndef serial_policy(\n    model_name: dp.StandardModelName = \"gpt-5-mini\",\n    proof_reattempts: int = 1\n) -&gt; dp.Policy[Branch | Fail, FindParamValueIP]:\n    model = dp.standard_model(model_name)\n    return dp.dfs() &amp; FindParamValueIP(\n        guess=dp.few_shot(model),\n        prove=dp.take(proof_reattempts + 1) @ dp.few_shot(model))\n</code></pre> <ol> <li>This decorator is only used statically to have the type checker verify that the policy being defined has a type compatible with the <code>find_param_value</code> strategy.</li> </ol> <p>As shown on Line 7, a policy (<code>Policy</code>) consists in two components that are paired using the <code>&amp;</code> operator. The first one is a search policy (<code>SearchPolicy</code>), which consists in a search algorithm used to navigate the tree defined by the strategy, and which must be capable of handling <code>Branch</code> and <code>Fail</code> nodes in this case. Here, we use depth-first search, which is implemented in the <code>dfs</code> standard library function. In addition, for every query issued by our strategy, we need to provide a suitable prompting policy (<code>PromptingPolicy</code>) to describe how the query must be answered by LLMs. These prompting policies are gathered in an record of type <code>FindParamValueIP</code>, which is called the inner policy type associated with <code>find_param_value</code> and which is defined as follows:</p> <pre><code>@dataclass\nclass FindParamValueIP: # (1)!\n    guess: dp.PromptingPolicy\n    prove: dp.PromptingPolicy\n</code></pre> <ol> <li>The <code>IP</code> suffix stands for inner policy.</li> </ol> <p>In general, for every strategy, an associated inner policy type is defined that precisely indicates what information must be provided to build associated policies (in addition to the toplevel search algorithm). Although the inner policy type is fairly simple in this case, it can get more complicated when (1) a strategy branches over results of another sub-strategy (in which case a <code>Policy</code> must be provided) or (2) strategies involve loops or recursion (in which case prompting policies and sub-policies may depend on extra parameters such as the iteration number or recursion depth). In the definition of <code>find_param_value</code>, the <code>using</code> method is called on queries to provide each time a mapping from the ambient inner policy (of type <code>FindParamValueIP</code>) to the prompting policy to use.</p> A More Concise Alternative for Handling Inner Policies <p>Defining inner policy types and specifying functions from those to prompting policies or sub-policies via <code>using</code> allows a maximal degree of flexibility, static type safety and editor support. However, one might find it verbose. Thus, inner policies can also be specified via simple Python dictionaries (see <code>IPDict</code>), as we soon demonstrate.</p> <p>The <code>serial_policy</code> policy defined above uses depth-first search (<code>dfs</code>) to find solutions: every time a branching node is reached in the search tree, branching candidates are lazily enumerated and explored in order. As specified in the inner policy, branching candidates are generated by repeatedly sampling LLM answers, using the <code>few_shot</code> prompting policy (we discuss how few-shot examples can be added in the next section). The branching factor for producing proofs is set to <code>proof_reattempts + 1</code>, while the branching factor for producing candidates for \\(n\\) is set to infinity (LLM answers are not deduplicated by default). As mentioned earlier, alternative policies can be defined. For example, the following policy repeatedly performs a parallel variant of depth-first search (<code>par_dfs</code>), where multiple LLM completions are requested at every branching nodes and children are explored in parallel.</p> <pre><code>@dp.ensure_compatible(find_param_value)\ndef parallel_policy(\n    model_name: dp.StandardModelName = \"gpt-5-mini\",\n    par_find: int = 2,\n    par_rewrite: int = 2\n) -&gt; dp.Policy[Branch | Fail, FindParamValueIP]:\n    model = dp.standard_model(model_name)\n    return dp.loop() @ dp.par_dfs() &amp; FindParamValueIP(\n        guess=dp.few_shot(model, max_requests=1, num_completions=par_find),\n        prove=dp.few_shot(model, max_requests=1, num_completions=par_rewrite))\n</code></pre> <p>In general, a wide variety of policies can be assembled using standard basic blocks such as <code>dfs</code>, <code>par_dfs</code>, <code>few_shot</code> and <code>take</code> (many others are available, e.g., <code>best_first_search</code>). However, adding new building blocks or search algorithms is easy. For example, <code>par_dfs</code> can be simply redefined as follows:</p> <pre><code>@search_policy\ndef par_dfs[P, T](\n    tree: Tree[Branch | Fail, P, T],\n    env: PolicyEnv,\n    policy: P,\n) -&gt; StreamGen[T]:\n    match tree.node:\n        case Success(x):\n            yield Solution(x)\n        case Fail():\n            pass\n        case Branch(cands):\n            cands = yield from cands.stream(env, policy).all()\n            yield from Stream.parallel([\n                par_dfs()(tree.child(a.tracked), env, policy)\n                for a in cands]).gen()\n</code></pre> <p>The manual chapter on policies provides details on how new policy components can be defined, using search stream combinators.</p> <p>Once a policy is specified, we can run our strategy as follows:</p> <pre><code>budget = dp.BudgetLimit({\"dp.NUM_REQUESTS\": 2}) # (1)!\nres, _ = (\n    find_param_value(\"2*x**2 - 4*x + n\")\n    .run_toplevel(dp.PolicyEnv(demonstration_files=[]), serial_policy()) # (2)!\n    .collect(budget=budget, num_generated=1))\nprint(res[0].tracked.value)  # e.g. 2\n</code></pre> <ol> <li>We define a budget limit for search, in terms of number of LLM requests. Other metrics are available: number if input/output tokens, API spending in dollars...</li> <li>In addition to a policy, we also provide a global policy environment (<code>PolicyEnv</code>), which can be used to specify demonstration files (for few-shot prompting), prompt templates, LLM request caches...</li> </ol> <p>Here, <code>gpt-5-mini</code> (the default model specified by <code>serial_policy</code>) is used to answer queries via zero-shot prompting. However, LLMs often work better when provided examples of answering similar queries. Delphyne features a domain-specific language for writing and maintaining such examples in the form of demonstrations.</p>"},{"location":"manual/overview/#adding-demonstrations","title":"Adding Demonstrations","text":"<p>Although queries can sometimes be successfully answered via zero-shot prompting, LLMs typically work better when examples of answering queries of the same type are provided. Such examples become essential parts of an LLM-enabled program, which must be kept in sync as it evolves. Delphyne offers a dedicated language for writing and maintaining examples. In this language, related examples are bundled with unit tests into coherent demonstrations. Demonstrations showcase concrete scenarios of navigating search trees and can be written interactively, using a tool-assisted, test-driven workflow.</p> <p>Let us add a demonstration for the <code>find_param_value</code> strategy. We do so by adding the following to a demonstration file (with extension <code>.demo.yaml</code>):</p> <pre><code>- strategy: find_param_value\n  args:\n    expr: \"x**2 - 2*x + n\"\n  tests:\n    - run | success\n  queries: []\n</code></pre> <p>The test in this snippet indicates that the goal is to demonstrate how to successfully solve a specific instance of our strategy, using a set of query/answer pairs provided in the <code>queries</code> section. This section is initially empty. Thus, evaluating the demonstration above (using the <code>Evaluate Demonstration</code> code action from the VSCode extension) results in a warning:</p> <p> </p> <p>Here, the extension indicates that the demonstation's unique test is stuck, due to a missing query answer. Using the extension's tree view, the user can visualize where in the tree it is stuck and add the missing query to the demonstration by clicking on the <code>+</code> icon:</p> <pre><code>- strategy: find_param_value\n  args:\n    expr: \"x**2 - 2*x + n\"\n  tests:\n    - run | success\n  queries: \n    - query: FindParamValue\n      args:\n        expr: x**2 - 2*x + n\n      answers: []\n</code></pre> <p>The user can then add an answer to the query, either manually or by querying an LLM and editing the result. After this, the demonstration can be evaluated again and the process repeats, until all tests pass. In this case, the final demonstration is:</p> <pre><code>- strategy: find_param_value\n  args:\n    expr: \"x**2 - 2*x + n\"\n  tests:\n    - run | success\n  queries: \n    - query: FindParamValue\n      args:\n        expr: x**2 - 2*x + n\n      answers:\n        - answer: | # (1)!\n            ```\n            1\n            ```\n    - query: RewriteExpr\n      args:\n        expr: x**2 - 2*x + 1\n      answers:\n        - answer: |\n            ```\n            (x - 1)**2\n            ```\n</code></pre> <ol> <li>As specified by the parser of <code>FindParamValue</code>, answers must end with a code block featuring a YAML object. A chain of thoughts or an explanation can be provided outside the code block, although we do not do so here.</li> </ol> <p>Once such a demonstration is written, the associated tests guarantee that it stays relevant and consistent as the whole program evolves. The Delphyne language server provides a wide range of diagnostics for demonstrations, from detecting unreachable or unparseable answers to indicating runtime strategy exceptions.</p> <p>The demonstration language allows expressing more advanced tests. In particular, it allows specifying negative examples and describing scenarios of recovering from bad decisions during search. More details are provided in the Demonstrations chapter of the manual.</p> <p>Demonstrations are Policy-Agnostic</p> <p>Crucially, demonstrations are policy-agnostic. In fact, a common practice is to start writing demonstrations after a strategy is defined and before associated policies are specified. Modifying policies is guaranteed never to break a demonstration, leveraging the full separation between strategies and policies at the heart of Delphyne's design.</p> <p>In order to walk through search trees without depending on a specific policy, the <code>run</code> test instruction leverages local navigation functions that are defined for every type of tree node (including custom nodes added by users). For example, upon encountering a branching node of type <code>Branch</code>, <code>run</code> examines whether branching occurs over query answers or over the results of another strategy. In the first case, an answer to the featured query is fetched from the <code>queries</code> section of the demonstration. In the second case, <code>run</code> executes recursively.</p>"},{"location":"manual/overview/#a-more-concise-version","title":"A More Concise Version","text":"<p>There are two ways in which the strategy above can be shortened (while preserving its logic). First, one can use inner policy dictionaries instead of manually defining and manipulating inner policy types such as <code>FindParamValueIP</code> (see <code>IPDict</code> for details). Second, Delphyne offers an experimental feature that saves users from manually defining queries. Indeed, the <code>guess</code> operator can be used to ask LLMs for an object of a given type, given some context that is automatically extracted from the stack frame at the call site.</p> <p>Using these two features, the <code>find_param_value</code> strategy can be rewritten as follows:</p> <pre><code>import sympy as sp\nfrom typing import assert_never\nimport delphyne as dp \nfrom delphyne import Branch, Fail, Strategy, strategy\n\n\n@strategy\ndef find_param_value(expr: str) -&gt; Strategy[Branch | Fail, IPDict, int]:\n    \"\"\"\n    Find an integer parameter `n` that makes a given math expression\n    nonnegative for all real `x`. Then, prove that the resulting\n    expression is indeed nonnegative for all real `x` by rewriting it\n    into an equivalent form that makes this fact clear.\n    \"\"\"\n    x, n = sp.Symbol(\"x\", real=True), sp.Symbol(\"n\")\n    symbs = {\"x\": x, \"n\": n}\n    try:\n        n_val = yield from dp.guess(int, using=[expr])\n        expr_sp = sp.parse_expr(expr, symbs).subs({n: n_val})\n        equiv = yield from dp.guess(str, using=[str(expr_sp)])\n        equiv_sp = sp.parse_expr(equiv, symbs)\n        equivalent = (expr_sp - equiv_sp).simplify() == 0\n        yield from dp.ensure(equivalent, \"not_equivalent\")\n        yield from dp.ensure(equiv_sp.is_nonnegative, \"not_nonneg\")\n        return n_val\n    except Exception as e:\n        assert_never((yield from dp.fail(\"sympy_error\", message=str(e))))\n\n\ndef serial_policy():\n    model = dp.standard_model(\"gpt-5-mini\")\n    return dp.dfs() &amp; {\n        \"n_val\": dp.few_shot(model),\n        \"equiv\": dp.take(2) @ dp.few_shot(model),\n    }\n</code></pre> <p>Behind the scenes, <code>guess</code> issues instances of the <code>UniversalQuery</code> query from Delphyne's standard library. We show a concrete example of a generated prompt below:</p> Prompt Details <p>Here is an instance of the exact prompt that is generated for the second instance of <code>guess</code> that assigns a value to <code>equiv</code>.</p> <p>System Prompt:</p> <p>I am executing a program that contains nondeterministic assignments along with assertions (e.g., in the form of <code>ensure</code> and <code>fail</code> statements). I am stuck at one of these nondeterministic assignments and your goal is to generate an assigned value, in such a way that the program can go on and not fail any assertion.</p> <p>More specifically, I'll give you three pieces of information:</p> <ul> <li>A nondeterministic program.</li> <li>The name of the variable that is being assigned at the program location where I am currently stuck.</li> <li>Some values for a number of local variables.</li> </ul> <p>Your job is to generate a correct value to assign. The expected type of this value is indicated inside the nondeterministic assignment operator.</p> <p>Terminate your answer with a code block (delimited by triple backquotes) that contains a YAML object of the requested type. Do not wrap this YAML value into an object with a field named like the assigned variable.</p> <p>Instance Prompt:</p> <pre><code>Program:\n\n```\n@strategy\ndef find_param_value(expr: str) -&gt; Strategy[Branch | Fail, IPDict, int]:\n    \"\"\"\n    Find an integer parameter `n` that makes a given math expression\n    nonnegative for all real `x`. Then, prove that the resulting\n    expression is indeed nonnegative for all real `x` by rewriting it\n    into an equivalent form that makes this fact clear.\n    \"\"\"\n    x, n = sp.Symbol(\"x\", dummy=True, real=True), sp.Symbol(\"n\", dummy=True)\n    symbs = {\"x\": x, \"n\": n}\n    try:\n        n_val = yield from dp.guess(int, using=[expr])\n        expr_sp = sp.parse_expr(expr, symbs).subs({n: n_val})\n        equiv = yield from dp.guess(str, using=[str(expr_sp)])\n        equiv_sp = sp.parse_expr(equiv, symbs)\n        equivalent = (expr_sp - equiv_sp).simplify() == 0\n        yield from dp.ensure(equivalent, \"not_equivalent\")\n        yield from dp.ensure(equiv_sp.is_nonnegative, \"not_nonneg\")\n        return n_val\n    except Exception as e:\n        assert_never((yield from dp.fail(\"sympy_error\", message=str(e))))\n```\n\nVariable being currently assigned: equiv\n\nSelected local variables:\n\n```yaml\nstr(expr_sp): x**2 - 2*x + 1\n```\n\nType of value to generate (as a YAML object): &lt;class 'str'&gt;\n</code></pre>"},{"location":"manual/policies/","title":"Policy Language","text":"<p>Delphyne offers a layered API for defining policies. At a high level, policies can be specified by assembling standard components. At a lower level, atomic components can be defined using search stream combinators. We summarize the key concepts and abstractions underlying Delphyne's policy language below. Links are provided to the Reference for details.</p>"},{"location":"manual/policies/#key-concepts","title":"Key Concepts","text":"<ul> <li>Policy: a policy is a pair of a search policy and of an inner policy. Combining a strategy and a policy results in a search stream.</li> <li>Search Policy: a search policy is a function that takes a tree, a global policy environment and an inner policy as arguments and returns a search stream.</li> <li>Inner Policy: an object that associates some prompting policies and policies to all query and sub-strategy instances inside a strategy. Inner policies are typically instances of custom dataclasses but Python dictionaries can also be used, trading flexibility and static type safety in exchange for concision (see <code>IPDict</code>).</li> <li>Prompting Policy: a function that maps a query along with a global policy environment to a search stream (e.g. <code>few_shot</code>).</li> <li>Global Policy Environment: global environment accessible to all policies, which allows: fetching prompts and examples, caching LLM requests, generating traces and logs...</li> <li>Search Stream: a (possibly infinite) iterator of yielded solutions and resource management messages (requesting authorization for spending some resource budget or declaring actual resource consumption). Search streams follow the search stream protocol and can be assembled using standard combinators.</li> <li>Budget: a finite-support function from resource consumption metrics (e.g. number of requests, LLM API spending in dollars) to real values.</li> <li>Stream Transformer: a function that maps a search stream into another search stream (e.g. <code>with_budget</code> and <code>take</code>). Stream transformers can be composed with search policies, prompting policies and other stream transformers using <code>@</code>.</li> <li>Tree Transformer: a function that maps a tree into another one, possible with a different signature (e.g. <code>elim_compute</code>, <code>elim_messages</code>). Can be composed with search policies using <code>@</code> to modify their accepted signature.</li> </ul>"},{"location":"manual/policies/#defining-new-search-policies","title":"Defining New Search Policies","text":"<p>For examples of defining new search policies, we recommend inspecting the source code of <code>dfs</code>, <code>par_dfs</code> and <code>best_first_search</code>.</p>"},{"location":"manual/strategies/","title":"Strategy Language","text":"<p>Following the previous Overview chapter, we now provide more details on Delphyne's strategy language. We provide a quick overview of the most useful techniques and concepts and refer to the Reference for more details and explanations (follow the hypertext links).</p>"},{"location":"manual/strategies/#defining-strategies","title":"Defining Strategies","text":"<p>A strategy is a program with unresolved choice points, which can be reified into a search tree. Delphyne allows writing strategies as Python generators that yield internal tree nodes and receive associated actions in return. The <code>Strategy</code> type has three type parameters, corresponding to the strategy's signature (i.e., the type of nodes it can emit), its associated inner policy type and its return type. Strategy functions are typically defined via the <code>strategy</code> decorator, which creates functions that return <code>StrategyInstance</code> values, wrapping the underlying generator while adding some metadata and convenience methods (e.g., <code>using</code>).</p> <pre><code>@strategy # (1)!\ndef find_param_value(\n    expr: str) -&gt; Strategy[Branch | Fail, FindParamValueIP, int]: ...\n</code></pre> <ol> <li>Example from the previous chapter.</li> </ol> <p>Query functions can have arguments of arbitrary type (including functions). When launching strategies from commands and in the presence of type annotations, arguments are automatically unserialized using Pydantic. Thus, it is useful for top-level strategies to have serializable argument types that are properly annotated.</p> <p>Branching nodes can be yielded via the <code>branch</code> function:</p> <pre><code>def branch[P, T](cands: Opaque[P, T]) -&gt; Strategy[Branch, P, T]: ...\n</code></pre> <p>Crucially, <code>branch</code> does not take a query as an argument but an opaque space (<code>Opaque</code>). An opaque space can be seen as a mapping from the ambient inner policy to an iterator of values (more precisely, a search stream). Opaque spaces can be produced from queries or strategy instances, by mapping the ambient inner policy to a prompting policy or a policy respectively:</p> <pre><code>class Query[T]:\n    def using[Pout](self,\n        get_policy: Callable[[Pout], PromptingPolicy]) -&gt; Opaque[Pout, T]: ...\n\nclass StrategyInstance[N: Node, P, T]:\n    def using(self,\n        get_policy: Callable[[Pout], Policy[N, P]]) -&gt; Opaque[Pout, T]: ...\n</code></pre> <p>Importantly, search policies such as <code>dfs</code> are unaware of whether an opaque space originates from a query or a strategy. This guarantees modularity and allows queries to be transparently refined into dedicated strategies whenever more guidance is desired. Opaque spaces also allow queries with different signatures (i.e., yielding different kinds of tree nodes) to be composed, while being associated independent search policies.</p> <p>Strategy Inlining</p> <p>It is also possible to inline a strategy call within another strategy, provided that both strategies share the same signature and inner policy type. This can be done using the <code>inline</code> method, which unwraps a <code>StrategyInstance</code> value and gives access to the underlying generator.</p> <p>For an example of a strategy that branches over results of a sub-strategy, see the <code>prove_program_via_abduction_and_branching</code> strategy from the <code>find_invariants</code> example. In particular, see how doing so results in nested inner policy records.</p> Source for <code>examples/find_invariants/abduct_and_branch.py</code> <pre><code>\"\"\"\nA simple Delphyne strategy to discover loop invariants with Why3.\n\"\"\"\n\nfrom collections.abc import Callable, Sequence\nfrom dataclasses import dataclass\n\nimport delphyne as dp\nfrom delphyne import Branch, Compute, Fail, Strategy, Value, strategy\n\nimport why3_utils as why3\n\n# fmt: off\n\n\n#####\n##### Inner Policy Types\n#####\n\n\n@dataclass\nclass ProposeInvsIP:\n    propose: dp.PromptingPolicy\n    novel: dp.PromptingPolicy\n\n\n@dataclass\nclass ProveProgIP:\n    propose: \"dp.Policy[Branch | Fail, ProposeInvsIP]\"\n    eval: dp.PromptingPolicy\n    quantify_eval: \"Callable[[ProofStateMetrics], float] | None\"\n\n\n#####\n##### Type Definitions\n#####\n\n\n@dataclass\nclass ProofStateMetrics:\n    has_redundant_invs: bool\n\n\ntype Proposal = Sequence[why3.Formula]\n\n\ntype Blacklist = Sequence[Proposal]\n\n\n\n#####\n##### Strategies\n#####\n\n\n@strategy\ndef prove_program_via_abduction_and_branching(\n    prog: why3.File,\n) -&gt; Strategy[Branch | Value | Fail | Compute, ProveProgIP, why3.File]:\n    annotated: why3.File = prog\n    while True:\n        feedback = yield from dp.compute(why3.check, prog, annotated)\n        yield from dp.ensure(feedback.error is None, \"invalid program\")\n        if feedback.success:\n            return annotated\n        remaining = [o for o in feedback.obligations if not o.proved]\n        yield from dp.ensure(\n            len(remaining) == 1, \"too many remaining obligations\")\n        unproved = remaining[0]\n        yield from dp.ensure(\n            not why3.invariant_init_obligation(unproved), \"init\")\n        if annotated != prog:  # if invariant annotations are present\n            yield from dp.value(\n                EvaluateProofState(unproved)\n                    .using(lambda p: p.eval, ProveProgIP),\n                lambda p: p.quantify_eval)\n        new_invariants = yield from dp.branch(\n            dp.iterate(\n                lambda prior:\n                    propose_invariants(unproved, prior)\n                        .using(lambda p: p.propose, ProveProgIP)))\n        annotated = why3.add_invariants(annotated, new_invariants)\n\n\n@strategy\ndef propose_invariants(\n    obligation: why3.Obligation,\n    blacklist: Sequence[Proposal] | None,\n) -&gt; Strategy[Branch | Fail, ProposeInvsIP, tuple[Proposal, Blacklist]]:\n    if blacklist is None:\n        blacklist = []\n    proposal = yield from dp.branch(\n        ProposeInvariants(obligation, blacklist)\n            .using(lambda p: p.propose, ProposeInvsIP))\n    sanity_check = all(why3.no_invalid_formula_symbol(inv) for inv in proposal)\n    yield from dp.ensure(sanity_check, \"sanity check failed\")\n    if blacklist:\n        novel = yield from dp.branch(\n            IsProposalNovel(proposal, blacklist)\n                .using(lambda p: p.novel, ProposeInvsIP))\n        yield from dp.ensure(novel, \"proposal is not novel\")\n    return proposal, [*blacklist, proposal]\n\n\n#####\n##### Queries\n#####\n\n\n@dataclass\nclass ProposeInvariants(dp.Query[Proposal]):\n    unproved: why3.Obligation\n    blacklist: Sequence[Proposal]\n\n    __parser__ = dp.last_code_block.yaml\n\n\n@dataclass\nclass IsProposalNovel(dp.Query[bool]):\n    proposal: Proposal\n    blacklist: Sequence[Proposal]\n\n    __parser__ = dp.last_code_block.yaml\n\n\n@dataclass\nclass EvaluateProofState(dp.Query[ProofStateMetrics]):\n    unproved: why3.Obligation\n\n    __parser__ = dp.last_code_block.yaml\n\n\n#####\n##### Policies\n#####\n\n\ndef prove_program_via_abduction_and_branching_policy(\n    fancy_model: str = \"gpt-4o\",\n    base_model: str = \"gpt-4o\",\n    max_depth: int = 2,\n    max_requests_per_proposal: int = 5,\n    root_proposal_penalty: float = 0.7,\n    nonroot_proposal_penalty: float = 1.0,\n    max_nonroot_proposals: int = 3,\n    enable_state_evaluation: bool = False,\n    min_value: float = 0.3,\n) -&gt; dp.Policy[Branch | Value | Fail | Compute, ProveProgIP]:\n\n    def compute_value(metrics: ProofStateMetrics) -&gt; float:\n        prob = 1\n        if metrics.has_redundant_invs:\n            prob = 0\n        return max(min_value, prob)\n\n    def child_confidence_prior(depth: int, prev_gen: int) -&gt; float:\n        if depth &gt;= 1:\n            if prev_gen &gt;= max_nonroot_proposals:\n                return 0\n            return nonroot_proposal_penalty ** prev_gen\n        return root_proposal_penalty ** prev_gen\n\n    n = dp.NUM_REQUESTS\n    fancy = dp.openai_model(fancy_model)\n    base = dp.openai_model(base_model)\n\n    propose_ip = ProposeInvsIP(\n        propose=dp.few_shot(fancy),\n        novel=dp.take(1) @ dp.few_shot(base),\n    )\n    proposal_limit = dp.BudgetLimit({n: max_requests_per_proposal})\n    prove_prog_ip = ProveProgIP(\n        propose=dp.with_budget(proposal_limit) @ dp.dfs() &amp; propose_ip,\n        eval=dp.take(1) @ dp.few_shot(base),\n        quantify_eval=compute_value if enable_state_evaluation else None,\n    )\n    bestfs = dp.best_first_search(\n        child_confidence_prior=child_confidence_prior,\n        max_depth=max_depth)\n\n    return bestfs @ dp.elim_compute() &amp; prove_prog_ip\n</code></pre>"},{"location":"manual/strategies/#queries","title":"Queries","text":"<p>New query types can be defined by subclassing the <code>Query</code> class. We refer to the associated API documentation for details. Some highlights:</p> <ul> <li>Queries can be associated system prompts and instance prompts. Prompts can be defined inline or in separate Jinja files (see <code>find_invariants</code> example).</li> <li>Query types can have fields of any type as long as they can be serialized and unserialized using Pydantic (this includes custom dataclasses).</li> <li>Prompts can be parameterized, and parameters instantiated on the policy side (e.g., <code>params</code> argument of <code>few_shot</code>). This is useful for testing prompt variations, specializing specific prompt fragments for particular, etc...</li> <li>It is possible to define several answer modes for a query, each mode being associated a distinct parser (see <code>tests/example_strategies.py:GetFavoriteDish</code> for an example).</li> <li>Queries support structured output and tool calls.</li> </ul>"},{"location":"manual/strategies/#trees-and-reification","title":"Trees and Reification","text":"<p>Strategies can be reified (i.e. compiled) into trees using the <code>reify</code> function (see reference documentation for details and caveats). The <code>Tree</code> class is defined as follows:</p> <pre><code>@dataclass(frozen=True)\nclass Tree[N: Node, P, T]:\n    node: N | Success[T]\n    child: Callable[[Value], Tree[N, P, T]]\n    ref: GlobalNodePath # (1)!\n</code></pre> <ol> <li>To ignore on first reading. See documentation on references.</li> </ol> <p>A tree contains either a node (<code>Node</code>) or a success leaf (<code>Node</code>). When applicable, children trees are indexed by actions (<code>Value</code>). Actions result from combining elements of local spaces (<code>Space</code>). For example, if <code>node</code> has type <code>Branch</code>, then an action corresponds to a branching candidate.</p>"},{"location":"manual/strategies/#adding-new-effects","title":"Adding New Effects","text":"<p>New types of effects beyond <code>Branch</code> and <code>Fail</code> can be added easily, by subclassing <code>Node</code>. Here are a number of additional effects defined in the Delphyne standard library:</p> <ul> <li><code>Join</code>: allows evaluating a sequence of independent sub-strategies, possibly in parallel.</li> <li><code>Compute</code>: allows performing expensive and possibly non-replicable/nondeterministic computations in strategies (see details in How-To Guide).</li> <li><code>Value</code>: allows adding value information into strategy trees. Such information can be leveraged by search policies (e.g. <code>best_first_search</code>).</li> <li><code>Flag</code>: allows providing a finite number of alternative implementations for sub-tasks, to be selected either offline or at runtime.</li> <li><code>Message</code>: allows decorating trees with debugging messages.</li> </ul> <p>Node types are dataclasses whose fields can be of several kinds:</p> <ul> <li>Nonparametric local spaces (<code>Space</code>), the main types of which are opaque spaces (<code>OpaqueSpace</code>) and embedded trees (<code>EmbeddedTree</code>).</li> <li>Parametric local spaces, which are functions from local values (i.e. assembly of elements from local spaces) to local spaces.</li> <li>Data fields that contain policy metadata, debugging information, etc...</li> </ul> <p>More details are available in the API Reference. For examples of defining new effects, you can refer to the source code of the aforementioned effects in the Delphyne standard library (in the <code>delphyne.stdlib.nodes</code> module).</p>"},{"location":"reference/cli/","title":"Delphyne Command Line Interface","text":""},{"location":"reference/cli/#delphyne.__main__.DelphyneCLI","title":"DelphyneCLI","text":"<p>The Delphyne Command Line Interface.</p> <p>The <code>delphyne</code> package features a <code>delphyne</code> command line application that is automatically generated from the <code>DelphyneCLI</code> class using fire. In particular, this application can be used to check demonstration files, execute command files, and launch the Delphyne language server.</p> Source code in <code>src/delphyne/__main__.py</code> <pre><code>class DelphyneCLI:\n    \"\"\"\n    The Delphyne Command Line Interface.\n\n    The `delphyne` package features a `delphyne` command line\n    application that is automatically generated from the `DelphyneCLI`\n    class using [fire](https://github.com/google/python-fire). In\n    particular, this application can be used to check demonstration\n    files, execute command files, and launch the Delphyne language\n    server.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        workspace_dir: Path | None = None,\n        ensure_no_error: bool = False,\n        ensure_no_warning: bool = False,\n    ):\n        \"\"\"\n        Arguments:\n            workspace_dir: The workspace directory. If not provided, it\n                is deduced for each demonstration or command file by\n                considering the closest transitive parent directory that\n                contains a `delphyne.yaml` file. If no such directory\n                exists, the current working directory is used.\n            ensure_no_error: Exit with a nonzero code if an error is\n                produced.\n            ensure_no_warning: Exit with a nonzero code if a warning is\n                produced.\n        \"\"\"\n        self.workspace_dir = workspace_dir\n        self.ensure_no_error = ensure_no_error\n        self.ensure_no_warning = ensure_no_warning\n\n    def _process_diagnostics(\n        self,\n        warnings: list[str],\n        errors: list[str],\n        use_stderr: bool = False,\n        show_summary: bool = True,\n    ):\n        show = partial(print, file=sys.stderr if use_stderr else sys.stdout)\n        num_errors = len(errors)\n        num_warnings = len(warnings)\n        if show_summary:\n            show(f\"{num_errors} error(s), {num_warnings} warning(s)\")\n        if errors or warnings:\n            show(\"\")\n        for e in errors:\n            show(f\"Error: {e}\")\n        for w in warnings:\n            show(f\"Warning: {w}\")\n        if self.ensure_no_error and num_errors &gt; 0:\n            exit(1)\n        if self.ensure_no_warning and num_warnings &gt; 0:\n            exit(1)\n\n    def _workspace_dir_for(self, file: Path) -&gt; Path:\n        \"\"\"\n        Get the workspace directory for a given file.\n        \"\"\"\n        workspace_dir = self.workspace_dir\n        if workspace_dir is None:\n            workspace_dir = find_workspace_dir(file)\n        if workspace_dir is None:\n            workspace_dir = Path.cwd()\n        return workspace_dir\n\n    def check(self, file: str):\n        \"\"\"\n        Check a demonstration file.\n        \"\"\"\n        file_path = Path(file)\n        workspace_dir = self._workspace_dir_for(file_path)\n        config = load_config(workspace_dir, local_config_from=file_path)\n        feedback = check_demo_file(\n            file_path, config.strategy_dirs, config.modules\n        )\n        self._process_diagnostics(feedback.warnings, feedback.errors)\n\n    def run(\n        self,\n        file: str,\n        *,\n        cache: bool = False,\n        update: bool = False,\n        no_output: bool = False,\n        no_header: bool = False,\n        no_status: bool = False,\n        filter: list[str] | None = None,\n        clear: bool = False,\n    ):\n        \"\"\"\n        Execute a command file.\n\n        Print an updated command file with an `outcome` section added on\n        stdout. Print other information on stderr.\n\n        Arguments:\n            file: Path to the command file to execute.\n            cache: Enable caching (assuming the command supports it).\n            update: Update the command file in place with the outcome.\n            no_output: Do not print on stdout.\n            no_header: Only print the `outcome` section on stdout.\n            no_status: Do not show the progress bar.\n            filter: Only show the provided subset of fields for the\n                `outcome.result` section.\n            clear: When this option is passed, all other options are\n                ignored and the `clear` method is called.\n        \"\"\"\n        file_path = Path(file)\n        workspace_dir = self._workspace_dir_for(file_path)\n        config = load_config(workspace_dir, local_config_from=file_path)\n        config = replace(\n            config,\n            status_refresh_period=STATUS_REFRESH_PERIOD_IN_SECONDS,\n            result_refresh_period=None,\n        )\n        if clear:\n            self.clear(file)\n            return\n        if update:\n            no_output = True\n            no_header = False\n        if cache and not config.cache_root:\n            config = replace(config, cache_root=file_path.parent / \"cache\")\n        with open(file, \"r\") as f:\n            spec = ty.pydantic_load(CommandSpec, yaml.safe_load(f))\n        cmd, args = spec.load(config.base)\n        if cache:\n            assert hasattr(args, \"cache_dir\"), (\n                \"Command does not have a `cache_dir` argument.\"\n            )\n            assert hasattr(args, \"cache_format\"), (\n                \"Command does not have a `cache_format` argument.\"\n            )\n            if not args.cache_dir:\n                args.cache_dir = file_path.stem\n            args.cache_format = \"db\"\n        progress = StatusIndicator(sys.stderr, show=not no_status)\n        res = std.run_command(cmd, args, config, on_status=progress.on_status)\n        progress.done()\n        res_type = std.command_optional_result_wrapper_type(cmd)\n        res_python: Any = ty.pydantic_dump(res_type, res)\n        if filter and res_python[\"result\"] is not None:\n            res_python[\"result\"] = {\n                k: v for k, v in res_python[\"result\"].items() if k in filter\n            }\n        if no_header:\n            output = pretty_yaml(res_python)\n        else:\n            with open(file_path, \"r\") as f:\n                header = command_file_header(f.read())\n            output = header.rstrip() + \"\\n\"\n            output += pretty_yaml({\"outcome\": res_python})\n        if not no_output:\n            print(output)\n        if update:\n            with open(file_path, \"w\") as f:\n                f.write(output)\n        errors = [d[1] for d in res.diagnostics if d[0] == \"error\"]\n        warnings = [d[1] for d in res.diagnostics if d[0] == \"warning\"]\n        self._process_diagnostics(\n            warnings,\n            errors,\n            use_stderr=True,\n            show_summary=self.ensure_no_error or self.ensure_no_warning,\n        )\n\n    def clear(self, file: str):\n        \"\"\"\n        Clear the outcome of a command file by updating it in place.\n        \"\"\"\n        path = Path(file)\n        with open(path, \"r\") as f:\n            content = f.read()\n        new_content = command_file_header(content)\n        with open(path, \"w\") as f:\n            f.write(new_content)\n\n    def serve(self, *, port: int = 3008):\n        \"\"\"\n        Launch an instance of the Delphyne language server.\n        \"\"\"\n        from delphyne.server.__main__ import main\n\n        main(port=port)\n</code></pre>"},{"location":"reference/cli/#delphyne.__main__.DelphyneCLI.__init__","title":"__init__","text":"<pre><code>__init__(\n    *,\n    workspace_dir: Path | None = None,\n    ensure_no_error: bool = False,\n    ensure_no_warning: bool = False,\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>workspace_dir</code> <code>Path | None</code> <p>The workspace directory. If not provided, it is deduced for each demonstration or command file by considering the closest transitive parent directory that contains a <code>delphyne.yaml</code> file. If no such directory exists, the current working directory is used.</p> <code>None</code> <code>ensure_no_error</code> <code>bool</code> <p>Exit with a nonzero code if an error is produced.</p> <code>False</code> <code>ensure_no_warning</code> <code>bool</code> <p>Exit with a nonzero code if a warning is produced.</p> <code>False</code> Source code in <code>src/delphyne/__main__.py</code> <pre><code>def __init__(\n    self,\n    *,\n    workspace_dir: Path | None = None,\n    ensure_no_error: bool = False,\n    ensure_no_warning: bool = False,\n):\n    \"\"\"\n    Arguments:\n        workspace_dir: The workspace directory. If not provided, it\n            is deduced for each demonstration or command file by\n            considering the closest transitive parent directory that\n            contains a `delphyne.yaml` file. If no such directory\n            exists, the current working directory is used.\n        ensure_no_error: Exit with a nonzero code if an error is\n            produced.\n        ensure_no_warning: Exit with a nonzero code if a warning is\n            produced.\n    \"\"\"\n    self.workspace_dir = workspace_dir\n    self.ensure_no_error = ensure_no_error\n    self.ensure_no_warning = ensure_no_warning\n</code></pre>"},{"location":"reference/cli/#delphyne.__main__.DelphyneCLI.check","title":"check","text":"<pre><code>check(file: str)\n</code></pre> <p>Check a demonstration file.</p> Source code in <code>src/delphyne/__main__.py</code> <pre><code>def check(self, file: str):\n    \"\"\"\n    Check a demonstration file.\n    \"\"\"\n    file_path = Path(file)\n    workspace_dir = self._workspace_dir_for(file_path)\n    config = load_config(workspace_dir, local_config_from=file_path)\n    feedback = check_demo_file(\n        file_path, config.strategy_dirs, config.modules\n    )\n    self._process_diagnostics(feedback.warnings, feedback.errors)\n</code></pre>"},{"location":"reference/cli/#delphyne.__main__.DelphyneCLI.run","title":"run","text":"<pre><code>run(\n    file: str,\n    *,\n    cache: bool = False,\n    update: bool = False,\n    no_output: bool = False,\n    no_header: bool = False,\n    no_status: bool = False,\n    filter: list[str] | None = None,\n    clear: bool = False,\n)\n</code></pre> <p>Execute a command file.</p> <p>Print an updated command file with an <code>outcome</code> section added on stdout. Print other information on stderr.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>Path to the command file to execute.</p> required <code>cache</code> <code>bool</code> <p>Enable caching (assuming the command supports it).</p> <code>False</code> <code>update</code> <code>bool</code> <p>Update the command file in place with the outcome.</p> <code>False</code> <code>no_output</code> <code>bool</code> <p>Do not print on stdout.</p> <code>False</code> <code>no_header</code> <code>bool</code> <p>Only print the <code>outcome</code> section on stdout.</p> <code>False</code> <code>no_status</code> <code>bool</code> <p>Do not show the progress bar.</p> <code>False</code> <code>filter</code> <code>list[str] | None</code> <p>Only show the provided subset of fields for the <code>outcome.result</code> section.</p> <code>None</code> <code>clear</code> <code>bool</code> <p>When this option is passed, all other options are ignored and the <code>clear</code> method is called.</p> <code>False</code> Source code in <code>src/delphyne/__main__.py</code> <pre><code>def run(\n    self,\n    file: str,\n    *,\n    cache: bool = False,\n    update: bool = False,\n    no_output: bool = False,\n    no_header: bool = False,\n    no_status: bool = False,\n    filter: list[str] | None = None,\n    clear: bool = False,\n):\n    \"\"\"\n    Execute a command file.\n\n    Print an updated command file with an `outcome` section added on\n    stdout. Print other information on stderr.\n\n    Arguments:\n        file: Path to the command file to execute.\n        cache: Enable caching (assuming the command supports it).\n        update: Update the command file in place with the outcome.\n        no_output: Do not print on stdout.\n        no_header: Only print the `outcome` section on stdout.\n        no_status: Do not show the progress bar.\n        filter: Only show the provided subset of fields for the\n            `outcome.result` section.\n        clear: When this option is passed, all other options are\n            ignored and the `clear` method is called.\n    \"\"\"\n    file_path = Path(file)\n    workspace_dir = self._workspace_dir_for(file_path)\n    config = load_config(workspace_dir, local_config_from=file_path)\n    config = replace(\n        config,\n        status_refresh_period=STATUS_REFRESH_PERIOD_IN_SECONDS,\n        result_refresh_period=None,\n    )\n    if clear:\n        self.clear(file)\n        return\n    if update:\n        no_output = True\n        no_header = False\n    if cache and not config.cache_root:\n        config = replace(config, cache_root=file_path.parent / \"cache\")\n    with open(file, \"r\") as f:\n        spec = ty.pydantic_load(CommandSpec, yaml.safe_load(f))\n    cmd, args = spec.load(config.base)\n    if cache:\n        assert hasattr(args, \"cache_dir\"), (\n            \"Command does not have a `cache_dir` argument.\"\n        )\n        assert hasattr(args, \"cache_format\"), (\n            \"Command does not have a `cache_format` argument.\"\n        )\n        if not args.cache_dir:\n            args.cache_dir = file_path.stem\n        args.cache_format = \"db\"\n    progress = StatusIndicator(sys.stderr, show=not no_status)\n    res = std.run_command(cmd, args, config, on_status=progress.on_status)\n    progress.done()\n    res_type = std.command_optional_result_wrapper_type(cmd)\n    res_python: Any = ty.pydantic_dump(res_type, res)\n    if filter and res_python[\"result\"] is not None:\n        res_python[\"result\"] = {\n            k: v for k, v in res_python[\"result\"].items() if k in filter\n        }\n    if no_header:\n        output = pretty_yaml(res_python)\n    else:\n        with open(file_path, \"r\") as f:\n            header = command_file_header(f.read())\n        output = header.rstrip() + \"\\n\"\n        output += pretty_yaml({\"outcome\": res_python})\n    if not no_output:\n        print(output)\n    if update:\n        with open(file_path, \"w\") as f:\n            f.write(output)\n    errors = [d[1] for d in res.diagnostics if d[0] == \"error\"]\n    warnings = [d[1] for d in res.diagnostics if d[0] == \"warning\"]\n    self._process_diagnostics(\n        warnings,\n        errors,\n        use_stderr=True,\n        show_summary=self.ensure_no_error or self.ensure_no_warning,\n    )\n</code></pre>"},{"location":"reference/cli/#delphyne.__main__.DelphyneCLI.clear","title":"clear","text":"<pre><code>clear(file: str)\n</code></pre> <p>Clear the outcome of a command file by updating it in place.</p> Source code in <code>src/delphyne/__main__.py</code> <pre><code>def clear(self, file: str):\n    \"\"\"\n    Clear the outcome of a command file by updating it in place.\n    \"\"\"\n    path = Path(file)\n    with open(path, \"r\") as f:\n        content = f.read()\n    new_content = command_file_header(content)\n    with open(path, \"w\") as f:\n        f.write(new_content)\n</code></pre>"},{"location":"reference/cli/#delphyne.__main__.DelphyneCLI.serve","title":"serve","text":"<pre><code>serve(*, port: int = 3008)\n</code></pre> <p>Launch an instance of the Delphyne language server.</p> Source code in <code>src/delphyne/__main__.py</code> <pre><code>def serve(self, *, port: int = 3008):\n    \"\"\"\n    Launch an instance of the Delphyne language server.\n    \"\"\"\n    from delphyne.server.__main__ import main\n\n    main(port=port)\n</code></pre>"},{"location":"reference/demos/definitions/","title":"Definition of Demonstrations","text":""},{"location":"reference/demos/definitions/#demonstration-files","title":"Demonstration Files","text":""},{"location":"reference/demos/definitions/#delphyne.core.demos","title":"delphyne.core.demos","text":"<p>Delphyne Demonstrations.</p> <p>A demonstration file can be directly parsed as a value of type <code>DemoFile</code>. Thus, field names are optimized to make for a pleasant YAML syntax.</p>"},{"location":"reference/demos/definitions/#delphyne.core.demos.DemoFile","title":"DemoFile","text":"<pre><code>DemoFile = list[Demo]\n</code></pre> <p>A demonstration file is a sequence of demonstrations. Demonstrations are independent and can thus be separately evaluted.</p>"},{"location":"reference/demos/definitions/#delphyne.core.demos.Demo","title":"Demo","text":"<pre><code>Demo = QueryDemo | StrategyDemo\n</code></pre> <p>A demonstration is either a standalone query demonstration or a strategy demonstration.</p>"},{"location":"reference/demos/definitions/#delphyne.core.demos.StrategyDemo","title":"StrategyDemo  <code>dataclass</code>","text":"<p>A strategy demonstration.</p> <p>For a given strategy instance, a strategy demonstration gathers a sequence of relevant query demonstrations, along with a sequence of unit tests that combine them into coherent scenarios of navigating the strategy tree.</p> <p>Attributes:</p> Name Type Description <code>strategy</code> <code>str</code> <p>The name of the strategy function.</p> <code>args</code> <code>dict[str, Any]</code> <p>Arguments to pass to the strategy function.</p> <code>tests</code> <code>list[TestCommandString]</code> <p>A sequence of unit tests that describe navigation scenarios in the strategy tree.</p> <code>queries</code> <code>list[QueryDemo]</code> <p>A sequence of query demonstrations. Featured answers are used when executing the tests.</p> <code>demonstration</code> <code>str | None</code> <p>An optional label for the demonstration (usually specified first in YAML syntax)</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass\nclass StrategyDemo:\n    \"\"\"\n    A strategy demonstration.\n\n    For a given strategy instance, a strategy demonstration gathers a\n    sequence of relevant query demonstrations, along with a sequence of\n    unit tests that combine them into coherent scenarios of navigating\n    the strategy tree.\n\n    Attributes:\n        strategy: The name of the strategy function.\n        args: Arguments to pass to the strategy function.\n        tests: A sequence of unit tests that describe navigation\n            scenarios in the strategy tree.\n        queries: A sequence of query demonstrations. Featured answers\n            are used when executing the tests.\n        demonstration: An optional label for the demonstration (usually\n            specified first in YAML syntax)\n    \"\"\"\n\n    strategy: str\n    args: dict[str, Any]\n    tests: list[TestCommandString]\n    queries: list[QueryDemo]\n    demonstration: str | None = None  # optional label\n</code></pre>"},{"location":"reference/demos/definitions/#delphyne.core.demos.QueryDemo","title":"QueryDemo  <code>dataclass</code>","text":"<p>A query demonstration.</p> <p>A query demonstration describes a query and associates answers to it. It can stand alone in a demonstration file, or be part of a strategy demonstration.</p> <p>Attributes:</p> Name Type Description <code>query</code> <code>str</code> <p>The query name.</p> <code>args</code> <code>dict[str, Any]</code> <p>The query arguments.</p> <code>answers</code> <code>list[Answer]</code> <p>A sequence of quer answers.</p> <code>demonstration</code> <code>str | None</code> <p>For standalone query demonstrations, an optional demonstration label (usully specified first in YAML syntax).</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass\nclass QueryDemo:\n    \"\"\"\n    A query demonstration.\n\n    A query demonstration describes a query and associates answers to\n    it. It can stand alone in a demonstration file, or be part of a\n    strategy demonstration.\n\n    Attributes:\n        query: The query name.\n        args: The query arguments.\n        answers: A sequence of quer answers.\n        demonstration: For standalone query demonstrations, an optional\n            demonstration label (usully specified first in YAML syntax).\n    \"\"\"\n\n    query: str\n    args: dict[str, Any]\n    answers: list[Answer]\n    demonstration: str | None = None  # optional label\n</code></pre>"},{"location":"reference/demos/definitions/#delphyne.core.demos.Answer","title":"Answer  <code>dataclass</code>","text":"<p>A query answer.</p> <p>Attributes:</p> Name Type Description <code>answer</code> <code>str | object</code> <p>The answer content, which can be a string or a structured JSON object. When a string is provided, the <code>structured</code> field is used to desambiguate whether or not the content should be interpreted as structured data.</p> <code>call</code> <code>Sequence[ToolCall]</code> <p>A sequence of tool calls. mode: the answer mode (<code>None</code> by default), which determines in particular how the answer must be parsed.</p> <code>label</code> <code>str | None</code> <p>An optional label for the answer, which can be referenced in demonstration tests.</p> <code>example</code> <code>bool | None</code> <p>A boolean value indicating whether the answer should be usable as a few-shot exmple (some answers are only used s negative examples or to describe alternative paths in the strategy tree and thus should not be used as examples).</p> <code>tags</code> <code>Sequence[str]</code> <p>A sequence of example tags that can be used by policies to select appropriate examples.</p> <code>justification</code> <code>str | None</code> <p>An optional justification for the answer (see <code>delphyne.core.refs.Answer</code>).</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass\nclass Answer:\n    \"\"\"\n    A query answer.\n\n    Attributes:\n        answer: The answer content, which can be a string or a\n            structured JSON object. When a string is provided, the\n            `structured` field is used to desambiguate whether or not the\n            content should be interpreted as structured data.\n        call: A sequence of tool calls. mode: the answer mode (`None` by\n            default), which determines in particular how the answer must\n            be parsed.\n        label: An optional label for the answer, which can be referenced\n            in demonstration tests.\n        example: A boolean value indicating whether the answer should be\n            usable as a few-shot exmple (some answers are only used s\n            negative examples or to describe alternative paths in the\n            strategy tree and thus should not be used as examples).\n        tags: A sequence of example tags that can be used by policies to\n            select appropriate examples.\n        justification: An optional justification for the answer (see\n            [`delphyne.core.refs.Answer`][]).\n    \"\"\"\n\n    answer: str | object\n    call: Sequence[ToolCall] = ()\n    structured: Literal[\"auto\", True] = \"auto\"\n    mode: str | None = None\n    label: str | None = None\n    example: bool | None = None\n    tags: Sequence[str] = ()\n    justification: str | None = None\n</code></pre>"},{"location":"reference/demos/definitions/#delphyne.core.demos.ToolCall","title":"ToolCall  <code>dataclass</code>","text":"<p>A tool call, as a part of a query answer.</p> <p>Attributes:</p> Name Type Description <code>tool</code> <code>str</code> <p>The name of the tool to call.</p> <code>args</code> <code>dict[str, Any]</code> <p>The arguments to pass to the tool.</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass\nclass ToolCall:\n    \"\"\"\n    A tool call, as a part of a query answer.\n\n    Attributes:\n        tool: The name of the tool to call.\n        args: The arguments to pass to the tool.\n    \"\"\"\n\n    tool: str\n    args: dict[str, Any]\n</code></pre>"},{"location":"reference/demos/definitions/#delphyne.core.demos.TestCommandString","title":"TestCommandString","text":"<pre><code>TestCommandString = str\n</code></pre> <p>A non-parsed test command (<code>TestCommand</code>).</p>"},{"location":"reference/demos/definitions/#demonstration-tests","title":"Demonstration Tests","text":""},{"location":"reference/demos/definitions/#delphyne.core.demos.TestCommand","title":"TestCommand","text":"<pre><code>TestCommand = Sequence[TestStep]\n</code></pre> <p>A test command is a sequence of test instructions.</p> <p>It describes a path in the strategy tree, starting from the root and reaching a destination node. A test can succeed, error or be stuck (i.e., reach a node where it cannot make further progress due to a missing answer in the <code>queries</code> section). It can also emit various warnings (i.e., a hint was not used).</p>"},{"location":"reference/demos/definitions/#delphyne.core.demos.TestStep","title":"TestStep","text":"<pre><code>TestStep = Run | IsSuccess | IsFailure | SelectSpace | Save | Load\n</code></pre> <p>A test instruction.</p> <p>Each instruction updates the current node position in the strategy tree. In addition, instructions can error or get stuck.</p>"},{"location":"reference/demos/definitions/#delphyne.core.demos.Run","title":"Run  <code>dataclass</code>","text":"<p>Walk through the tree, using local node navigation functions along with the content of the demonstration's <code>query</code> section to answer queries.</p> <p>Depending on whether <code>until</code> is provided, this corresponds to either the \"run\" or \"at\" instruction in concrete syntax.</p> Attributed <p>hints: Whenever a query must be answered, the first answer     provided in the <code>query</code> section is used, unless an answer     whose label matches the first remaining hint exists, in     which case it is used insted and the hint is consumed. This     mechanism allows concisely describing alternative paths in     the tree that only differ from the default path in a small     number of key decisions. until: When provided, the walk stops when the current node     matches the provided description (see <code>NodeSelector</code>).</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass\nclass Run:\n    \"\"\"\n    Walk through the tree, using local node navigation functions along\n    with the content of the demonstration's `query` section to answer\n    queries.\n\n    Depending on whether `until` is provided, this corresponds to either\n    the \"run\" or \"at\" instruction in concrete syntax.\n\n    Attributed:\n        hints: Whenever a query must be answered, the first answer\n            provided in the `query` section is used, unless an answer\n            whose label matches the first remaining hint exists, in\n            which case it is used insted and the hint is consumed. This\n            mechanism allows concisely describing alternative paths in\n            the tree that only differ from the default path in a small\n            number of key decisions.\n        until: When provided, the walk stops when the current node\n            matches the provided description (see `NodeSelector`).\n    \"\"\"\n\n    hints: Sequence[Hint]\n    until: NodeSelector | None\n</code></pre>"},{"location":"reference/demos/definitions/#delphyne.core.demos.IsSuccess","title":"IsSuccess  <code>dataclass</code>","text":"<p>Do not move but fail if the current node is not a success leaf.</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass\nclass IsSuccess:\n    \"\"\"\n    Do not move but fail if the current node is *not* a success leaf.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/demos/definitions/#delphyne.core.demos.IsFailure","title":"IsFailure  <code>dataclass</code>","text":"<p>Do not move but fail if the current node is not a failure node (i.e., a leaf node that is not a success leaf).</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass\nclass IsFailure:\n    \"\"\"\n    Do not move but fail if the current node is *not* a failure node\n    (i.e., a leaf node that is not a success leaf).\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/demos/definitions/#delphyne.core.demos.SelectSpace","title":"SelectSpace  <code>dataclass</code>","text":"<p>Select a particular local space of the current node, using a hint-based reference.</p> <p>Depending on the value of <code>expects_query</code>, this corresponds to either the \"go\" or the \"answer\" instruction in concrete syntax.</p> <p>Attributes:</p> Name Type Description <code>space</code> <code>SpaceRef</code> <p>Local, hint-based reference for the space to select.</p> <code>expects_query</code> <code>bool</code> <p>Whether the space is expected to be induced by a query. When true, the current node position is left unchanged and the instruction fails if the selected space is not induced by a query or if this query is not answered. When set to false, the current node position is updated to the root of the tree inducing the selected space (the instruction fails if this space is induced by a query).</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass\nclass SelectSpace:\n    \"\"\"\n    Select a particular local space of the current node, using a\n    hint-based reference.\n\n    Depending on the value of `expects_query`, this corresponds to\n    either the \"go\" or the \"answer\" instruction in concrete syntax.\n\n    Attributes:\n        space: Local, hint-based reference for the space to select.\n        expects_query: Whether the space is expected to be induced by a\n            query. When true, the current node position is left\n            unchanged and the instruction fails if the selected space is\n            not induced by a query or if this query is not answered.\n            When set to false, the current node position is updated to\n            the root of the tree inducing the selected space (the\n            instruction fails if this space is induced by a query).\n    \"\"\"\n\n    space: SpaceRef\n    expects_query: bool\n</code></pre>"},{"location":"reference/demos/definitions/#delphyne.core.demos.Save","title":"Save  <code>dataclass</code>","text":"<p>Save the current node under a given name.</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass\nclass Save:\n    \"\"\"\n    Save the current node under a given name.\n    \"\"\"\n\n    name: str\n</code></pre>"},{"location":"reference/demos/definitions/#delphyne.core.demos.Load","title":"Load  <code>dataclass</code>","text":"<p>Go to a tree node that was previously saved under a given name.</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass\nclass Load:\n    \"\"\"\n    Go to a tree node that was previously saved under a given name.\n    \"\"\"\n\n    name: str\n</code></pre>"},{"location":"reference/demos/definitions/#node-and-space-selectors","title":"Node and Space Selectors","text":""},{"location":"reference/demos/definitions/#delphyne.core.demos.NodeSelector","title":"NodeSelector","text":"<pre><code>NodeSelector = TagSelectors | WithinSpace\n</code></pre> <p>Describes a node as a path of tags from the current tree.</p> <p>A node selector either denotes a node that matches a series of tags in the surrounding tree (<code>TagSelectors</code>), or a node within nested tree, which induces a space that is itself described by a series of tags (<code>WithinSpace</code>).</p>"},{"location":"reference/demos/definitions/#delphyne.core.demos.TagSelectors","title":"TagSelectors","text":"<pre><code>TagSelectors = Sequence[TagSelector]\n</code></pre> <p>A series of tag selectors that must all be matched.</p> <p>Tag selectors apply to either nodes or spaces.</p>"},{"location":"reference/demos/definitions/#delphyne.core.demos.TagSelector","title":"TagSelector  <code>dataclass</code>","text":"<p>A tag selector consists in a tag along with an optional occurence number.</p> <p>Attributes:</p> Name Type Description <code>tag</code> <code>str</code> <p>The tag to match.</p> <code>num</code> <code>int | None</code> <p>An optional occurence number. When equal to integer <code>n</code>, the selector does not match the first occurence of the tag (along the walked path) but the <code>n</code>-th occurence instead.</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass(frozen=True)\nclass TagSelector:\n    \"\"\"\n    A tag selector consists in a tag along with an optional occurence\n    number.\n\n    Attributes:\n        tag: The tag to match.\n        num: An optional occurence number. When equal to integer `n`,\n            the selector does not match the first occurence of the tag\n            (along the walked path) but the `n`-th occurence instead.\n    \"\"\"\n\n    tag: str\n    num: int | None\n</code></pre>"},{"location":"reference/demos/definitions/#delphyne.core.demos.WithinSpace","title":"WithinSpace  <code>dataclass</code>","text":"<p>A node selector that matches a node within a particular space of the surrounding tree.</p> <p>Attributes:</p> Name Type Description <code>space</code> <code>TagSelectors</code> <p>A conjunction of tags describing a space in the surrounding tree.</p> <code>selector</code> <code>NodeSelector</code> <p>A node selector, relative to the tree that induces the aforementioned space.</p> Source code in <code>src/delphyne/core/demos.py</code> <pre><code>@dataclass\nclass WithinSpace:\n    \"\"\"\n    A node selector that matches a node within a particular space of the\n    surrounding tree.\n\n    Attributes:\n        space: A conjunction of tags describing a space in the\n            surrounding tree.\n        selector: A node selector, relative to the tree that induces the\n            aforementioned space.\n    \"\"\"\n\n    space: TagSelectors\n    selector: NodeSelector\n</code></pre>"},{"location":"reference/demos/interpreter/","title":"Evaluating Demonstrations","text":""},{"location":"reference/demos/interpreter/#evaluation-feedback","title":"Evaluation Feedback","text":""},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.DemoFeedback","title":"DemoFeedback","text":"<pre><code>DemoFeedback = StrategyDemoFeedback | QueryDemoFeedback\n</code></pre> <p>Feedback sent by the server for each demonstration in a file.</p>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.QueryDemoFeedback","title":"QueryDemoFeedback  <code>dataclass</code>","text":"<p>Feedback sent by the server for a standalone query demonstration.</p> <p>Attributes:</p> Name Type Description <code>kind</code> <code>Literal['query']</code> <p>Always \"query\".</p> <code>diagnostics</code> <code>list[Diagnostic]</code> <p>Global diagnostics.</p> <code>answer_diagnostics</code> <code>list[tuple[int, Diagnostic]]</code> <p>Diagnostics attached to specific answers.</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass(kw_only=True)\nclass QueryDemoFeedback:\n    \"\"\"\n    Feedback sent by the server for a standalone query demonstration.\n\n    Attributes:\n        kind: Always \"query\".\n        diagnostics: Global diagnostics.\n        answer_diagnostics: Diagnostics attached to specific answers.\n    \"\"\"\n\n    kind: Literal[\"query\"]\n    diagnostics: list[Diagnostic]\n    answer_diagnostics: list[tuple[int, Diagnostic]]\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.StrategyDemoFeedback","title":"StrategyDemoFeedback  <code>dataclass</code>","text":"<p>Feedback sent by the server for each strategy demonstration.</p> <p>Attributes:</p> Name Type Description <code>kind</code> <code>Literal['strategy']</code> <p>Always \"strategy\".</p> <code>trace</code> <code>Trace</code> <p>The resulting browsable trace, which includes all visited nodes.</p> <code>answer_refs</code> <code>dict[TraceAnswerId, DemoAnswerId]</code> <p>A mapping from answer ids featured in the trace to the position of the corresponding answer in the demonstration. This mapping may be partial. For example, using value hints (e.g., <code>#flag_value</code>) forces the demonstration interpreter to create answers on the fly that are not part of the demonstration.</p> <code>saved_nodes</code> <code>dict[str, TraceNodeId]</code> <p>Nodes saved using the <code>save</code> test instruction.</p> <code>test_feedback</code> <code>list[TestFeedback]</code> <p>Feedback for each test in the demonstration.</p> <code>global_diagnostics</code> <code>list[Diagnostic]</code> <p>Diagnostics that apply to the whole demonstration (individual tests have their own diagnostics).</p> <code>query_diagnostics</code> <code>list[tuple[DemoQueryId, Diagnostic]]</code> <p>Diagnostics attached to specific queries.</p> <code>answer_diagnostics</code> <code>list[tuple[DemoAnswerId, Diagnostic]]</code> <p>Diagnostics attached to specific answers.</p> <code>implicit_answers</code> <code>list[ImplicitAnswer]</code> <p>Implicit answers that were generated on the fly and that can be explicitly added to the demonstration.</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass(kw_only=True)\nclass StrategyDemoFeedback:\n    \"\"\"\n    Feedback sent by the server for each strategy demonstration.\n\n    Attributes:\n        kind: Always \"strategy\".\n        trace: The resulting browsable trace, which includes all visited\n            nodes.\n        answer_refs: A mapping from answer ids featured in the\n            trace to the position of the corresponding answer in the\n            demonstration. This mapping may be **partial**. For example,\n            using value hints (e.g., `#flag_value`) forces the\n            demonstration interpreter to create answers on the fly that\n            are not part of the demonstration.\n        saved_nodes: Nodes saved using the `save` test instruction.\n        test_feedback: Feedback for each test in the demonstration.\n        global_diagnostics: Diagnostics that apply to the whole\n            demonstration (individual tests have their own diagnostics).\n        query_diagnostics: Diagnostics attached to specific queries.\n        answer_diagnostics: Diagnostics attached to specific answers.\n        implicit_answers: Implicit answers that were generated on the fly\n            and that can be explicitly added to the demonstration.\n    \"\"\"\n\n    kind: Literal[\"strategy\"]\n    trace: Trace\n    answer_refs: dict[TraceAnswerId, DemoAnswerId]\n    saved_nodes: dict[str, TraceNodeId]\n    test_feedback: list[TestFeedback]\n    global_diagnostics: list[Diagnostic]\n    query_diagnostics: list[tuple[DemoQueryId, Diagnostic]]\n    answer_diagnostics: list[tuple[DemoAnswerId, Diagnostic]]\n    implicit_answers: list[ImplicitAnswer]\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.TestFeedback","title":"TestFeedback  <code>dataclass</code>","text":"<p>Feedback returned by the demo interpreter for a single test.</p> <p>The test is considered successful if no diagnostic is a warning or an error. Most of the time, and even when unsuccessful, a test stops at a given node, which can be inspected in the UI and which is indicated in field <code>node_id</code>.</p> <p>Attributes:</p> Name Type Description <code>diagnostics</code> <code>list[Diagnostic]</code> <p>List of diagnostics for the test.</p> <code>node_id</code> <code>TraceNodeId | None</code> <p>Identifier of the node where the test stopped.</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass\nclass TestFeedback:\n    \"\"\"\n    Feedback returned by the demo interpreter for a single test.\n\n    The test is considered successful if no diagnostic is a warning or an\n    error. Most of the time, and even when unsuccessful, a test stops at\n    a given node, which can be inspected in the UI and which is\n    indicated in field `node_id`.\n\n    Attributes:\n        diagnostics: List of diagnostics for the test.\n        node_id: Identifier of the node where the test stopped.\n    \"\"\"\n\n    diagnostics: list[Diagnostic]\n    node_id: TraceNodeId | None\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.ImplicitAnswer","title":"ImplicitAnswer  <code>dataclass</code>","text":"<p>An implicit answer that is not part of the demonstration but was generated on the fly.</p> <p>The VSCode extension then offers to add such answers explicitly in the demonstration. This is particularly useful for handling <code>Compute</code> nodes in demonstrations.</p> <p>Attributes:</p> Name Type Description <code>query_name</code> <code>str</code> <p>Query name.</p> <code>query_args</code> <code>dict[str, object]</code> <p>Arguments passed to the query.</p> <code>answer</code> <code>str</code> <p>The implicit answer value, as a raw string (mode <code>None</code> is implicitly used for parsing).</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass\nclass ImplicitAnswer:\n    \"\"\"\n    An implicit answer that is not part of the demonstration but was\n    generated on the fly.\n\n    The VSCode extension then offers to add such answers explicitly in\n    the demonstration. This is particularly useful for handling\n    `Compute` nodes in demonstrations.\n\n    Attributes:\n        query_name: Query name.\n        query_args: Arguments passed to the query.\n        answer: The implicit answer value, as a raw string (mode `None`\n            is implicitly used for parsing).\n    \"\"\"\n\n    # TODO: generalize implicit answers to accept full answers instead\n    # of just a string? In particular, other modes could be used.\n\n    query_name: str\n    query_args: dict[str, object]\n    answer: str\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.DemoAnswerId","title":"DemoAnswerId","text":"<pre><code>DemoAnswerId = tuple[int, int]\n</code></pre> <p>A (query_id, answer_index) pair that identifies an answer in a demo.</p>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.DemoQueryId","title":"DemoQueryId","text":"<pre><code>DemoQueryId = int\n</code></pre> <p>Index of the query in the queries section of a demo.</p>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.Diagnostic","title":"Diagnostic","text":"<pre><code>Diagnostic = tuple[DiagnosticType, str]\n</code></pre> <p>A diagnostic gathers a type (i.e. severity) and a message.</p>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.DiagnosticType","title":"DiagnosticType","text":"<pre><code>DiagnosticType = Literal['error', 'warning', 'info']\n</code></pre> <p>Diagnostic type.</p>"},{"location":"reference/demos/interpreter/#browsable-traces","title":"Browsable Traces","text":""},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.Trace","title":"Trace  <code>dataclass</code>","text":"<p>A browsable trace.</p> <p>Raw traces contain all the information necessary to recompute a trace but are not easily manipulated by tools. In comparison, these offer a more redundant but also more explicit view. This module provides a way to convert a trace from the former format to the latter.</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>dict[TraceNodeId, Node]</code> <p>A mapping from node ids to their description.</p> <p>Info</p> <p>A browsable trace features answer identifiers, for which a meaning must be provided externally. For example, the demonstration interpreter also produces a mapping from answer ids to their position in the demonstration file. In addition, commands like <code>run_strategy</code> return a raw trace (<code>core.traces.Trace</code>) in addition to the browsable version, which maps answer ids to their actual content.</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass\nclass Trace:\n    \"\"\"\n    A browsable trace.\n\n    [Raw traces][delphyne.core.traces.Trace] contain all the information\n    necessary to recompute a trace but are not easily manipulated by\n    tools. In comparison, [these][delphyne.analysis.feedback.Trace]\n    offer a more redundant but also more explicit view. This module\n    provides a way to convert a trace from the former format to the\n    latter.\n\n    Attributes:\n        nodes: A mapping from node ids to their description.\n\n    !!! info\n        A browsable trace features answer identifiers, for which a\n        meaning must be provided externally. For example, the\n        demonstration interpreter also produces a mapping from answer\n        ids to their position in the demonstration file. In addition,\n        commands like `run_strategy` return a raw trace\n        (`core.traces.Trace`) in addition to the browsable version,\n        which maps answer ids to their actual content.\n    \"\"\"\n\n    nodes: dict[TraceNodeId, Node]\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.Node","title":"Node  <code>dataclass</code>","text":"<p>Information about a node.</p> <p>Attributes:</p> Name Type Description <code>kind</code> <code>str</code> <p>Name of the node type, or <code>Success</code>.</p> <code>success_value</code> <code>ValueRepr | None</code> <p>The success value if the node is a success leaf, or <code>None</code> otherwise.</p> <code>summary_message</code> <code>str | None</code> <p>A short summary message (see the <code>Node.sumary_message</code> method).</p> <code>leaf_node</code> <code>bool</code> <p>Whether the node is a leaf node</p> <code>label</code> <code>str | None</code> <p>A label describing the node, which can be useful for writing node selectors (although there is currently no guarantee that the label constitutes a valid selector leading to the node). Currently, the label shows all node tags, separated by \"&amp;\".</p> <code>tags</code> <code>list[str]</code> <p>The list of all tags attached to the node.</p> <code>properties</code> <code>list[tuple[Reference, NodeProperty]]</code> <p>List of node properties (attached queries, nested trees, data fields...). Each property is accompanied by a pretty-printed, local space reference.</p> <code>actions</code> <code>list[Action]</code> <p>A list of explored actions.</p> <code>origin</code> <code>NodeOrigin</code> <p>The origin of the node in the global trace.</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass(kw_only=True)\nclass Node:\n    \"\"\"\n    Information about a node.\n\n    Attributes:\n        kind: Name of the node type, or `Success`.\n        success_value: The success value if the node is a success leaf,\n            or `None` otherwise.\n        summary_message: A short summary message (see the\n            `Node.sumary_message` method).\n        leaf_node: Whether the node is a leaf node\n        label: A label describing the node, which can be useful for\n            writing node selectors (although there is currently no\n            guarantee that the label constitutes a valid selector\n            leading to the node). Currently, the label shows all node\n            tags, separated by \"&amp;\".\n        tags: The list of all tags attached to the node.\n        properties: List of node properties (attached queries, nested\n            trees, data fields...). Each property is accompanied by a\n            pretty-printed, local space reference.\n        actions: A list of explored actions.\n        origin: The origin of the node in the global trace.\n    \"\"\"\n\n    # TODO: Make node labels into valid selectors that can be used with\n    # the `at` instruction in demonstration tests.\n\n    kind: str\n    success_value: ValueRepr | None\n    summary_message: str | None\n    leaf_node: bool\n    label: str | None\n    tags: list[str]\n    properties: list[tuple[Reference, NodeProperty]]\n    actions: list[Action]\n    origin: NodeOrigin\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.NodeOrigin","title":"NodeOrigin","text":"<pre><code>NodeOrigin = (\n    Literal[\"root\"]\n    | tuple[Literal[\"child\"], TraceNodeId, TraceActionId]\n    | tuple[Literal[\"nested\"], TraceNodeId, TraceNodePropertyId]\n)\n</code></pre> <p>Origin of a node.</p> <p>A node can be the global root, the child of another node, or the root of a nested tree.</p>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.Action","title":"Action  <code>dataclass</code>","text":"<p>An action associated with a node.</p> <p>Attributes:</p> Name Type Description <code>ref</code> <code>Reference</code> <p>Pretty-printed local reference for the action.</p> <code>hints</code> <code>list[str] | None</code> <p>If the trace results from executing a demonstration, this provides the list of hints that can be used to recover the action through navigation. Otherwise, it is <code>None</code>. Note that this is not identical to <code>ref.with_hints</code>. Both could plausibly be shown in the UI but the former is more concise.</p> <code>related_success_nodes</code> <code>list[TraceNodeId]</code> <p>List of related success nodes. A related success node is a node whose attached value was used in building the action. Indeed, in the VSCode extension's Path View, we get a sequence of actions and for each of them the list of success paths that were involved in building that action.</p> <code>related_answers</code> <code>list[TraceAnswerId]</code> <p>List of related answers. A related answer is an answer to a local query that is used in building the action. Storing this information is useful to detect useless answers that are not used in any action.</p> <code>destination</code> <code>TraceNodeId</code> <p>Id of the child node that the action leads to.</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass(kw_only=True)\nclass Action:\n    \"\"\"\n    An action associated with a node.\n\n    Attributes:\n        ref: Pretty-printed local reference for the action.\n        hints: If the trace results from executing a demonstration,\n            this provides the list of hints that can be used to recover\n            the action through navigation. Otherwise, it is `None`. Note\n            that this is not identical to `ref.with_hints`. Both could\n            plausibly be shown in the UI but the former is more concise.\n        related_success_nodes: List of related success nodes. A related\n            success node is a node whose attached value was used in\n            building the action. Indeed, in the VSCode extension's Path\n            View, we get a sequence of actions and for each of them the\n            list of success paths that were involved in building that\n            action.\n        related_answers: List of related answers. A related answer is an\n            answer to a local query that is used in building the action.\n            Storing this information is useful to detect useless answers\n            that are not used in any action.\n        destination: Id of the child node that the action leads to.\n    \"\"\"\n\n    ref: Reference\n    hints: list[str] | None\n    related_success_nodes: list[TraceNodeId]\n    related_answers: list[TraceAnswerId]\n    value: ValueRepr\n    destination: TraceNodeId\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.NodeProperty","title":"NodeProperty","text":"<pre><code>NodeProperty = Data | NestedTree | Query\n</code></pre> <p>Description of a node property (see <code>NodePropertyId</code>).</p>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.Data","title":"Data  <code>dataclass</code>","text":"<p>Generic property that displays some data.</p> <p>Attributes:</p> Name Type Description <code>kind</code> <code>Literal['data']</code> <p>Always \"data\".</p> <code>content</code> <code>str</code> <p>string representation of the data content.</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass\nclass Data:\n    \"\"\"\n    Generic property that displays some data.\n\n    Attributes:\n        kind: Always \"data\".\n        content: string representation of the data content.\n    \"\"\"\n\n    kind: Literal[\"data\"]\n    content: str\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.NestedTree","title":"NestedTree  <code>dataclass</code>","text":"<p>A nested tree.</p> <p>Attributes:</p> Name Type Description <code>kind</code> <code>Literal['nested']</code> <p>Always \"nested\".</p> <code>strategy</code> <code>str</code> <p>Name of the strategy function that induces the tree.</p> <code>args</code> <code>dict[str, ValueRepr]</code> <p>Arguments passed to the strategy function.</p> <code>tags</code> <code>list[str]</code> <p>Tags attached to the space induced by the tree.</p> <code>node_id</code> <code>TraceNodeId | None</code> <p>Identifier of the root node of the nested tree, or <code>None</code> if it is not in the trace (i.e., the nested tree hasn't been explored).</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass(kw_only=True)\nclass NestedTree:\n    \"\"\"\n    A nested tree.\n\n    Attributes:\n        kind: Always \"nested\".\n        strategy: Name of the strategy function that induces the tree.\n        args: Arguments passed to the strategy function.\n        tags: Tags attached to the space induced by the tree.\n        node_id: Identifier of the root node of the nested tree, or\n            `None` if it is not in the trace (i.e., the nested tree hasn't\n            been explored).\n    \"\"\"\n\n    kind: Literal[\"nested\"]\n    strategy: str\n    args: dict[str, ValueRepr]\n    tags: list[str]\n    node_id: TraceNodeId | None  # None if the subtree hasn't been explored\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.Query","title":"Query  <code>dataclass</code>","text":"<p>Information about a query.</p> <p>Attributes:</p> Name Type Description <code>kind</code> <code>Literal['query']</code> <p>Always \"query\".</p> <code>name</code> <code>str</code> <p>Name of the query.</p> <code>args</code> <code>dict[str, object]</code> <p>Query arguments, serialized in JSON.</p> <code>tags</code> <code>list[str]</code> <p>Tags attached to the space induced by the query.</p> <code>answers</code> <code>list[Answer]</code> <p>All answers to the query present in the trace.</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass(kw_only=True)\nclass Query:\n    \"\"\"\n    Information about a query.\n\n    Attributes:\n        kind: Always \"query\".\n        name: Name of the query.\n        args: Query arguments, serialized in JSON.\n        tags: Tags attached to the space induced by the query.\n        answers: All answers to the query present in the trace.\n    \"\"\"\n\n    kind: Literal[\"query\"]\n    name: str\n    args: dict[str, object]\n    tags: list[str]\n    answers: list[Answer]\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.Answer","title":"Answer  <code>dataclass</code>","text":"<p>An answer to a query.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>TraceAnswerId</code> <p>Unique answer identifier.</p> <code>value</code> <code>ValueRepr</code> <p>Parsed answer value.</p> <code>hint</code> <code>tuple[] | tuple[str] | None</code> <p>If the trace results from executing a demonstration (vs running a policy with tracing enabled), then <code>hint</code> is either <code>()</code> if the answer corresponds to the default answer and <code>(l,)</code> if the answer is labeled with <code>l</code>. Otherwise, it is <code>None</code>.</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass(kw_only=True)\nclass Answer:\n    \"\"\"\n    An answer to a query.\n\n    Attributes:\n        id: Unique answer identifier.\n        value: Parsed answer value.\n        hint: If the trace results from executing a demonstration (vs\n            running a policy with tracing enabled), then `hint` is\n            either `()` if the answer corresponds to the default answer\n            and `(l,)` if the answer is labeled with `l`. Otherwise, it\n            is `None`.\n    \"\"\"\n\n    id: TraceAnswerId\n    hint: tuple[()] | tuple[str] | None\n    value: ValueRepr\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.Reference","title":"Reference  <code>dataclass</code>","text":"<p>A reference to a space or to a value.</p> <p>Several human-readable representations are provided:</p> <p>Attributes:</p> Name Type Description <code>with_ids</code> <code>str</code> <p>A pretty-printed, id-based reference.</p> <code>with_hints</code> <code>str | None</code> <p>A pretty-printed, hint-based reference. These are typically available in the output of the demonstration interpreter, but not when converting arbitrary traces that result from running policies.</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass(kw_only=True)\nclass Reference:\n    \"\"\"\n    A reference to a space or to a value.\n\n    Several human-readable representations are provided:\n\n    Attributes:\n        with_ids: A pretty-printed, id-based reference.\n        with_hints: A pretty-printed, hint-based reference. These are\n            typically available in the output of the demonstration\n            interpreter, but not when converting arbitrary traces that\n            result from running policies.\n    \"\"\"\n\n    with_ids: str\n    with_hints: str | None\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.ValueRepr","title":"ValueRepr  <code>dataclass</code>","text":"<p>Multiple representations for a Python object.</p> <p>We allow providing several representations for Python objects: short, one-liner string descriptions, detailed descriptions, JSON representation... All of these can be leveraged by different tools and UI components.</p> <p>Attributes:</p> Name Type Description <code>short</code> <code>str</code> <p>A short representation, typically obtained using the <code>str</code> function.</p> <code>long</code> <code>str | None</code> <p>A longer, often multi-line representation, typically obtained using the <code>pprint</code> module.</p> <code>json</code> <code>object</code> <p>A JSON representation of the object.</p> <code>json_provided</code> <code>bool</code> <p>Whether a JSON representation is provided (the JSON field is <code>None</code> otherwise). This is not always the case since not all Python objects can be serialized to JSON.</p> Source code in <code>src/delphyne/analysis/feedback.py</code> <pre><code>@dataclass(kw_only=True)\nclass ValueRepr:\n    \"\"\"\n    Multiple representations for a Python object.\n\n    We allow providing several representations for Python objects:\n    short, one-liner string descriptions, detailed descriptions, JSON\n    representation... All of these can be leveraged by different tools\n    and UI components.\n\n    Attributes:\n        short: A short representation, typically obtained using the\n            `str` function.\n        long: A longer, often multi-line representation, typically\n            obtained using the `pprint` module.\n        json: A JSON representation of the object.\n        json_provided: Whether a JSON representation is provided (the\n            JSON field is `None` otherwise). This is not always the case\n            since not all Python objects can be serialized to JSON.\n    \"\"\"\n\n    short: str\n    long: str | None\n    json_provided: bool\n    json: object\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.TraceAnswerId","title":"TraceAnswerId","text":"<pre><code>TraceAnswerId = int\n</code></pre> <p>Global answer id, as set by <code>core.traces.Trace</code>.</p>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.TraceActionId","title":"TraceActionId","text":"<pre><code>TraceActionId = int\n</code></pre> <p>Index of an action within a given node.</p>"},{"location":"reference/demos/interpreter/#delphyne.analysis.feedback.TraceNodePropertyId","title":"TraceNodePropertyId","text":"<pre><code>TraceNodePropertyId = int\n</code></pre> <p>Index of a property within a given node. A property is an element that can be listed in the UI, which is either an attached query, a nested tree or some data.</p>"},{"location":"reference/demos/interpreter/#demonstration-interpreter","title":"Demonstration Interpreter","text":""},{"location":"reference/demos/interpreter/#delphyne.analysis.demo_interpreter.evaluate_demo","title":"evaluate_demo","text":"<pre><code>evaluate_demo(\n    demo: Demo, context: DemoExecutionContext, extra_objects: dict[str, object]\n) -&gt; DemoFeedback\n</code></pre> <p>Evaluate a query or strategy demonstration.</p> <p>This is the main entrypoint of the demonstration interpreter.</p> <p>Attributes:</p> Name Type Description <code>demo</code> <p>The demonstration to evaluate.</p> <code>context</code> <p>The execution context in which to resolve Python identifiers.</p> <code>extra_objects</code> <p>Additional objects that can be resolved by name (with higher precedence).</p> <p>Returns:</p> Type Description <code>DemoFeedback</code> <p>A feedback object containing the results of the evaluation.</p> <p>Warning</p> <p>This function creates an <code>ObjectLoader</code> internally and is therefore not thread-safe.</p> Source code in <code>src/delphyne/analysis/demo_interpreter.py</code> <pre><code>def evaluate_demo(\n    demo: dm.Demo,\n    context: DemoExecutionContext,\n    extra_objects: dict[str, object],\n) -&gt; fb.DemoFeedback:\n    \"\"\"\n    Evaluate a query or strategy demonstration.\n\n    This is the main entrypoint of the demonstration interpreter.\n\n    Attributes:\n        demo: The demonstration to evaluate.\n        context: The execution context in which to resolve Python\n            identifiers.\n        extra_objects: Additional objects that can be resolved by name\n            (with higher precedence).\n\n    Returns:\n        A feedback object containing the results of the evaluation.\n\n    !!! warning\n        This function creates an `ObjectLoader` internally and is\n        therefore not thread-safe.\n    \"\"\"\n    if isinstance(demo, dm.StrategyDemo):\n        feedback, _ = evaluate_strategy_demo_and_return_trace(\n            demo, context, extra_objects\n        )\n        return feedback\n    else:\n        return evaluate_standalone_query_demo(demo, context, extra_objects)\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.DemoExecutionContext","title":"DemoExecutionContext  <code>dataclass</code>","text":"<p>Demonstration Execution Context.</p> <p>Attributes:</p> Name Type Description <code>strategy_dirs</code> <code>Sequence[Path]</code> <p>A list of directories in which strategy modules can be found, to be added to <code>sys.path</code>.</p> <code>modules</code> <code>Sequence[str]</code> <p>A list of modules in which python object identifiers should be resolved. Modules can be part of packages and so their name may feature <code>.</code>.</p> Source code in <code>src/delphyne/analysis/demo_interpreter.py</code> <pre><code>@dataclass(frozen=True)\nclass DemoExecutionContext:\n    \"\"\"\n    Demonstration Execution Context.\n\n    Attributes:\n        strategy_dirs: A list of directories in which strategy modules\n            can be found, to be added to `sys.path`.\n        modules: A list of modules in which python object identifiers\n            should be resolved. Modules can be part of packages and so\n            their name may feature `.`.\n    \"\"\"\n\n    strategy_dirs: Sequence[Path]\n    modules: Sequence[str]\n\n    def with_root(self, root: Path) -&gt; \"DemoExecutionContext\":\n        return DemoExecutionContext(\n            strategy_dirs=[root / p for p in self.strategy_dirs],\n            modules=self.modules,\n        )\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.ObjectLoader","title":"ObjectLoader","text":"<p>Utility class for loading Python objects.</p> <p>Demonstration and command files may refer to Python identifiers that need to be resolved. This is done relative to an execution context (<code>DemoExecutionContext</code>) that specifies a list of directories to be added to <code>sys.path</code>, along with a list of modules.</p> <p>An exception is raised if an object with the requested identifier can be found in several modules.</p> Source code in <code>src/delphyne/analysis/demo_interpreter.py</code> <pre><code>class ObjectLoader:\n    \"\"\"\n    Utility class for loading Python objects.\n\n    Demonstration and command files may refer to Python identifiers that\n    need to be resolved. This is done relative to an execution context\n    (`DemoExecutionContext`) that specifies a list of directories to be\n    added to `sys.path`, along with a list of modules.\n\n    An exception is raised if an object with the requested identifier\n    can be found in several modules.\n    \"\"\"\n\n    def __init__(\n        self,\n        ctx: DemoExecutionContext,\n        extra_objects: dict[str, object] | None = None,\n        reload: bool = True,\n    ):\n        \"\"\"\n        Attributes:\n            ctx: The execution context in which to resolve Python\n                identifiers.\n            extra_objects: Additional objects that can be resolved by\n                name (with higher precedence).\n            reload: Whether to reload all modules specified in the\n                execution context upon initialization. Setting this\n                value to `True` makes `ObjectLoader` not thread-safe\n                (also, multiple instances must not be used in an\n                overlappaping way within a single thread).\n\n        Raises:\n            ModuleNotFound: a module could not be found.\n        \"\"\"\n        self.ctx = ctx\n        self.extra_objects = extra_objects if extra_objects is not None else {}\n        self.modules: list[Any] = []\n        with _append_path(self.ctx.strategy_dirs):\n            for module_name in ctx.modules:\n                try:\n                    module = __import__(module_name)\n                    if reload:\n                        module = importlib.reload(module)\n                    self.modules.append(module)\n                except AttributeError:\n                    raise ModuleNotFound(module_name)\n\n    def find_object(self, name: str) -&gt; Any:\n        \"\"\"\n        Find an object with a given name.\n\n        If the name is unqualified (it features no `.`), one attempts to\n        find the object in every registered module in order. If the name\n        is qualified, one looks at the specified registered module.\n\n        Raises:\n            ObjectNotFound: The object could not be found.\n            AmbiguousObjectIdentifier: The object name is ambiguous,\n                i.e. it is found in several modules.\n        \"\"\"\n        if name in self.extra_objects:\n            return self.extra_objects[name]\n        comps = name.split(\".\")\n        assert comps\n        if len(comps) == 1:\n            # unqualified name\n            cands: list[object] = []\n            modules_with_id: dict[int, list[str]] = defaultdict(list)\n            for module in self.modules:\n                if hasattr(module, name):\n                    obj = getattr(module, name)\n                    modules_with_id[id(obj)].append(module)\n                    cands.append(obj)\n            if len(modules_with_id) &gt; 1:\n                ambiguous = [ms[0] for ms in modules_with_id.values()]\n                raise AmbiguousObjectIdentifier(name, ambiguous)\n            if cands:\n                return cands[0]\n        else:\n            # qualified name\n            module = \".\".join(comps[:-1])\n            attr = comps[-1]\n            if hasattr(module, attr):\n                return getattr(module, attr)\n        raise ObjectNotFound(name)\n\n    def load_and_call_function(self, name: str, args: dict[str, Any]) -&gt; Any:\n        \"\"\"\n        Load and call a function by wrapping a call to `find_object`.\n        \"\"\"\n        f = self.find_object(name)\n        args = tp.parse_function_args(f, args)\n        return f(**args)\n\n    def load_strategy_instance(\n        self, name: str, args: dict[str, Any]\n    ) -&gt; dp.StrategyComp[Any, Any, Any]:\n        \"\"\"\n        Load and instantiate a strategy function with given arguments.\n\n        Raises:\n            ObjectNotFound: If the strategy function cannot be found.\n            AmbiguousObjectIdentifier: If an ambiguous name is given.\n            StrategyLoadingError: If the object is not a strategy function\n                or if the arguments are invalid.\n        \"\"\"\n        f = self.find_object(name)\n        try:\n            args = tp.parse_function_args(f, args)\n            comp = f(**args)\n            assert isinstance(comp, dp.StrategyComp), (\n                f\"Object {name} is not a strategy function.\"\n                + \" Did you forget to use the @strategy decorator?\"\n            )\n            return cast(Any, comp)\n        except Exception as e:\n            raise StrategyLoadingError(str(e))\n\n    def load_query(\n        self, name: str, args: dict[str, Any]\n    ) -&gt; dp.AbstractQuery[Any]:\n        \"\"\"\n        Load a query by name and instantiate it with given arguments.\n\n        Raises:\n            ObjectNotFound: if the query cannot be found.\n            AmbiguousObjectIdentifier: if an ambiguous name is given.\n            AssertionError: if the object is not a query.\n        \"\"\"\n        obj = self.find_object(name)\n        assert issubclass(obj, dp.AbstractQuery), (\n            f\"Object {name} is not a query type.\"\n        )\n        q = cast(type[dp.AbstractQuery[Any]], obj)\n        return q.parse_instance(args)\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.ObjectLoader.__init__","title":"__init__","text":"<pre><code>__init__(\n    ctx: DemoExecutionContext,\n    extra_objects: dict[str, object] | None = None,\n    reload: bool = True,\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>ctx</code> <p>The execution context in which to resolve Python identifiers.</p> <code>extra_objects</code> <p>Additional objects that can be resolved by name (with higher precedence).</p> <code>reload</code> <p>Whether to reload all modules specified in the execution context upon initialization. Setting this value to <code>True</code> makes <code>ObjectLoader</code> not thread-safe (also, multiple instances must not be used in an overlappaping way within a single thread).</p> <p>Raises:</p> Type Description <code>ModuleNotFound</code> <p>a module could not be found.</p> Source code in <code>src/delphyne/analysis/demo_interpreter.py</code> <pre><code>def __init__(\n    self,\n    ctx: DemoExecutionContext,\n    extra_objects: dict[str, object] | None = None,\n    reload: bool = True,\n):\n    \"\"\"\n    Attributes:\n        ctx: The execution context in which to resolve Python\n            identifiers.\n        extra_objects: Additional objects that can be resolved by\n            name (with higher precedence).\n        reload: Whether to reload all modules specified in the\n            execution context upon initialization. Setting this\n            value to `True` makes `ObjectLoader` not thread-safe\n            (also, multiple instances must not be used in an\n            overlappaping way within a single thread).\n\n    Raises:\n        ModuleNotFound: a module could not be found.\n    \"\"\"\n    self.ctx = ctx\n    self.extra_objects = extra_objects if extra_objects is not None else {}\n    self.modules: list[Any] = []\n    with _append_path(self.ctx.strategy_dirs):\n        for module_name in ctx.modules:\n            try:\n                module = __import__(module_name)\n                if reload:\n                    module = importlib.reload(module)\n                self.modules.append(module)\n            except AttributeError:\n                raise ModuleNotFound(module_name)\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.ObjectLoader.find_object","title":"find_object","text":"<pre><code>find_object(name: str) -&gt; Any\n</code></pre> <p>Find an object with a given name.</p> <p>If the name is unqualified (it features no <code>.</code>), one attempts to find the object in every registered module in order. If the name is qualified, one looks at the specified registered module.</p> <p>Raises:</p> Type Description <code>ObjectNotFound</code> <p>The object could not be found.</p> <code>AmbiguousObjectIdentifier</code> <p>The object name is ambiguous, i.e. it is found in several modules.</p> Source code in <code>src/delphyne/analysis/demo_interpreter.py</code> <pre><code>def find_object(self, name: str) -&gt; Any:\n    \"\"\"\n    Find an object with a given name.\n\n    If the name is unqualified (it features no `.`), one attempts to\n    find the object in every registered module in order. If the name\n    is qualified, one looks at the specified registered module.\n\n    Raises:\n        ObjectNotFound: The object could not be found.\n        AmbiguousObjectIdentifier: The object name is ambiguous,\n            i.e. it is found in several modules.\n    \"\"\"\n    if name in self.extra_objects:\n        return self.extra_objects[name]\n    comps = name.split(\".\")\n    assert comps\n    if len(comps) == 1:\n        # unqualified name\n        cands: list[object] = []\n        modules_with_id: dict[int, list[str]] = defaultdict(list)\n        for module in self.modules:\n            if hasattr(module, name):\n                obj = getattr(module, name)\n                modules_with_id[id(obj)].append(module)\n                cands.append(obj)\n        if len(modules_with_id) &gt; 1:\n            ambiguous = [ms[0] for ms in modules_with_id.values()]\n            raise AmbiguousObjectIdentifier(name, ambiguous)\n        if cands:\n            return cands[0]\n    else:\n        # qualified name\n        module = \".\".join(comps[:-1])\n        attr = comps[-1]\n        if hasattr(module, attr):\n            return getattr(module, attr)\n    raise ObjectNotFound(name)\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.ObjectLoader.load_and_call_function","title":"load_and_call_function","text":"<pre><code>load_and_call_function(name: str, args: dict[str, Any]) -&gt; Any\n</code></pre> <p>Load and call a function by wrapping a call to <code>find_object</code>.</p> Source code in <code>src/delphyne/analysis/demo_interpreter.py</code> <pre><code>def load_and_call_function(self, name: str, args: dict[str, Any]) -&gt; Any:\n    \"\"\"\n    Load and call a function by wrapping a call to `find_object`.\n    \"\"\"\n    f = self.find_object(name)\n    args = tp.parse_function_args(f, args)\n    return f(**args)\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.ObjectLoader.load_strategy_instance","title":"load_strategy_instance","text":"<pre><code>load_strategy_instance(name: str, args: dict[str, Any]) -&gt; StrategyComp[Any, Any, Any]\n</code></pre> <p>Load and instantiate a strategy function with given arguments.</p> <p>Raises:</p> Type Description <code>ObjectNotFound</code> <p>If the strategy function cannot be found.</p> <code>AmbiguousObjectIdentifier</code> <p>If an ambiguous name is given.</p> <code>StrategyLoadingError</code> <p>If the object is not a strategy function or if the arguments are invalid.</p> Source code in <code>src/delphyne/analysis/demo_interpreter.py</code> <pre><code>def load_strategy_instance(\n    self, name: str, args: dict[str, Any]\n) -&gt; dp.StrategyComp[Any, Any, Any]:\n    \"\"\"\n    Load and instantiate a strategy function with given arguments.\n\n    Raises:\n        ObjectNotFound: If the strategy function cannot be found.\n        AmbiguousObjectIdentifier: If an ambiguous name is given.\n        StrategyLoadingError: If the object is not a strategy function\n            or if the arguments are invalid.\n    \"\"\"\n    f = self.find_object(name)\n    try:\n        args = tp.parse_function_args(f, args)\n        comp = f(**args)\n        assert isinstance(comp, dp.StrategyComp), (\n            f\"Object {name} is not a strategy function.\"\n            + \" Did you forget to use the @strategy decorator?\"\n        )\n        return cast(Any, comp)\n    except Exception as e:\n        raise StrategyLoadingError(str(e))\n</code></pre>"},{"location":"reference/demos/interpreter/#delphyne.ObjectLoader.load_query","title":"load_query","text":"<pre><code>load_query(name: str, args: dict[str, Any]) -&gt; AbstractQuery[Any]\n</code></pre> <p>Load a query by name and instantiate it with given arguments.</p> <p>Raises:</p> Type Description <code>ObjectNotFound</code> <p>if the query cannot be found.</p> <code>AmbiguousObjectIdentifier</code> <p>if an ambiguous name is given.</p> <code>AssertionError</code> <p>if the object is not a query.</p> Source code in <code>src/delphyne/analysis/demo_interpreter.py</code> <pre><code>def load_query(\n    self, name: str, args: dict[str, Any]\n) -&gt; dp.AbstractQuery[Any]:\n    \"\"\"\n    Load a query by name and instantiate it with given arguments.\n\n    Raises:\n        ObjectNotFound: if the query cannot be found.\n        AmbiguousObjectIdentifier: if an ambiguous name is given.\n        AssertionError: if the object is not a query.\n    \"\"\"\n    obj = self.find_object(name)\n    assert issubclass(obj, dp.AbstractQuery), (\n        f\"Object {name} is not a query type.\"\n    )\n    q = cast(type[dp.AbstractQuery[Any]], obj)\n    return q.parse_instance(args)\n</code></pre>"},{"location":"reference/policies/definitions/","title":"Policy Types","text":""},{"location":"reference/policies/definitions/#delphyne.AbstractPolicy","title":"AbstractPolicy","text":"<p>               Bases: <code>Generic[E, N, P]</code>, <code>ABC</code></p> <p>A pair of a search policy and of an inner policy.</p> <p>More preciely, a policy for trees with effects <code>N</code> (contravariant) gathers a search policy handling <code>N</code> along with an inner policy object of type <code>P</code> (covariant).</p> Source code in <code>src/delphyne/core/policies.py</code> <pre><code>class AbstractPolicy(Generic[E, N, P], ABC):\n    \"\"\"\n    A pair of a search policy and of an inner policy.\n\n    More preciely, a policy for trees with effects `N` (contravariant)\n    gathers a search policy handling `N` along with an inner policy\n    object of type `P` (covariant).\n    \"\"\"\n\n    @property\n    def search(self) -&gt; \"AbstractSearchPolicy[E, N]\": ...\n    @property\n    def inner(self) -&gt; P: ...\n</code></pre>"},{"location":"reference/policies/definitions/#delphyne.AbstractSearchPolicy","title":"AbstractSearchPolicy","text":"<p>               Bases: <code>Generic[E, N]</code>, <code>Protocol</code></p> <p>A search policy takes as arguments a tree with a given signature (covariant type parameter <code>N</code>), a global policy environment, and an inner policy with appropriate type, and returns a search stream.</p> Source code in <code>src/delphyne/core/policies.py</code> <pre><code>class AbstractSearchPolicy(Generic[E, N], Protocol):\n    \"\"\"\n    A search policy takes as arguments a tree with a given signature\n    (covariant type parameter `N`), a global policy environment, and an\n    inner policy with appropriate type, and returns a search stream.\n    \"\"\"\n\n    def __call__[P, T](\n        self, tree: \"Tree[N, P, T]\", env: E, policy: P\n    ) -&gt; AbstractStream[T]: ...\n</code></pre>"},{"location":"reference/policies/definitions/#delphyne.AbstractPromptingPolicy","title":"AbstractPromptingPolicy","text":"<p>               Bases: <code>Generic[E]</code>, <code>Protocol</code></p> <p>A prompting policy takes as arguments a query (attached to a specific node) and a global policy environment, and returns a search stream.</p> Source code in <code>src/delphyne/core/policies.py</code> <pre><code>class AbstractPromptingPolicy(Generic[E], Protocol):\n    \"\"\"\n    A prompting policy takes as arguments a query (attached to a\n    specific node) and a global policy environment, and returns a search\n    stream.\n    \"\"\"\n\n    def __call__[T](\n        self, query: AttachedQuery[T], env: E\n    ) -&gt; AbstractStream[T]: ...\n</code></pre>"},{"location":"reference/policies/streams/","title":"Search Streams","text":""},{"location":"reference/policies/streams/#summary","title":"Summary","text":""},{"location":"reference/policies/streams/#delphyne.core.streams","title":"delphyne.core.streams","text":"<p>The Search Stream Protocol.</p> <p>In order to allow the composition of heterogeneous search policies and prompting policies, a standard protocol is defined for defining resource-aware search iterators.</p> <p>A search stream consists in an iterator that yields three kinds of messages:</p> <ul> <li><code>Solution</code> messages indicating that a solution has been found.</li> <li><code>Barrier</code> messages asking authorization to spend a given amount of   resources (for which an over-estimate is provided).</li> <li><code>Spent</code> messages reporting actual resource spending.</li> </ul> <p>The following invariants and guarantees must be offered and preserved by stream combinators:</p> <p>Invariants</p> <ul> <li><code>Barrier</code> and <code>Spent</code> messages come in pairs and are associated   using shared identifiers. Because search streams can spawn mulitple   threads internally, multiple <code>Barrier</code> messages can be simultaneously   pending (i.e., in waiting of a matching <code>Spent</code> message).</li> <li>A stream must eventually terminate if all spending requests are denied   (this is why <code>loop</code> has a <code>stop_on_reject</code> argument).</li> <li>A stream can be interrupted before exhaustion (and be later garbage   collected), provided that no <code>Barrier</code> messages are pending (i.e., an   identical number of <code>Barrier</code> and <code>Spent</code> messages has been seen so   far). If this condition does not hold, some actual resource spending   might be unreported.</li> </ul> <p>Warning</p> <p>Manually implementing the search stream protocol by yielding <code>Barrier</code> and <code>Spent</code> messages is error-prone. Standard stream combinators should usually be used instead (see <code>Stream</code> class from the standard library).</p>"},{"location":"reference/policies/streams/#definitions","title":"Definitions","text":""},{"location":"reference/policies/streams/#delphyne.Budget","title":"Budget  <code>dataclass</code>","text":"<p>An immutable datastructure for tracking spent budget as an infinite vector with finite support. Each dimension corresponds to a different metric (e.g., number of requests, price in dollars...)</p> <p>Attributes:</p> Name Type Description <code>values</code> <code>Mapping[str, float]</code> <p>a mapping from metrics to spent budget. Metrics outside of this field are associated a spending of 0.</p> Source code in <code>src/delphyne/core/streams.py</code> <pre><code>@dataclass(frozen=True)\nclass Budget:\n    \"\"\"\n    An immutable datastructure for tracking spent budget as an infinite\n    vector with finite support. Each dimension corresponds to a\n    different metric (e.g., number of requests, price in dollars...)\n\n    Attributes:\n        values: a mapping from metrics to spent budget. Metrics outside\n            of this field are associated a spending of 0.\n    \"\"\"\n\n    values: Mapping[str, float]\n\n    def __getitem__(self, key: str) -&gt; float:\n        return self.values.get(key, 0)\n\n    def __add__(self, other: \"Budget\") -&gt; \"Budget\":\n        vals = dict(self.values).copy()\n        for k, v in other.values.items():\n            vals[k] = self[k] + v\n        return Budget(vals)\n\n    def __rmul__(self, const: float) -&gt; \"Budget\":\n        assert const &gt;= 0\n        values = {k: const * v for k, v in self.values.items()}\n        return Budget(values)\n\n    def __le__(self, limit: \"BudgetLimit\") -&gt; bool:\n        if not isinstance(limit, BudgetLimit):  # pyright: ignore[reportUnnecessaryIsInstance]\n            return NotImplemented\n        for k, v in limit.values.items():\n            if self[k] &gt; v:\n                return False\n        return True\n\n    def __ge__(self, other: \"Budget\") -&gt; bool:\n        if not isinstance(other, Budget):  # pyright: ignore[reportUnnecessaryIsInstance]\n            return NotImplemented\n        for k, v in other.values.items():\n            if self[k] &lt; v:\n                return False\n        return True\n\n    @staticmethod\n    def zero() -&gt; \"Budget\":\n        return Budget({})\n</code></pre>"},{"location":"reference/policies/streams/#delphyne.BudgetLimit","title":"BudgetLimit  <code>dataclass</code>","text":"<p>An immutable datastructure for representing a budget limit as an infinite vector with finite support.</p> <p>Elements outside of the finite support are associated an infinite limit. Hence the separation of <code>Budget</code> and <code>BudgetLimit</code>.</p> Source code in <code>src/delphyne/core/streams.py</code> <pre><code>@dataclass(frozen=True)\nclass BudgetLimit:\n    \"\"\"\n    An immutable datastructure for representing a budget limit as an\n    infinite vector with finite support.\n\n    Elements outside of the finite support are associated an\n    **infinite** limit. Hence the separation of `Budget` and\n    `BudgetLimit`.\n    \"\"\"\n\n    values: Mapping[str, float]\n\n    def __getitem__(self, key: str) -&gt; float:\n        return self.values.get(key, math.inf)\n</code></pre>"},{"location":"reference/policies/streams/#delphyne.AbstractStream","title":"AbstractStream","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for search streams.</p> <p>A search stream must be capable of producing a search stream generator. The standard library contains a subclass with more features (<code>Stream</code>).</p> Source code in <code>src/delphyne/core/streams.py</code> <pre><code>class AbstractStream[T](ABC):\n    \"\"\"\n    Base class for search streams.\n\n    A search stream must be capable of producing a search stream\n    generator. The standard library contains a subclass with more\n    features (`Stream`).\n    \"\"\"\n\n    @abstractmethod\n    def gen(self) -&gt; StreamGen[T]:\n        \"\"\"\n        Produce a search stream generator, i.e. an iterator that yields\n        `Barrier` and `Spent` messages along with solutions.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/policies/streams/#delphyne.AbstractStream.gen","title":"gen  <code>abstractmethod</code>","text":"<pre><code>gen() -&gt; StreamGen[T]\n</code></pre> <p>Produce a search stream generator, i.e. an iterator that yields <code>Barrier</code> and <code>Spent</code> messages along with solutions.</p> Source code in <code>src/delphyne/core/streams.py</code> <pre><code>@abstractmethod\ndef gen(self) -&gt; StreamGen[T]:\n    \"\"\"\n    Produce a search stream generator, i.e. an iterator that yields\n    `Barrier` and `Spent` messages along with solutions.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/policies/streams/#delphyne.StreamGen","title":"StreamGen","text":"<pre><code>StreamGen = Generator[Solution[T] | Barrier | Spent, None, None]\n</code></pre> <p>A search stream generator.</p> <p>See delphyne.core.streams for more explanations about the search stream protocol.</p>"},{"location":"reference/policies/streams/#delphyne.Solution","title":"Solution  <code>dataclass</code>","text":"<p>A solution yielded by a search stream, which combines a tracked value with optional metadata.</p> <p>Attributes:</p> Name Type Description <code>tracked</code> <code>Tracked[T]</code> <p>A tracked value.</p> <code>meta</code> <code>SearchMeta | None</code> <p>Optional metadata.</p> Source code in <code>src/delphyne/core/streams.py</code> <pre><code>@dataclass(frozen=True)\nclass Solution[T]:\n    \"\"\"\n    A solution yielded by a search stream, which combines a tracked\n    value with optional metadata.\n\n    Attributes:\n        tracked: A tracked value.\n        meta: Optional metadata.\n    \"\"\"\n\n    tracked: Tracked[T]\n    meta: SearchMeta | None = None\n</code></pre>"},{"location":"reference/policies/streams/#delphyne.core.streams.Barrier","title":"Barrier  <code>dataclass</code>","text":"<p>Ask authorization for spending a given budget amount.</p> <p>Attributes:</p> Name Type Description <code>budget</code> <code>Budget</code> <p>an over-estimate of how much budget will be spent if the request is granted. An inaccurate estimate can be provided by a policy, although more budget could be actually be spent than is intended in this case.</p> <code>allow</code> <code>bool</code> <p>a boolean flag that can be set to <code>False</code> by consumers of the stream to deny the request.</p> <code>id</code> <code>BarrierId</code> <p>a unique identifier, which is shared by a unique associated <code>Spent</code> message, to be yielded later.</p> <p>Warning</p> <p>Manually yielding <code>Spent</code> and <code>Barrier</code> messages is error-prone and usually not recommended. Use stream combinators instead (see the <code>Stream</code> class from the standard library).</p> Source code in <code>src/delphyne/core/streams.py</code> <pre><code>@dataclass(frozen=False)\nclass Barrier:\n    \"\"\"\n    Ask authorization for spending a given budget amount.\n\n    Attributes:\n        budget: an over-estimate of how much budget will be spent if the\n            request is granted. An inaccurate estimate can be provided\n            by a policy, although more budget could be actually be spent\n            than is intended in this case.\n        allow: a boolean flag that can be set to `False` by consumers of\n            the stream to deny the request.\n        id: a unique identifier, which is shared by a unique associated\n            `Spent` message, to be yielded later.\n\n    !!! warning\n        Manually yielding `Spent` and `Barrier` messages is error-prone\n        and usually not recommended. Use stream combinators instead (see\n        the `Stream` class from the standard library).\n    \"\"\"\n\n    budget: Budget\n    allow: bool\n    id: BarrierId\n\n    def __init__(self, budget: Budget, id: BarrierId | None = None):\n        import builtins\n\n        self.budget = budget\n        self.allow = True\n        self.id = id if id is not None else builtins.id(self)\n        pass\n</code></pre>"},{"location":"reference/policies/streams/#delphyne.core.streams.Spent","title":"Spent  <code>dataclass</code>","text":"<p>Indicate that an actual amount of resources has been spent.</p> <p>Each <code>Spent</code> message is associated with a unique prior <code>Barrier</code> message that shares the same identifier.</p> <p>Attributes:</p> Name Type Description <code>budget</code> <code>Budget</code> <p>Amount of budget that was actually spent.</p> <code>barrier_id</code> <code>BarrierId</code> <p>Identifier of the prior associated <code>Barrier</code> message.</p> <p>Warning</p> <p>Manually yielding <code>Spent</code> and <code>Barrier</code> messages is error-prone and usually not recommended. Use stream combinators instead (see the <code>Stream</code> class from the standard library).</p> Source code in <code>src/delphyne/core/streams.py</code> <pre><code>@dataclass(frozen=True)\nclass Spent:\n    \"\"\"\n    Indicate that an actual amount of resources has been spent.\n\n    Each `Spent` message is associated with a unique prior `Barrier`\n    message that shares the same identifier.\n\n    Attributes:\n        budget: Amount of budget that was actually spent.\n        barrier_id: Identifier of the prior associated `Barrier`\n            message.\n\n    !!! warning\n        Manually yielding `Spent` and `Barrier` messages is error-prone\n        and usually not recommended. Use stream combinators instead (see\n        the `Stream` class from the standard library).\n    \"\"\"\n\n    budget: Budget\n    barrier_id: BarrierId\n</code></pre>"},{"location":"reference/policies/streams/#delphyne.core.streams.BarrierId","title":"BarrierId","text":"<pre><code>BarrierId = int\n</code></pre> <p>A unique identifier associated with a <code>Barrier</code> message, used to identify a matching <code>Spent</code> message. Overlapping barrier messages must not share the same identifier (barrier messages are considered to overlap if the second one occurs before the <code>Spent</code> message associated with the first).</p>"},{"location":"reference/policies/streams/#delphyne.SearchMeta","title":"SearchMeta","text":"<p>Base class for valid search metadata.</p> <p>Search metadata can be attached to all solutions yielded by a search stream. See <code>ProbInfo</code> for an example.</p> Source code in <code>src/delphyne/core/streams.py</code> <pre><code>class SearchMeta:\n    \"\"\"\n    Base class for valid search metadata.\n\n    Search metadata can be attached to all solutions yielded by a search\n    stream. See `ProbInfo` for an example.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/stdlib/algorithms/","title":"Search Algorithms and Utilities","text":""},{"location":"reference/stdlib/algorithms/#strategies","title":"Strategies","text":""},{"location":"reference/stdlib/algorithms/#delphyne.interact","title":"interact","text":"<pre><code>interact(\n    step: Callable[\n        [AnswerPrefix, InteractStats], Opaque[P, Response[A | WrappedParseError, T]]\n    ],\n    process: Callable[[A, InteractStats], Opaque[P, B | Error]],\n    tools: Mapping[type[T], Callable[[Any], Opaque[P, Any]]] | None = None,\n    inner_policy_type: type[P] | None = None,\n) -&gt; Strategy[Branch, P, B]\n</code></pre> <p>A standard strategy for creating conversational agents.</p> <p>A common pattern for interacting with LLMs is to have multi-message exchanges where the full conversation history is resent repeatedly. LLMs are also often allowed to request tool call. This strategy implements this pattern. It is meant to be inlined into a wrapping strategy (since it is not decorated with <code>strategy</code>).</p> <p>Attributes:</p> Name Type Description <code>step</code> <p>a parametric opaque space, induced by a strategy or query that takes as an argument the current chat history (possibly empty) along with some statistics, and returns an answer to be processed. Oftentimes, this parametric opaque space is induced by a query with a special <code>prefix</code> field for receiving the chat history (see <code>Query</code>).</p> <code>process</code> <p>an opaque space induced by a query or strategy that is called on all model responses that are not tool calls, and which returns either a final response to be returned, or an error to be transmitted to the model as feedback (as an <code>Error</code> value with an absent or serializable <code>meta</code> field).</p> <code>tools</code> <p>a mapping from supported tool interfaces to implementations. Tools themselves can be implemented using arbitrary strategies or queries, allowing the integration of horizontal and vertical LLM pipelines.</p> <code>inner_policy_type</code> <p>Ambient inner policy type. This information is not used at runtime but it can be provided to help type inference when necessary.</p> Source code in <code>src/delphyne/stdlib/search/interactive.py</code> <pre><code>def interact[P, A, B, T: md.AbstractTool[Any]](\n    step: Callable[\n        [dp.AnswerPrefix, InteractStats],\n        Opaque[P, dq.Response[A | WrappedParseError, T]],\n    ],\n    process: Callable[[A, InteractStats], Opaque[P, B | dp.Error]],\n    tools: Mapping[type[T], Callable[[Any], Opaque[P, Any]]] | None = None,\n    inner_policy_type: type[P] | None = None,\n) -&gt; dp.Strategy[Branch, P, B]:\n    \"\"\"\n    A standard strategy for creating conversational agents.\n\n    A common pattern for interacting with LLMs is to have multi-message\n    exchanges where the full conversation history is resent repeatedly.\n    LLMs are also often allowed to request tool call. This strategy\n    implements this pattern. It is meant to be inlined into a wrapping\n    strategy (since it is not decorated with `strategy`).\n\n    Attributes:\n        step: a parametric opaque space, induced by a strategy or query\n            that takes as an argument the current chat history (possibly\n            empty) along with some statistics, and returns an answer to\n            be processed. Oftentimes, this parametric opaque space is\n            induced by a query with a special `prefix` field for\n            receiving the chat history (see `Query`).\n        process: an opaque space induced by a query or strategy that is\n            called on all model responses that are not tool calls, and\n            which returns either a final response to be returned, or an\n            error to be transmitted to the model as feedback (as an\n            `Error` value with an absent or serializable `meta` field).\n        tools: a mapping from supported tool interfaces to\n            implementations. Tools themselves can be implemented using\n            arbitrary strategies or queries, allowing the integration of\n            horizontal and vertical LLM pipelines.\n        inner_policy_type: Ambient inner policy type. This information\n            is not used at runtime but it can be provided to help type\n            inference when necessary.\n    \"\"\"\n\n    prefix: dp.AnswerPrefix = []\n    stats = InteractStats(num_rejected=0, num_tool_call_rounds=0)\n    while True:\n        resp = yield from branch(step(prefix, stats))\n        prefix += [dp.OracleMessage(\"oracle\", resp.answer)]\n        match resp.parsed:\n            case dq.FinalAnswer(a):\n                if isinstance(a, WrappedParseError):\n                    msg = dp.FeedbackMessage(\n                        kind=\"feedback\",\n                        label=a.error.label,\n                        description=a.error.description,\n                        meta=a.error.meta,\n                    )\n                    stats.num_rejected += 1\n                    prefix += [msg]\n                else:\n                    res = yield from branch(process(a, stats))\n                    if isinstance(res, dp.Error):\n                        msg = dp.FeedbackMessage(\n                            kind=\"feedback\",\n                            label=res.label,\n                            description=res.description,\n                            meta=res.meta,\n                        )\n                        stats.num_rejected += 1\n                        prefix += [msg]\n                    else:\n                        return res\n            case dq.ToolRequests(tc):\n                for i, t in enumerate(tc):\n                    assert tools is not None\n                    tres = yield from branch(tools[type(t)](t))\n                    msg = dp.ToolResult(\n                        \"tool\",\n                        resp.answer.tool_calls[i],\n                        t.render_result(tres),\n                    )\n                    prefix += [msg]\n                stats.num_tool_call_rounds += 1\n</code></pre>"},{"location":"reference/stdlib/algorithms/#policies","title":"Policies","text":""},{"location":"reference/stdlib/algorithms/#delphyne.stdlib.search.dfs.dfs","title":"dfs","text":"<pre><code>dfs(\n    tree: Tree[Branch | Fail, P, T],\n    env: PolicyEnv,\n    policy: P,\n    max_depth: int | None = None,\n    max_branching: int | None = None,\n) -&gt; StreamGen[T]\n</code></pre> <p>The Standard Depth-First Search Algorithm.</p> <p>Whenever a branching node is encountered, branching candidates are lazily enumerated and the corresponding child recursively searched.</p> <p>Attributes:</p> Name Type Description <code>max_depth</code> <code>optional</code> <p>maximum number of branching nodes that can be traversed in a path to success.</p> <code>max_branching</code> <code>optional</code> <p>maximum number of children explored at each branching node.</p> Source code in <code>src/delphyne/stdlib/search/dfs.py</code> <pre><code>@search_policy\ndef dfs[P, T](\n    tree: Tree[Branch | Fail, P, T],\n    env: PolicyEnv,\n    policy: P,\n    max_depth: int | None = None,\n    max_branching: int | None = None,\n) -&gt; StreamGen[T]:\n    \"\"\"\n    The Standard Depth-First Search Algorithm.\n\n    Whenever a branching node is encountered, branching candidates are\n    lazily enumerated and the corresponding child recursively searched.\n\n    Attributes:\n        max_depth (optional): maximum number of branching nodes\n            that can be traversed in a path to success.\n        max_branching (optional): maximum number of children explored at\n            each branching node.\n    \"\"\"\n    assert max_branching is None or max_branching &gt; 0\n    match tree.node:\n        case Success(x):\n            yield Solution(x)\n        case Fail():\n            pass\n        case Branch(cands):\n            if max_depth is not None and max_depth &lt;= 0:\n                return\n            cands = cands.stream(env, policy)\n            if max_branching is not None:\n                cands = cands.take(max_branching, strict=True)\n            yield from cands.bind(\n                lambda a: dfs(\n                    max_depth=max_depth - 1 if max_depth is not None else None,\n                    max_branching=max_branching,\n                )(tree.child(a.tracked), env, policy).gen()\n            ).gen()\n        case _:\n            unsupported_node(tree.node)\n</code></pre>"},{"location":"reference/stdlib/algorithms/#delphyne.stdlib.search.dfs.par_dfs","title":"par_dfs","text":"<pre><code>par_dfs(tree: Tree[Branch | Fail, P, T], env: PolicyEnv, policy: P) -&gt; StreamGen[T]\n</code></pre> <p>Parallel Depth-First Search.</p> <p>Whenever a branching node is encountered, all branching candidates are computed at once and the associated children are explored in parallel.</p> Source code in <code>src/delphyne/stdlib/search/dfs.py</code> <pre><code>@search_policy\ndef par_dfs[P, T](\n    tree: Tree[Branch | Fail, P, T],\n    env: PolicyEnv,\n    policy: P,\n) -&gt; StreamGen[T]:\n    \"\"\"\n    Parallel Depth-First Search.\n\n    Whenever a branching node is encountered, all branching candidates\n    are computed at once and the associated children are explored in\n    parallel.\n    \"\"\"\n    match tree.node:\n        case Success(x):\n            yield Solution(x)\n        case Fail():\n            pass\n        case Branch(cands):\n            cands = yield from cands.stream(env, policy).all()\n            yield from Stream.parallel(\n                [par_dfs()(tree.child(a.tracked), env, policy) for a in cands]\n            ).gen()\n        case _:\n            unsupported_node(tree.node)\n</code></pre>"},{"location":"reference/stdlib/algorithms/#combinators","title":"Combinators","text":""},{"location":"reference/stdlib/algorithms/#delphyne.sequence","title":"sequence","text":"<pre><code>sequence(\n    policies: Iterable[PromptingPolicy], *, stop_on_reject: bool = True\n) -&gt; PromptingPolicy\n</code></pre><pre><code>sequence(\n    policies: Iterable[SearchPolicy[N]], *, stop_on_reject: bool = True\n) -&gt; SearchPolicy[N]\n</code></pre><pre><code>sequence(\n    policies: Iterable[Policy[N, P]], *, stop_on_reject: bool = True\n) -&gt; Policy[N, P]\n</code></pre> <pre><code>sequence(policies: Iterable[_AnyPolicy], *, stop_on_reject: bool = True) -&gt; _AnyPolicy\n</code></pre> <p>Try a list of policies, search policies, or prompting policies in sequence.</p> <ul> <li>policies: An iterable of policies, search policies, or prompting       policies to try in sequence.</li> <li>stop_on_reject: If True, stop the sequence as soon as one policy       sees all its resource requests denied. Note that this is       necessary for termination when <code>policies</code> is an infinite       iterator.</li> </ul> Source code in <code>src/delphyne/stdlib/misc.py</code> <pre><code>def sequence(\n    policies: Iterable[_AnyPolicy],\n    *,\n    stop_on_reject: bool = True,\n) -&gt; _AnyPolicy:\n    \"\"\"\n    Try a list of policies, search policies, or prompting policies in\n    sequence.\n\n    Attributes:\n    - policies: An iterable of policies, search policies, or prompting\n          policies to try in sequence.\n    - stop_on_reject: If True, stop the sequence as soon as one policy\n          sees all its resource requests denied. Note that this is\n          necessary for termination when `policies` is an infinite\n          iterator.\n    \"\"\"\n\n    it = iter(policies)\n    first = next(it)\n    if isinstance(first, PromptingPolicy):\n        return sequence_prompting_policies(\n            cast(Iterable[PromptingPolicy], policies),\n            stop_on_reject=stop_on_reject,\n        )\n    elif isinstance(first, SearchPolicy):\n        return sequence_search_policies(\n            cast(Iterable[SearchPolicy[Any]], policies),\n            stop_on_reject=stop_on_reject,\n        )\n    else:\n        assert isinstance(first, Policy)\n        return sequence_policies(\n            cast(Iterable[Policy[Any, Any]], policies),\n            stop_on_reject=stop_on_reject,\n        )\n</code></pre>"},{"location":"reference/stdlib/algorithms/#delphyne.or_else","title":"or_else","text":"<pre><code>or_else(main: PromptingPolicy, other: PromptingPolicy) -&gt; PromptingPolicy\n</code></pre><pre><code>or_else(main: SearchPolicy[N], other: SearchPolicy[N]) -&gt; SearchPolicy[N]\n</code></pre><pre><code>or_else(main: Policy[N, P], other: Policy[N, P]) -&gt; Policy[N, P]\n</code></pre> <pre><code>or_else(main: _AnyPolicy, other: _AnyPolicy) -&gt; _AnyPolicy\n</code></pre> <p>Take two policies, search policies, or prompting policies as arguments. Try the first one, and then the second one only if it fails (i.e., it does not produce any solution).</p> Source code in <code>src/delphyne/stdlib/misc.py</code> <pre><code>def or_else(main: _AnyPolicy, other: _AnyPolicy) -&gt; _AnyPolicy:\n    \"\"\"\n    Take two policies, search policies, or prompting policies as\n    arguments. Try the first one, and then the second one only if it\n    fails (i.e., it does not produce any solution).\n    \"\"\"\n    if isinstance(main, PromptingPolicy):\n        assert isinstance(other, PromptingPolicy)\n        return prompting_policy_or_else(main, other)\n    elif isinstance(main, SearchPolicy):\n        assert isinstance(other, SearchPolicy)\n        return search_policy_or_else(main, other)\n    else:\n        return policy_or_else(main, other)  # type: ignore\n</code></pre>"},{"location":"reference/stdlib/algorithms/#delphyne.nofail","title":"nofail","text":"<pre><code>nofail(space: Opaque[P, A], *, default: B) -&gt; Opaque[P, A | B]\n</code></pre> <p>Modify an opaque space to that branching over it can never fail.</p> <p>If the stream associated with the opaque space gets exhausted and no solution is produced, the provided default value is used.</p> <p>In demonstrations, the default value can be selected by using the <code>#no_fail_default</code> hint.</p> Source code in <code>src/delphyne/stdlib/misc.py</code> <pre><code>def nofail[P, A, B](space: Opaque[P, A], *, default: B) -&gt; Opaque[P, A | B]:\n    \"\"\"\n    Modify an opaque space to that branching over it can never fail.\n\n    If the stream associated with the opaque space gets exhausted and no\n    solution is produced, the provided default value is used.\n\n    In demonstrations, the default value can be selected by using the\n    `#no_fail_default` hint.\n    \"\"\"\n    try_policy = dfs() @ elim_flag(NoFailFlag, \"no_fail_try\")\n    def_policy = dfs() @ elim_flag(NoFailFlag, \"no_fail_default\")\n    search_policy = or_else(try_policy, def_policy)\n    return nofail_strategy(space, default=default).using(\n        lambda p: search_policy &amp; p\n    )\n</code></pre>"},{"location":"reference/stdlib/algorithms/#delphyne.iterate","title":"iterate","text":"<pre><code>iterate(\n    next: Callable[[S | None], Opaque[P, tuple[T | None, S]]],\n    transform_stream: Callable[[P], StreamTransformer | None] | None = None,\n) -&gt; Opaque[P, T]\n</code></pre> <p>Iteratively call a strategy or query, repeatedly feeding back the last call's output state into a new call and yielding values along the way.</p> <p>A standard use case is to repeatedly call a query or strategy with a blacklist of previously generated values, so as to produce diverse success values.</p> <p>Parameters:</p> Name Type Description Default <code>next</code> <code>Callable[[S | None], Opaque[P, tuple[T | None, S]]]</code> <p>A parametric opaque space, induced by a query or stratey that takes a state as an input (or <code>None</code> initially) and outputs a new state, along with a generated value.</p> required <code>transform_stream</code> <code>Callable[[P], StreamTransformer | None] | None</code> <p>An optional mapping from the inner policy to a stream transformer to be applied to the resulting stream of generated values.</p> <code>None</code> <p>Returns:</p> Type Description <code>Opaque[P, T]</code> <p>An opaque space enumerating all generated values.</p> Source code in <code>src/delphyne/stdlib/search/iteration.py</code> <pre><code>def iterate[P, S, T](\n    next: Callable[[S | None], Opaque[P, tuple[T | None, S]]],\n    transform_stream: Callable[[P], StreamTransformer | None] | None = None,\n) -&gt; Opaque[P, T]:\n    \"\"\"\n    Iteratively call a strategy or query, repeatedly feeding back the\n    last call's output state into a new call and yielding values along\n    the way.\n\n    A standard use case is to repeatedly call a query or strategy with a\n    blacklist of previously generated values, so as to produce diverse\n    success values.\n\n    Arguments:\n        next: A parametric opaque space, induced by a query or stratey\n            that takes a state as an input (or `None` initially) and\n            outputs a new state, along with a generated value.\n        transform_stream: An optional mapping from the inner policy to a\n            stream transformer to be applied to the resulting stream of\n            generated values.\n\n    Returns:\n        An opaque space enumerating all generated values.\n    \"\"\"\n\n    def iterate_policy(inner_policy: P):\n        policy = _search_iteration()\n        if transform_stream is not None:\n            trans = transform_stream(inner_policy)\n            if trans is not None:\n                policy = trans @ policy\n        return policy &amp; inner_policy\n\n    return _iterate(next).using(iterate_policy)\n</code></pre>"},{"location":"reference/stdlib/algorithms/#opaque-spaces-sugar","title":"Opaque Spaces Sugar","text":""},{"location":"reference/stdlib/algorithms/#delphyne.just_dfs","title":"just_dfs","text":"<pre><code>just_dfs(policy: P) -&gt; Policy[Branch | Fail, P]\n</code></pre> <p>Convenience shortcut to avoid passing lambdas to the <code>get_policy</code> argument of <code>using</code>, when using DFS in combination with the ambient inner policy.</p> Source code in <code>src/delphyne/stdlib/misc.py</code> <pre><code>def just_dfs[P](policy: P) -&gt; Policy[Branch | Fail, P]:\n    \"\"\"\n    Convenience shortcut to avoid passing lambdas to the `get_policy`\n    argument of `using`, when using DFS in combination with the ambient\n    inner policy.\n    \"\"\"\n    return dfs() &amp; policy\n</code></pre>"},{"location":"reference/stdlib/algorithms/#delphyne.just_compute","title":"just_compute","text":"<pre><code>just_compute(policy: P) -&gt; Policy[Compute, P]\n</code></pre> <p>Convenience shortcut to avoid passing lambdas to the <code>get_policy</code> argument of <code>using</code>, in the case of sub-strategies that only feature the <code>Compute</code> effect.</p> Source code in <code>src/delphyne/stdlib/misc.py</code> <pre><code>def just_compute[P](policy: P) -&gt; Policy[Compute, P]:\n    \"\"\"\n    Convenience shortcut to avoid passing lambdas to the `get_policy`\n    argument of `using`, in the case of sub-strategies that only feature\n    the `Compute` effect.\n    \"\"\"\n    return dfs() @ elim_compute() &amp; policy\n</code></pre>"},{"location":"reference/stdlib/algorithms/#delphyne.ambient_pp","title":"ambient_pp","text":"<pre><code>ambient_pp(policy: PromptingPolicy) -&gt; PromptingPolicy\n</code></pre> <p>Convenience shortcut to avoid passing lambdas to the <code>get_policy</code> argument of <code>Query.using</code>, when using the ambient inner policy as a prompting policy.</p> Source code in <code>src/delphyne/stdlib/misc.py</code> <pre><code>def ambient_pp(policy: PromptingPolicy) -&gt; PromptingPolicy:\n    \"\"\"\n    Convenience shortcut to avoid passing lambdas to the `get_policy`\n    argument of `Query.using`, when using the ambient inner policy as a\n    prompting policy.\n    \"\"\"\n    return policy\n</code></pre>"},{"location":"reference/stdlib/algorithms/#delphyne.ambient","title":"ambient","text":"<pre><code>ambient(policy: F) -&gt; F\n</code></pre> <p>Convenience shortcut to avoid passing lambdas to the <code>get_policy</code> argument of <code>Query.using</code>, when using the ambient inner policy as a sub-policy (or as a sub- prompting policy).</p> Source code in <code>src/delphyne/stdlib/misc.py</code> <pre><code>def ambient[F](policy: F) -&gt; F:\n    \"\"\"\n    Convenience shortcut to avoid passing lambdas to the `get_policy`\n    argument of `Query.using`, when using the ambient inner policy as a\n    sub-policy (or as a sub- prompting policy).\n    \"\"\"\n    return policy\n</code></pre>"},{"location":"reference/stdlib/algorithms/#universal-queries","title":"Universal Queries","text":""},{"location":"reference/stdlib/algorithms/#delphyne.UniversalQuery","title":"UniversalQuery  <code>dataclass</code>","text":"<p>               Bases: <code>Query[object]</code></p> <p>A universal query, implicitly defined by the surrounding context of its call. See <code>guess</code> for more information.</p> <p>Attributes:</p> Name Type Description <code>strategy</code> <code>str</code> <p>Fully qualified name of the surrounding strategy (e.g., <code>my_package.my_module.my_strategy</code>).</p> <code>expected_type</code> <code>str</code> <p>A string rendition of the expected answer type.</p> <code>tags</code> <code>Sequence[str]</code> <p>Tags associated with the space induced by the query, which can be used to locate the exact location where the query is issued (the default tag takes the name of the variable that the query result is assigned to).</p> <code>locals</code> <code>dict[str, object]</code> <p>A dictionary that provides the values of a subset of local variables or expressions (as JSON values).</p> <p>Experimental</p> <p>This feature is experimental and subject to change.</p> Source code in <code>src/delphyne/stdlib/universal_queries.py</code> <pre><code>@dataclass\nclass UniversalQuery(Query[object]):\n    \"\"\"\n    A universal query, implicitly defined by the surrounding context of\n    its call. See `guess` for more information.\n\n    Attributes:\n        strategy: Fully qualified name of the surrounding strategy\n            (e.g., `my_package.my_module.my_strategy`).\n        expected_type: A string rendition of the expected answer type.\n        tags: Tags associated with the space induced by the query, which\n            can be used to locate the exact location where the query is\n            issued (the default tag takes the name of the variable that\n            the query result is assigned to).\n        locals: A dictionary that provides the values of a subset of\n            local variables or expressions (as JSON values).\n\n    !!! warning \"Experimental\"\n        This feature is experimental and subject to change.\n    \"\"\"\n\n    # TODO: add a `context` field where we store objects whose\n    # documentation or source should be added to the prompt.\n\n    strategy: str\n    expected_type: str\n    tags: Sequence[str]\n    locals: dict[str, object]\n\n    __parser__ = last_code_block.yaml\n\n    @override\n    def default_tags(self):\n        return self.tags\n\n    @property\n    def strategy_source(self) -&gt; str:\n        \"\"\"\n        Return the source code of the strategy that contains this query.\n        \"\"\"\n        strategy_obj = _load_from_qualified_name(self.strategy)\n        assert callable(strategy_obj)\n        return _source_code(strategy_obj)\n</code></pre>"},{"location":"reference/stdlib/algorithms/#delphyne.UniversalQuery.strategy_source","title":"strategy_source  <code>property</code>","text":"<pre><code>strategy_source: str\n</code></pre> <p>Return the source code of the strategy that contains this query.</p>"},{"location":"reference/stdlib/algorithms/#delphyne.guess","title":"guess","text":"<pre><code>guess(\n    annot: type[T], /, *, using: Sequence[object]\n) -&gt; Strategy[Branch | Fail, IPDict, T]\n</code></pre><pre><code>guess(\n    annot: TypeAnnot[Any], /, *, using: Sequence[object]\n) -&gt; Strategy[Branch | Fail, IPDict, Any]\n</code></pre> <pre><code>guess(\n    annot: TypeAnnot[Any], /, *, using: Sequence[object]\n) -&gt; Strategy[Branch | Fail, IPDict, Any]\n</code></pre> <p>Attempt to guess a value of a given type, using the surrounding context of the call site along with the value of some local variables or expressions.</p> <p>This function inspects the call stack to determine the context in which it is called and issues a <code>UniversalQuery</code>, with a tag corresponding to the name of the assigned variable. A failure node is issued if the oracle result cannot be parsed into the expected type. For example:</p> <pre><code>res = yield from guess(int, using=[x, y.summary()])\n</code></pre> <p>issues a <code>UniversalQuery</code> query tagged <code>res</code>, with attribute <code>locals</code> a dictionary with string keys <code>\"x\"</code> and <code>\"y.summary()\"</code>.</p> <p>Attributes:</p> Name Type Description <code>annot</code> <p>The expected type of the value to be guessed.</p> <code>using</code> <p>A sequence of local variables or expressions whose value should be communicated to the oracle (a label for each expression is automatically generated using source information).</p> <p>Note</p> <p>Our use of an overloaded type should not be necessary anymore when <code>TypeExpr</code> is released with Python 3.14.</p> <p>Experimental</p> <p>This feature is experimental and subject to change.</p> Source code in <code>src/delphyne/stdlib/universal_queries.py</code> <pre><code>def guess(\n    annot: TypeAnnot[Any], /, *, using: Sequence[object]\n) -&gt; dp.Strategy[Branch | Fail, IPDict, Any]:\n    \"\"\"\n    Attempt to guess a value of a given type, using the surrounding\n    context of the call site along with the value of some local\n    variables or expressions.\n\n    This function inspects the call stack to determine the context in\n    which it is called and issues a `UniversalQuery`, with a tag\n    corresponding to the name of the assigned variable. A failure node is\n    issued if the oracle result cannot be parsed into the expected type.\n    For example:\n\n    ```python\n    res = yield from guess(int, using=[x, y.summary()])\n    ```\n\n    issues a `UniversalQuery` query tagged `res`, with attribute\n    `locals` a dictionary with string keys `\"x\"` and `\"y.summary()\"`.\n\n    Attributes:\n        annot: The expected type of the value to be guessed.\n        using: A sequence of local variables or expressions whose value\n            should be communicated to the oracle (a label for each\n            expression is automatically generated using source information).\n\n    !!! note\n        Our use of an overloaded type should not be necessary anymore\n        when `TypeExpr` is released with Python 3.14.\n\n    !!! warning \"Experimental\"\n        This feature is experimental and subject to change.\n    \"\"\"\n\n    # Extracting the name of the surrounding strategy\n    strategy = surrounding_qualname(skip=1)\n    assert strategy is not None\n    strategy = _rename_main_module_in_qualified_name(strategy)\n\n    # Extracting the name of the variable being assigned\n    cur_instr_src = current_instruction_source(skip=1)\n    ret_val_name = assigned_var_name(cur_instr_src)\n    assert isinstance(ret_val_name, str)\n\n    # Computing the 'locals' dictionary\n    guess_args = call_argument_sources(cur_instr_src, guess)\n    assert guess_args is not None\n    _args, kwargs = guess_args\n    using_args = _parse_list_of_ids(kwargs[\"using\"])\n    assert len(using) == len(using_args)\n    locals = {k: pydantic_dump(type(v), v) for k, v in zip(using_args, using)}\n\n    # Building the query\n    query = UniversalQuery(strategy, str(annot), [ret_val_name], locals)\n\n    ret = yield from branch(query.using(...))\n    try:\n        parsed = pydantic_load(annot, ret)\n    except Exception as e:\n        assert_never((yield from fail(\"parse_error\", message=str(e))))\n    return parsed\n</code></pre>"},{"location":"reference/stdlib/algorithms/#best-first-search","title":"Best-First Search","text":""},{"location":"reference/stdlib/algorithms/#delphyne.best_first_search","title":"best_first_search","text":"<pre><code>best_first_search(\n    tree: Tree[Branch | Factor | Value | Fail, P, T],\n    env: PolicyEnv,\n    policy: P,\n    child_confidence_prior: Callable[[int, int], float],\n    max_depth: int | None = None,\n) -&gt; StreamGen[T]\n</code></pre> <p>Best First Search Algorithm.</p> <p>Nodes can be branching nodes or factor nodes. Factor nodes feature a confidence score in the [0, 1] interval. The total confidence of any node in the tree is the product of all confidence factors found on the path from the root to this node. The algorithm stores all visited branching nodes in a priority queue. At every step, it picks the node with highest confidence and spends an atomic amount of effort trying to generate a new child. If it succeeds, the first descendant branching node is added to the tree and the algorithm continues.</p> <p>Also, the total confidence of each branching node is multiplied by an additional penalty factor that depends on how many children have been generated already, using the <code>child_confidence_prior</code> argument. This argument is a function that takes as its first argument the depth of the current branching node (0 for the root, only incrementing when meeting other branching nodes) and as its second argument how many children have been generated so far. It returns the additional penalty to be added.</p> <p>The <code>max_depth</code> parameter indicates the maximum depth a branch node can have. The root has depth 0 and and only branch nodes count towards increasing the depth.</p> Source code in <code>src/delphyne/stdlib/search/bestfs.py</code> <pre><code>@search_policy\ndef best_first_search[P, T](\n    tree: dp.Tree[Branch | Factor | Value | Fail, P, T],\n    env: PolicyEnv,\n    policy: P,\n    child_confidence_prior: Callable[[int, int], float],\n    max_depth: int | None = None,\n) -&gt; dp.StreamGen[T]:\n    \"\"\"\n    Best First Search Algorithm.\n\n    Nodes can be branching nodes or factor nodes. Factor nodes feature a\n    confidence score in the [0, 1] interval. The total confidence of any\n    node in the tree is the product of all confidence factors found on\n    the path from the root to this node. The algorithm stores all\n    visited branching nodes in a priority queue. At every step, it picks\n    the node with highest confidence and spends an atomic amount of\n    effort trying to generate a new child. If it succeeds, the first\n    descendant branching node is added to the tree and the algorithm\n    continues.\n\n    Also, the total confidence of each branching node is multiplied by\n    an additional penalty factor that depends on how many children have\n    been generated already, using the `child_confidence_prior` argument.\n    This argument is a function that takes as its first argument the\n    depth of the current branching node (0 for the root, only\n    incrementing when meeting other branching nodes) and as its second\n    argument how many children have been generated so far. It returns\n    the additional penalty to be added.\n\n    The `max_depth` parameter indicates the maximum depth a branch node\n    can have. The root has depth 0 and and only branch nodes count\n    towards increasing the depth.\n    \"\"\"\n    # `counter` is used to assign ids that are used to solve ties in the\n    # priority queue (the older element gets priority).\n    counter = 0\n    pqueue: list[_PriorityItem] = []  # a heap\n\n    def push_fresh_node(\n        tree: dp.Tree[Branch | Factor | Value | Fail, Any, Any],\n        confidence: float,\n        depth: int,\n    ) -&gt; dp.StreamGen[T]:\n        match tree.node:\n            case dp.Success():\n                yield dp.Solution(tree.node.success)\n            case Fail():\n                pass\n            case Factor() | Value():\n                if isinstance(tree.node, Value):\n                    penalty_fun = tree.node.value(policy)\n                else:\n                    penalty_fun = tree.node.factor(policy)\n                # Evaluate metrics if a penalty function is provided\n                if penalty_fun is not None:\n                    eval_stream = tree.node.eval.stream(env, policy)\n                    eval = yield from eval_stream.first()\n                    # If we failed to evaluate the metrics, we give up.\n                    if eval is None:\n                        return\n                    if isinstance(tree.node, Value):\n                        confidence = penalty_fun(eval.tracked.value)\n                    else:\n                        confidence *= penalty_fun(eval.tracked.value)\n                yield from push_fresh_node(tree.child(None), confidence, depth)\n            case Branch():\n                if max_depth is not None and depth &gt; max_depth:\n                    return\n                state = _NodeState(\n                    depth=depth,\n                    children=[],\n                    confidence=confidence,\n                    stream=[tree.node.cands.stream(env, policy)],\n                    node=tree.node,\n                    tree=tree,\n                    next_actions=[],\n                )\n                nonlocal counter\n                counter += 1\n                prior = child_confidence_prior(depth, 0)\n                item_confidence = confidence * prior\n                item = _PriorityItem(-item_confidence, counter, state)\n                heapq.heappush(pqueue, item)\n            case _:\n                unsupported_node(tree.node)\n\n    def reinsert_node(state: _NodeState) -&gt; None:\n        nonlocal counter\n        counter += 1\n        prior = child_confidence_prior(state.depth, len(state.children))\n        item_confidence = state.confidence * prior\n        item = _PriorityItem(-item_confidence, counter, state)\n        heapq.heappush(pqueue, item)\n\n    # Put the root into the queue.\n    yield from push_fresh_node(tree, 1.0, 0)\n    while pqueue:\n        state = heapq.heappop(pqueue).node_state\n        if not state.next_actions:\n            if not state.stream[0]:\n                # No more actions to take, we do not put the node back.\n                continue\n            generated, _, next = yield from state.stream[0].next()\n            state.next_actions.extend([a.tracked for a in generated])\n            state.stream[0] = next\n        if state.next_actions:\n            cand = state.next_actions.pop(0)\n            child = state.tree.child(cand)\n            state.children.append(child.ref)\n            yield from push_fresh_node(child, 1, state.depth + 1)\n        # We put the node back into the queue\n        reinsert_node(state)\n</code></pre>"},{"location":"reference/stdlib/algorithms/#abduction","title":"Abduction","text":""},{"location":"reference/stdlib/algorithms/#delphyne.Abduction","title":"Abduction  <code>dataclass</code>","text":"<p>               Bases: <code>Node</code></p> <p>Node for the singleton tree produced by <code>abduction</code>. See <code>abduction</code> for details.</p> <p>An action is a successful proof of the main goal.</p> Source code in <code>src/delphyne/stdlib/search/abduction.py</code> <pre><code>@dataclass\nclass Abduction(dp.Node):\n    \"\"\"\n    Node for the singleton tree produced by `abduction`.\n    See `abduction` for details.\n\n    An action is a successful proof of the main goal.\n    \"\"\"\n\n    prove: Callable[\n        [Sequence[tuple[_Fact, _Proof]], _Fact | None],\n        OpaqueSpace[Any, _Status],\n    ]\n    suggest: Callable[\n        [_Feedback],\n        OpaqueSpace[Any, Sequence[_Fact]],\n    ]\n    search_equivalent: Callable[\n        [Sequence[_Fact], _Fact],\n        OpaqueSpace[Any, _Fact | None],\n    ]\n    redundant: Callable[\n        [Sequence[_Fact], _Fact],\n        OpaqueSpace[Any, bool],\n    ]\n\n    def navigate(self) -&gt; dp.Navigation:\n        def aux(fact: dp.Tracked[_Fact] | None) -&gt; dp.Navigation:\n            # Take a fact as an argument and return a list of\n            # (proved_fact, proof) pairs.\n            res = yield self.prove([], fact)\n            status, payload = res[0], res[1]\n            if status.value == \"proved\":\n                return [(fact, payload)]\n            elif status.value == \"disproved\":\n                return []\n            else:\n                assert status.value == \"feedback\"\n                feedback = payload\n                suggestions = yield self.suggest(feedback)\n                proved: list[Any] = []\n                for s in suggestions:\n                    extra: Any = yield from aux(s)\n                    proved.extend(extra)\n                res = yield self.prove(proved, fact)\n                status, payload = res[0], res[1]\n                if status.value == \"proved\":\n                    proved.append((fact, payload))\n                return _remove_duplicates(proved, by=lambda x: drop_refs(x[0]))\n\n        proved: Any = yield from aux(None)\n        main_proof = _find_assoc(proved, None)\n        if main_proof is None:\n            raise dp.NavigationError(\n                \"No proof for the main goal was produced.\"\n            )\n        return main_proof\n</code></pre>"},{"location":"reference/stdlib/algorithms/#delphyne.abduction","title":"abduction","text":"<pre><code>abduction(\n    prove: Callable[\n        [Sequence[tuple[Fact, Proof]], Fact | None],\n        Opaque[P, AbductionStatus[Feedback, Proof]],\n    ],\n    suggest: Callable[[Feedback], Opaque[P, Sequence[Fact]]],\n    search_equivalent: Callable[[Sequence[Fact], Fact], Opaque[P, Fact | None]],\n    redundant: Callable[[Sequence[Fact], Fact], Opaque[P, bool]],\n    inner_policy_type: type[P] | None = None,\n) -&gt; Strategy[Abduction, P, Proof]\n</code></pre> <p>Higher-order strategy for proving a fact via recursive abduction.</p> <p>Parameters:</p> Name Type Description Default <code>prove</code> <code>Callable[[Sequence[tuple[Fact, Proof]], Fact | None], Opaque[P, AbductionStatus[Feedback, Proof]]]</code> <p>take a sequence of already established facts as an argument along with a new fact, and attempt to prove this new fact. Three outcomes are possible: the fact is proved, disproved, or a list of suggestions are made that might be helpful to prove first. <code>None</code> denotes the top-level goal to be proved.</p> required <code>suggest</code> <code>Callable[[Feedback], Opaque[P, Sequence[Fact]]]</code> <p>take some feedback from the <code>prove</code> function and return a sequence of fact candidates that may be useful to prove before reattempting the original proof.</p> required <code>search_equivalent</code> <code>Callable[[Sequence[Fact], Fact], Opaque[P, Fact | None]]</code> <p>take a collection of facts along with a new one, and return either the first fact of the list equivalent to the new fact or <code>None</code>. This is used to avoid spending search in proving equivalent facts.</p> required <code>redundant</code> <code>Callable[[Sequence[Fact], Fact], Opaque[P, bool]]</code> <p>take a collection of established facts and decide whether they imply a new fact candidate. This is useful to avoid trying to prove and accumulating redundant facts.</p> required <p>Returns:</p> Type Description <code>Strategy[Abduction, P, Proof]</code> <p>a proof of the top-level goal.</p> Source code in <code>src/delphyne/stdlib/search/abduction.py</code> <pre><code>def abduction[Fact, Feedback, Proof, P](\n    prove: Callable[\n        [Sequence[tuple[Fact, Proof]], Fact | None],\n        Opaque[P, AbductionStatus[Feedback, Proof]],\n    ],\n    suggest: Callable[\n        [Feedback],\n        Opaque[P, Sequence[Fact]],\n    ],\n    search_equivalent: Callable[\n        [Sequence[Fact], Fact], Opaque[P, Fact | None]\n    ],\n    redundant: Callable[[Sequence[Fact], Fact], Opaque[P, bool]],\n    inner_policy_type: type[P] | None = None,\n) -&gt; dp.Strategy[Abduction, P, Proof]:\n    \"\"\"\n    Higher-order strategy for proving a fact via recursive abduction.\n\n    Arguments:\n      prove: take a sequence of already established facts as an\n        argument along with a new fact, and attempt to prove this new\n        fact. Three outcomes are possible: the fact is proved,\n        disproved, or a list of suggestions are made that might be\n        helpful to prove first. `None` denotes the top-level goal to be\n        proved.\n\n      suggest: take some feedback from the `prove` function and return a\n        sequence of fact candidates that may be useful to prove before\n        reattempting the original proof.\n\n      search_equivalent: take a collection of facts along with a new\n        one, and return either the first fact of the list equivalent to\n        the new fact or `None`. This is used to avoid spending search in\n        proving equivalent facts.\n\n      redundant: take a collection of established facts and decide\n        whether they imply a new fact candidate. This is useful to avoid\n        trying to prove and accumulating redundant facts.\n\n    Returns:\n      a proof of the top-level goal.\n    \"\"\"\n    res = yield spawn_node(\n        Abduction,\n        prove=prove,\n        suggest=suggest,\n        search_equivalent=search_equivalent,\n        redundant=redundant,\n    )\n    return cast(Proof, res)\n</code></pre>"},{"location":"reference/stdlib/algorithms/#delphyne.abduct_and_saturate","title":"abduct_and_saturate","text":"<pre><code>abduct_and_saturate(\n    tree: Tree[Abduction, P, Proof],\n    env: PolicyEnv,\n    policy: P,\n    max_rollout_depth: int = 3,\n    scoring_function: ScoringFunction = _default_scoring_function,\n    verbose: bool = False,\n) -&gt; StreamGen[Proof]\n</code></pre> <p>A standard, sequential policy to process abduction nodes.</p> <p>Note: facts must be hashable.</p> Source code in <code>src/delphyne/stdlib/search/abduction.py</code> <pre><code>@search_policy\ndef abduct_and_saturate[P, Proof](\n    tree: dp.Tree[Abduction, P, Proof],\n    env: PolicyEnv,\n    policy: P,\n    max_rollout_depth: int = 3,\n    scoring_function: ScoringFunction = _default_scoring_function,\n    verbose: bool = False,\n) -&gt; dp.StreamGen[Proof]:\n    \"\"\"\n    A standard, sequential policy to process abduction nodes.\n\n    Note: facts must be hashable.\n    \"\"\"\n\n    # TODO: we are currently allowing redundant facts in `proved` since\n    # we never clean up `proved`. For example, if `x &gt; 0` is established\n    # before the stronger `x &gt;= 0`, the former won't be deleted from\n    # `proved`.\n\n    # Invariant: `candidates`, `proved`, `disproved` and `redundant` are\n    # disjoint. Together, they form the set of \"canonical facts\".\n    candidates: dict[_EFact, _CandInfo] = {}\n    proved: dict[_EFact, _Proof] = {}\n    disproved: set[_EFact] = set()\n    # Facts that are implied by the conjunction of all proved facts.\n    redundant: set[_EFact] = set()\n\n    # It is easier to manipulate untracked facts and so we keep the\n    # correspondence with tracked facts here.\n    # Invariant: all canonical facts are included in `tracked`.\n    tracked: dict[_EFact, _Tracked_EFact] = {None: None}\n\n    # The `equivalent` dict maps a fact to its canonical equivalent\n    # representative that is somewhere in `candidates`, `proved`,\n    # `disproved` or `redundant`.\n    equivalent: dict[_EFact, _EFact] = {}\n\n    # Can a new fact make a candidate redundant? YES. So we should also\n    # do this in `propagate`\n\n    assert isinstance(tree.node, Abduction)\n    node = tree.node\n\n    def dbg(msg: str):\n        if verbose:\n            log(env, msg)\n\n    def all_canonical() -&gt; Sequence[_EFact]:\n        return [*candidates, *proved, *disproved, *redundant]\n\n    def is_redundant(f: _EFact) -&gt; dp.StreamContext[bool]:\n        if f is None:\n            return False\n        respace = node.redundant([tracked[o] for o in proved], tracked[f])\n        res = yield from respace.stream(env, policy).first()\n        if res is None:\n            raise _Abort()\n        return res.tracked.value\n\n    def add_candidate(c: _EFact) -&gt; dp.StreamContext[None]:\n        # Take a new fact and put it into either `proved`, `disproved`,\n        # `candidates` or `redundant`. If a canonical fact is passed,\n        # nothing is done.\n        if c in all_canonical():\n            return\n        # We first make a redundancy check\n        if (yield from is_redundant(c)):\n            dbg(f\"Redundant: {c}\")\n            redundant.add(c)\n            return\n        # If not redundant, we try and prove it\n        facts_list = [(tracked[f], p) for f, p in proved.items()]\n        pstream = node.prove(facts_list, tracked[c]).stream(env, policy)\n        res = yield from pstream.first()\n        if res is None:\n            raise _Abort()\n        status, payload = res.tracked[0], res.tracked[1]\n        if status.value == \"disproved\":\n            disproved.add(c)\n            dbg(f\"Disproved: {c}\")\n            if c is None:\n                raise _Abort()\n        elif status.value == \"proved\":\n            proved[c] = payload\n            dbg(f\"Proved: {c}\")\n            if c is None:\n                raise _ProofFound()\n        else:\n            candidates[c] = _CandInfo(payload, 0, 0)\n\n    def propagate() -&gt; dp.StreamContext[Literal[\"updated\", \"not_updated\"]]:\n        # Go through each candidate and see if it is now provable\n        # assuming all established facts.\n        old_candidates = candidates.copy()\n        candidates.clear()\n        for c, i in old_candidates.items():\n            yield from add_candidate(c)\n            if c in candidates:\n                # Restore the counters if `c` is still a candidate\n                candidates[c].num_proposed = i.num_proposed\n                candidates[c].num_visited = i.num_visited\n        return (\n            \"updated\"\n            if len(candidates) != len(old_candidates)\n            else \"not_updated\"\n        )\n\n    def saturate() -&gt; dp.StreamContext[None]:\n        # Propagate facts until saturation\n        while (yield from propagate()) == \"updated\":\n            pass\n\n    def get_canonical(f: _EFact) -&gt; dp.StreamContext[_EFact]:\n        # The result is guaranteed to be in `tracked`\n        if f in proved or f in disproved or f in candidates:\n            # Case where f is a canonical fact\n            return f\n        assert f is not None\n        if f in equivalent:\n            # Case where an equivalent canonical fact is known already\n            nf = equivalent[f]\n            assert nf in all_canonical()\n            return equivalent[f]\n        # New fact whose equivalence must be tested\n        prev = [tracked[o] for o in all_canonical() if o is not None]\n        if not prev:\n            # First fact: no need to make equivalence call\n            return f\n        eqspace = node.search_equivalent(prev, tracked[f])\n        res = yield from eqspace.stream(env, policy).first()\n        if res is None:\n            raise _Abort()\n        res = res.tracked\n        if res.value is None:\n            return f\n        elif res.value in all_canonical():\n            equivalent[f] = res.value\n            return res.value\n        else:\n            log(env, \"invalid_equivalent_call\")\n            return f\n\n    def get_raw_suggestions(c: _EFact) -&gt; dp.StreamContext[Sequence[_EFact]]:\n        assert c in candidates\n        sstream = node.suggest(candidates[c].feedback).stream(env, policy)\n        res = yield from sstream.all()\n        if not res:\n            # If no suggestions are returned, we are out of budget and\n            # abort so as to not call this again in a loop.\n            raise _Abort()\n        tracked_suggs = [s for r in res for s in r.tracked]\n        # Populate the `tracked` cache (this is the only place where new\n        # facts can be created and so the only place where `tracked`\n        # must be updated).\n        suggs = [s.value for s in tracked_suggs]\n        dbg(f\"Suggestions: {suggs}\")\n        for s, ts in zip(suggs, tracked_suggs):\n            if s not in tracked:\n                tracked[s] = ts\n        return suggs\n\n    def get_suggestions(c: _EFact) -&gt; dp.StreamContext[dict[_EFact, int]]:\n        # Return a dict representing a multiset of suggestions\n        assert c in candidates\n        raw_suggs = yield from get_raw_suggestions(c)\n        suggs: list[_EFact] = []\n        for s in raw_suggs:\n            suggs.append((yield from get_canonical(s)))\n        len_proved_old = len(proved)\n        for s in suggs:\n            yield from add_candidate(s)\n        if len_proved_old != len(proved):\n            assert len(proved) &gt; len_proved_old\n            yield from saturate()\n        suggs = [s for s in suggs if s in candidates]\n        suggs_multiset: dict[_EFact, int] = {}\n        for s in suggs:\n            if s not in suggs_multiset:\n                suggs_multiset[s] = 0\n            suggs_multiset[s] += 1\n        dbg(f\"Filtered: {suggs_multiset}\")\n        return suggs_multiset\n\n    try:\n        yield from add_candidate(None)\n        while True:\n            cur: _EFact = None\n            for _ in range(max_rollout_depth):\n                dbg(f\"Explore fact: {cur}\")\n                suggs = yield from get_suggestions(cur)\n                if not suggs:\n                    break\n                n = sum(suggs.values())\n                for s, k in suggs.items():\n                    candidates[s].num_proposed += k / n\n                infos = [candidates[c] for c in suggs]\n                best = _argmax(\n                    scoring_function(i.num_proposed, i.num_visited)\n                    for i in infos\n                )\n                cur = list(suggs.keys())[best]\n                candidates[cur].num_visited += 1\n    except _Abort:\n        return\n    except _ProofFound:\n        action = proved[None]\n        child = tree.child(action)\n        assert isinstance(child.node, dp.Success)\n        yield dp.Solution(child.node.success)\n        return\n</code></pre>"},{"location":"reference/stdlib/basic/","title":"Basic Definitions","text":""},{"location":"reference/stdlib/basic/#opaque-spaces-and-policies","title":"Opaque Spaces and Policies","text":""},{"location":"reference/stdlib/basic/#delphyne.OpaqueSpace","title":"OpaqueSpace  <code>dataclass</code>","text":"<p>               Bases: <code>Space[T]</code></p> <p>A space defined by a mapping from the ambient inner policy to a search stream.</p> <p>Opaque spaces can be defined from strategy instances (<code>StrategyInstance</code>) or from queries (<code>Query</code>) via the <code>using</code> method. Crucially, policies are unaware of how an opaque space was created, preserving abstraction.</p> <p>          Class Type Parameters:        </p> Name Bound or Constraints Description Default <code>P</code> <p>Type parameter for the ambient inner policy type.</p> required <code>T</code> <p>Type parameter for the element type.</p> required <p>Attributes:</p> Name Type Description <code>stream</code> <code>Callable[[PolicyEnv, P], Stream[T]]</code> <p>Maps the ambient inner policy to a search stream.</p> Source code in <code>src/delphyne/stdlib/opaque.py</code> <pre><code>@dataclass(frozen=True)\nclass OpaqueSpace[P, T](dp.Space[T]):\n    \"\"\"\n    A space defined by a mapping from the ambient inner policy to a\n    search stream.\n\n    Opaque spaces can be defined from strategy instances\n    (`StrategyInstance`) or from queries (`Query`) via the `using`\n    method. Crucially, policies are unaware of how an opaque space was\n    created, preserving abstraction.\n\n    Type Parameters:\n        P: Type parameter for the ambient inner policy type.\n        T: Type parameter for the element type.\n\n    Attributes:\n        stream: Maps the ambient inner policy to a search stream.\n    \"\"\"\n\n    stream: Callable[[PolicyEnv, P], Stream[T]]\n    _source: dp.NestedTree[Any, Any, T] | dp.AttachedQuery[T]\n    _tags: Sequence[dp.Tag]\n\n    @override\n    def source(self) -&gt; dp.NestedTree[Any, Any, T] | dp.AttachedQuery[T]:\n        return self._source\n\n    @override\n    def tags(self) -&gt; Sequence[dp.Tag]:\n        return self._tags\n\n    @staticmethod\n    def from_query[P1, T1](\n        query: dp.AbstractQuery[T1],\n        get_policy: Callable[[P1, Sequence[dp.Tag]], PromptingPolicy],\n    ) -&gt; \"dp.SpaceBuilder[OpaqueSpace[P1, T1]]\":\n        \"\"\"\n        Create an opaque space from a query.\n\n        The `Query.using` method is a more ergonomic wrapper.\n        \"\"\"\n\n        def build(\n            spawner: QuerySpawner, tags: Sequence[dp.Tag]\n        ) -&gt; OpaqueSpace[P1, T1]:\n            attached = spawner(query)\n            return OpaqueSpace(\n                stream=(lambda env, pol: get_policy(pol, tags)(attached, env)),\n                _source=attached,\n                _tags=tags,\n            )\n\n        return dp.SpaceBuilder(\n            build=lambda _, spawner, tags: build(spawner, tags),\n            tags=query.default_tags(),\n        )\n\n    @staticmethod\n    def from_strategy[N: dp.Node, P1, P2, T1](\n        strategy: dp.StrategyComp[N, P2, T1],\n        get_policy: Callable[[P1, Sequence[dp.Tag]], Policy[N, P2]],\n    ) -&gt; \"dp.SpaceBuilder[OpaqueSpace[P1, T1]]\":\n        \"\"\"\n        Create an opaque space from a strategy instance.\n\n        The `StrategyInstance.using` method is a more ergonomic wrapper.\n        \"\"\"\n\n        def build(\n            spawner: NestedTreeSpawner, tags: Sequence[dp.Tag]\n        ) -&gt; OpaqueSpace[P1, T1]:\n            nested = spawner(strategy)\n\n            def stream(env: PolicyEnv, policy: P1) -&gt; Stream[T1]:\n                tree = nested.spawn_tree()\n                sub = get_policy(policy, tags)\n                return sub.search(tree, env, sub.inner)\n\n            return OpaqueSpace(stream, nested, tags)\n\n        return dp.SpaceBuilder(\n            build=lambda spawner, _, tags: build(spawner, tags),\n            tags=strategy.default_tags(),\n        )\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.OpaqueSpace.from_query","title":"from_query  <code>staticmethod</code>","text":"<pre><code>from_query(\n    query: AbstractQuery[T1], get_policy: Callable[[P1, Sequence[Tag]], PromptingPolicy]\n) -&gt; SpaceBuilder[OpaqueSpace[P1, T1]]\n</code></pre> <p>Create an opaque space from a query.</p> <p>The <code>Query.using</code> method is a more ergonomic wrapper.</p> Source code in <code>src/delphyne/stdlib/opaque.py</code> <pre><code>@staticmethod\ndef from_query[P1, T1](\n    query: dp.AbstractQuery[T1],\n    get_policy: Callable[[P1, Sequence[dp.Tag]], PromptingPolicy],\n) -&gt; \"dp.SpaceBuilder[OpaqueSpace[P1, T1]]\":\n    \"\"\"\n    Create an opaque space from a query.\n\n    The `Query.using` method is a more ergonomic wrapper.\n    \"\"\"\n\n    def build(\n        spawner: QuerySpawner, tags: Sequence[dp.Tag]\n    ) -&gt; OpaqueSpace[P1, T1]:\n        attached = spawner(query)\n        return OpaqueSpace(\n            stream=(lambda env, pol: get_policy(pol, tags)(attached, env)),\n            _source=attached,\n            _tags=tags,\n        )\n\n    return dp.SpaceBuilder(\n        build=lambda _, spawner, tags: build(spawner, tags),\n        tags=query.default_tags(),\n    )\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.OpaqueSpace.from_strategy","title":"from_strategy  <code>staticmethod</code>","text":"<pre><code>from_strategy(\n    strategy: StrategyComp[N, P2, T1],\n    get_policy: Callable[[P1, Sequence[Tag]], Policy[N, P2]],\n) -&gt; SpaceBuilder[OpaqueSpace[P1, T1]]\n</code></pre> <p>Create an opaque space from a strategy instance.</p> <p>The <code>StrategyInstance.using</code> method is a more ergonomic wrapper.</p> Source code in <code>src/delphyne/stdlib/opaque.py</code> <pre><code>@staticmethod\ndef from_strategy[N: dp.Node, P1, P2, T1](\n    strategy: dp.StrategyComp[N, P2, T1],\n    get_policy: Callable[[P1, Sequence[dp.Tag]], Policy[N, P2]],\n) -&gt; \"dp.SpaceBuilder[OpaqueSpace[P1, T1]]\":\n    \"\"\"\n    Create an opaque space from a strategy instance.\n\n    The `StrategyInstance.using` method is a more ergonomic wrapper.\n    \"\"\"\n\n    def build(\n        spawner: NestedTreeSpawner, tags: Sequence[dp.Tag]\n    ) -&gt; OpaqueSpace[P1, T1]:\n        nested = spawner(strategy)\n\n        def stream(env: PolicyEnv, policy: P1) -&gt; Stream[T1]:\n            tree = nested.spawn_tree()\n            sub = get_policy(policy, tags)\n            return sub.search(tree, env, sub.inner)\n\n        return OpaqueSpace(stream, nested, tags)\n\n    return dp.SpaceBuilder(\n        build=lambda spawner, _, tags: build(spawner, tags),\n        tags=strategy.default_tags(),\n    )\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.Opaque","title":"Opaque","text":"<pre><code>Opaque = SpaceBuilder[OpaqueSpace[P, T]]\n</code></pre> <p>A convenience type alias for an opaque space builder.</p>"},{"location":"reference/stdlib/basic/#delphyne.IPDict","title":"IPDict","text":"<pre><code>IPDict = Mapping[str, Policy[Any, Any] | PromptingPolicy]\n</code></pre> <p>Type of an Inner-Policy Dictionary.</p> <p>Inner-Policy dictionaries allow to define strategies in a more concise way in exchange for less static type safety.</p> <p>Normally, an inner policy type must be defined for every strategy, and opaque spaces are created from queries or strategy by passing the <code>using</code> method a mapping from the ambient inner policy to a proper sub-policy, often in the form of an anonymous function:</p> <pre><code>@dataclass class MyInnerPolicy:\n    foo: PromptingPolicy\n    # etc\n\ndef my_strategy() -&gt; Strategy[Branch, MyInnerPolicy, str]:\n    x = yield from branch(Foo().using(lambda p: p.foo))\n    # etc\n</code></pre> <p>As an alternative, one can have a strategy use an inner policy dictionary, by passing ellipses (<code>...</code>) to the <code>using</code> method:</p> <pre><code>def my_strategy() -&gt; Strategy[Branch, IPDict, str]:\n    x = yield from branch(Foo().using(...))\n    # etc\n</code></pre> <p>When doing so, a simple Python dictionary can be used as an inner policy, whose keys are space tags (the same tags can be referenced in demonstration tests). In the example above, and since a spaces induced by a query inherits its name as a tag by default, one can define an inner policy for <code>my_strategy</code> as:</p> <pre><code>{\"Foo\": foo_prompting_policy, ...}\n</code></pre> <p>A conjunction of tags can also be specified, separated by <code>&amp;</code> (without spaces). For example, <code>{\"tag1&amp;tag2\": pp, ...}</code> associates prompting policies <code>pp</code> to spaces with both tags <code>tag1</code> and <code>tag2</code>. New tags can be added to a space builder using the <code>SpaceBuilder.tagged</code> method.</p> <p>Info</p> <p>If several entries of the inner policy dictionary apply for a given instance of <code>.using(...)</code>, a runtime error is raised.</p> <p>See <code>tests/example_strategies:generate_number</code> for another example.</p>"},{"location":"reference/stdlib/basic/#delphyne.Policy","title":"Policy  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[N, P]</code>, <code>AbstractPolicy[PolicyEnv, N, P]</code></p> <p>A pair of a search policy and of an inner policy.</p> <p>More preciely, a policy for trees with effects <code>N</code> (contravariant) gathers a search policy handling <code>N</code> along with an inner policy object of type <code>P</code> (covariant).</p> <p>Values of this type can be built concisely using the <code>&amp;</code> operator defined on type <code>SearchPolicy</code>.</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>@dataclass(frozen=True)\nclass Policy(Generic[N, P], dp.AbstractPolicy[PolicyEnv, N, P]):\n    \"\"\"\n    A pair of a search policy and of an inner policy.\n\n    More preciely, a policy for trees with effects `N` (contravariant)\n    gathers a search policy handling `N` along with an inner policy\n    object of type `P` (covariant).\n\n    Values of this type can be built concisely using the `&amp;` operator\n    defined on type `SearchPolicy`.\n    \"\"\"\n\n    _search: \"SearchPolicy[N]\"\n    _inner: P\n\n    @property\n    def search(self) -&gt; \"SearchPolicy[N]\":\n        return self._search\n\n    @property\n    def inner(self) -&gt; P:\n        return self._inner\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.SearchPolicy","title":"SearchPolicy  <code>dataclass</code>","text":"<p>               Bases: <code>AbstractSearchPolicy[PolicyEnv, N]</code></p> <p>A search policy takes as arguments a tree with a given signature (covariant type parameter <code>N</code>), a global policy environment, and an inner policy with appropriate type, and returns a search stream.</p> <p><code>SearchPolicy</code> is a subclass of <code>AbstractSearchPolicy</code>, which provides convenience features such as support for the <code>@</code> composition operator (for composing search policies with stream transformers and tree transformers) and the <code>&amp;</code> operator for pairing a search policy with an inner policy.</p> <p>Search policies can be conveniently defined using the <code>search_policy</code> decorator. See <code>dfs</code> for an example.</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>@dataclass(frozen=True)\nclass SearchPolicy[N: Node](dp.AbstractSearchPolicy[PolicyEnv, N]):\n    \"\"\"\n    A search policy takes as arguments a tree with a given signature\n    (covariant type parameter `N`), a global policy environment, and an\n    inner policy with appropriate type, and returns a search stream.\n\n    `SearchPolicy` is a subclass of `AbstractSearchPolicy`, which\n    provides convenience features such as support for the `@`\n    composition operator (for composing search policies with stream\n    transformers and tree transformers) and the `&amp;` operator for pairing\n    a search policy with an inner policy.\n\n    Search policies can be conveniently defined using the\n    `search_policy` decorator. See `dfs` for an example.\n    \"\"\"\n\n    _fn: \"_SearchPolicyFn[N]\"\n\n    def __call__[P, T](\n        self,\n        tree: \"dp.Tree[N, P, T]\",\n        env: PolicyEnv,\n        policy: P,\n    ) -&gt; Stream[T]:\n        return Stream(lambda: self._fn(tree, env, policy))\n\n    def __and__[P](self, other: P) -&gt; \"Policy[N, P]\":\n        \"\"\"\n        Pair a search policy with an inner policy to form a policy.\n        \"\"\"\n        return Policy(self, other)\n\n    def __rmatmul__(self, other: StreamTransformer) -&gt; \"SearchPolicy[N]\":\n        \"\"\"\n        Compose a search policy with a stream transformer.\n        \"\"\"\n        if not isinstance(other, StreamTransformer):  # pyright: ignore[reportUnnecessaryIsInstance]\n            return NotImplemented\n        return self._compose_with_stream_transformer(other)\n\n    def _compose_with_stream_transformer(\n        self,\n        trans: StreamTransformer,\n    ) -&gt; \"SearchPolicy[N]\":\n        def policy[P, T](\n            tree: dp.Tree[N, P, T], env: PolicyEnv, policy: P\n        ) -&gt; dp.StreamGen[T]:\n            return trans(self(tree, env, policy), env).gen()\n\n        return SearchPolicy(policy)\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.SearchPolicy.__and__","title":"__and__","text":"<pre><code>__and__(other: P) -&gt; Policy[N, P]\n</code></pre> <p>Pair a search policy with an inner policy to form a policy.</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>def __and__[P](self, other: P) -&gt; \"Policy[N, P]\":\n    \"\"\"\n    Pair a search policy with an inner policy to form a policy.\n    \"\"\"\n    return Policy(self, other)\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.SearchPolicy.__rmatmul__","title":"__rmatmul__","text":"<pre><code>__rmatmul__(other: StreamTransformer) -&gt; SearchPolicy[N]\n</code></pre> <p>Compose a search policy with a stream transformer.</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>def __rmatmul__(self, other: StreamTransformer) -&gt; \"SearchPolicy[N]\":\n    \"\"\"\n    Compose a search policy with a stream transformer.\n    \"\"\"\n    if not isinstance(other, StreamTransformer):  # pyright: ignore[reportUnnecessaryIsInstance]\n        return NotImplemented\n    return self._compose_with_stream_transformer(other)\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.PromptingPolicy","title":"PromptingPolicy  <code>dataclass</code>","text":"<p>               Bases: <code>AbstractPromptingPolicy[PolicyEnv]</code></p> <p>A prompting policy takes as arguments a query (attached to a specific node) and a global policy environment, and returns a search stream (<code>SearchStream</code>).</p> <p><code>PromptingPolicy</code> is a subclass of <code>AbstractPromptingPolicy</code>, which provides convenience features such as support for the <code>@</code> composition operator (for composing prompting policies with stream transformers).</p> <p>Prompting policies can be conveniently defined using the <code>prompting_policy</code> decorator. See the definition of <code>few_shot</code> for an example.</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>@dataclass(frozen=True)\nclass PromptingPolicy(dp.AbstractPromptingPolicy[PolicyEnv]):\n    \"\"\"\n    A prompting policy takes as arguments a query (attached to a\n    specific node) and a global policy environment, and returns a search\n    stream (`SearchStream`).\n\n    `PromptingPolicy` is a subclass of `AbstractPromptingPolicy`, which\n    provides convenience features such as support for the `@`\n    composition operator (for composing prompting policies with stream\n    transformers).\n\n    Prompting policies can be conveniently defined using the\n    `prompting_policy` decorator. See the definition of `few_shot` for\n    an example.\n    \"\"\"\n\n    _fn: \"_PromptingPolicyFn\"\n\n    def __call__[T](\n        self, query: dp.AttachedQuery[T], env: PolicyEnv\n    ) -&gt; Stream[T]:\n        return Stream(lambda: self._fn(query, env))\n\n    def __rmatmul__(self, other: StreamTransformer) -&gt; \"PromptingPolicy\":\n        \"\"\"\n        Compose a prompting policy with a stream transformer.\n        \"\"\"\n        if not isinstance(other, StreamTransformer):  # pyright: ignore[reportUnnecessaryIsInstance]\n            return NotImplemented\n        return self._compose_with_stream_transformer(other)\n\n    def _compose_with_stream_transformer(\n        self,\n        trans: StreamTransformer,\n    ) -&gt; \"PromptingPolicy\":\n        def policy[T](\n            query: dp.AttachedQuery[T], env: PolicyEnv\n        ) -&gt; dp.StreamGen[T]:\n            return trans(self(query, env), env).gen()\n\n        return PromptingPolicy(policy)\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.PromptingPolicy.__rmatmul__","title":"__rmatmul__","text":"<pre><code>__rmatmul__(other: StreamTransformer) -&gt; PromptingPolicy\n</code></pre> <p>Compose a prompting policy with a stream transformer.</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>def __rmatmul__(self, other: StreamTransformer) -&gt; \"PromptingPolicy\":\n    \"\"\"\n    Compose a prompting policy with a stream transformer.\n    \"\"\"\n    if not isinstance(other, StreamTransformer):  # pyright: ignore[reportUnnecessaryIsInstance]\n        return NotImplemented\n    return self._compose_with_stream_transformer(other)\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.ContextualTreeTransformer","title":"ContextualTreeTransformer  <code>dataclass</code>","text":"<p>Wrapper for a function that maps trees to trees, possibly changing their signature. Can depend on the global policy environment (hence the contextual aspect).</p> <p>Contextual tree transformers can be composed with search policies to modify their accepted signature. They can be convniently defined using the <code>contextual_tree_transformer</code> decorator. See <code>elim_compute</code> and <code>elim_messages</code> for an examples.</p> <p>          Class Type Parameters:        </p> Name Bound or Constraints Description Default <code>A</code> <code>Node</code> <p>The type of nodes that the transformer removes from search policy signature.</p> required <code>B</code> <code>Node</code> <p>The type of nodes that the transformer adds to search policy signature (or the bottom type <code>Never</code> if no types are added).</p> required <p>Attributes:</p> Name Type Description <code>fn</code> <code>_ContextualTreeTransformerFn[A, B]</code> <p>A function that takes a policy environment and an inner policy as arguments (hence the contextual aspect) and returns a pure tree transformer (<code>PureTreeTransformerFn</code>)</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>@dataclass\nclass ContextualTreeTransformer[A: Node, B: Node]:\n    \"\"\"\n    Wrapper for a function that maps trees to trees, possibly\n    changing their signature. Can depend on the global policy\n    environment (hence the *contextual* aspect).\n\n    Contextual tree transformers can be composed with search policies to\n    modify their accepted signature. They can be convniently defined\n    using the `contextual_tree_transformer` decorator. See\n    `elim_compute` and `elim_messages` for an examples.\n\n    Type Parameters:\n        A: The type of nodes that the transformer removes from search\n            policy signature.\n        B: The type of nodes that the transformer adds to search policy\n            signature (or the bottom type `Never` if no types are\n            added).\n\n    Attributes:\n        fn: A function that takes a policy environment and an inner\n            policy as arguments (hence the *contextual* aspect) and\n            returns a pure tree transformer (`PureTreeTransformerFn`)\n    \"\"\"\n\n    fn: _ContextualTreeTransformerFn[A, B]\n\n    @staticmethod\n    def pure(\n        fn: PureTreeTransformerFn[A, B],\n    ) -&gt; \"ContextualTreeTransformer[A, B]\":\n        \"\"\"\n        Create a contextual tree transformer from a pure tree\n        transformer.\n        \"\"\"\n\n        def contextual(env: PolicyEnv, policy: Any):\n            return fn\n\n        return ContextualTreeTransformer(contextual)\n\n    def __rmatmul__[N: Node](\n        self, search_policy: \"SearchPolicy[B | N]\"\n    ) -&gt; \"SearchPolicy[A | N]\":\n        \"\"\"\n        Compose a contextual tree transformer with a search policy.\n        \"\"\"\n        if not isinstance(search_policy, SearchPolicy):  # pyright: ignore[reportUnnecessaryIsInstance]\n            return NotImplemented\n\n        def new_search_policy[P, T](\n            tree: dp.Tree[A | N, P, T],\n            env: PolicyEnv,\n            policy: P,\n        ) -&gt; dp.StreamGen[T]:\n            new_tree = self.fn(env, policy)(tree)\n            return search_policy(new_tree, env, policy).gen()\n\n        return SearchPolicy(new_search_policy)\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.ContextualTreeTransformer.pure","title":"pure  <code>staticmethod</code>","text":"<pre><code>pure(fn: PureTreeTransformerFn[A, B]) -&gt; ContextualTreeTransformer[A, B]\n</code></pre> <p>Create a contextual tree transformer from a pure tree transformer.</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>@staticmethod\ndef pure(\n    fn: PureTreeTransformerFn[A, B],\n) -&gt; \"ContextualTreeTransformer[A, B]\":\n    \"\"\"\n    Create a contextual tree transformer from a pure tree\n    transformer.\n    \"\"\"\n\n    def contextual(env: PolicyEnv, policy: Any):\n        return fn\n\n    return ContextualTreeTransformer(contextual)\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.ContextualTreeTransformer.__rmatmul__","title":"__rmatmul__","text":"<pre><code>__rmatmul__(search_policy: SearchPolicy[B | N]) -&gt; SearchPolicy[A | N]\n</code></pre> <p>Compose a contextual tree transformer with a search policy.</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>def __rmatmul__[N: Node](\n    self, search_policy: \"SearchPolicy[B | N]\"\n) -&gt; \"SearchPolicy[A | N]\":\n    \"\"\"\n    Compose a contextual tree transformer with a search policy.\n    \"\"\"\n    if not isinstance(search_policy, SearchPolicy):  # pyright: ignore[reportUnnecessaryIsInstance]\n        return NotImplemented\n\n    def new_search_policy[P, T](\n        tree: dp.Tree[A | N, P, T],\n        env: PolicyEnv,\n        policy: P,\n    ) -&gt; dp.StreamGen[T]:\n        new_tree = self.fn(env, policy)(tree)\n        return search_policy(new_tree, env, policy).gen()\n\n    return SearchPolicy(new_search_policy)\n</code></pre>"},{"location":"reference/stdlib/basic/#convenience-decorators","title":"Convenience Decorators","text":""},{"location":"reference/stdlib/basic/#delphyne.search_policy","title":"search_policy","text":"<pre><code>search_policy(fn: _ParametricSearchPolicyFn[N, A]) -&gt; _ParametricSearchPolicy[N, A]\n</code></pre> <p>Convenience decorator for creating parametric search policies (i.e., functions that return search policies).</p> <p>See <code>dfs</code> for an example.</p> <p>Attributes:</p> Name Type Description <code>fn</code> <p>A function that takes a tree, a policy environment, an inner policy, and additional parameters as arguments and returns a search stream generator (<code>SearchStreamGen</code>).</p> <p>Returns:</p> Type Description <code>_ParametricSearchPolicy[N, A]</code> <p>A function that takes the additional parameters of <code>fn</code> as</p> <code>_ParametricSearchPolicy[N, A]</code> <p>arguments and returns a search policy (<code>SearchPolicy</code>).</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>def search_policy[N: Node, **A](\n    fn: _ParametricSearchPolicyFn[N, A],\n) -&gt; _ParametricSearchPolicy[N, A]:\n    \"\"\"\n    Convenience decorator for creating parametric search policies (i.e.,\n    functions that return search policies).\n\n    See `dfs` for an example.\n\n    Attributes:\n        fn: A function that takes a tree, a policy environment, an inner\n            policy, and additional parameters as arguments and returns a\n            search stream generator (`SearchStreamGen`).\n\n    Returns:\n        A function that takes the additional parameters of `fn` as\n        arguments and returns a search policy (`SearchPolicy`).\n    \"\"\"\n\n    def parametric(*args: A.args, **kwargs: A.kwargs) -&gt; SearchPolicy[N]:\n        def policy[T](\n            tree: dp.Tree[N, Any, T], env: PolicyEnv, policy: Any\n        ) -&gt; dp.StreamGen[T]:\n            return fn(tree, env, policy, *args, **kwargs)\n\n        return SearchPolicy(policy)\n\n    return parametric\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.stdlib.policies._SearchPolicyFn","title":"_SearchPolicyFn","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>class _SearchPolicyFn[N: Node](Protocol):\n    def __call__[P, T](\n        self,\n        tree: dp.Tree[N, P, T],\n        env: PolicyEnv,\n        policy: P,\n    ) -&gt; dp.StreamGen[T]: ...\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.stdlib.policies._ParametricSearchPolicyFn","title":"_ParametricSearchPolicyFn","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>class _ParametricSearchPolicyFn[N: Node, **A](Protocol):\n    def __call__[P, T](\n        self,\n        tree: dp.Tree[N, P, T],\n        env: PolicyEnv,\n        policy: P,\n        *args: A.args,\n        **kwargs: A.kwargs,\n    ) -&gt; dp.StreamGen[T]: ...\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.stdlib.policies._ParametricSearchPolicy","title":"_ParametricSearchPolicy","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>class _ParametricSearchPolicy[N: Node, **A](Protocol):\n    def __call__(\n        self, *args: A.args, **kwargs: A.kwargs\n    ) -&gt; SearchPolicy[N]: ...\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.prompting_policy","title":"prompting_policy","text":"<pre><code>prompting_policy(\n    fn: _ParametricPromptingPolicyFn[A],\n) -&gt; _ParametricPromptingPolicy[A]\n</code></pre> <p>Convenience decorator for creating parametric prompting policies (i.e., functions that return prompting policies).</p> <p>See the definition of <code>few_shot</code> for an example.</p> <p>Attributes:</p> Name Type Description <code>fn</code> <p>A function that takes an attached query, a policy environment, and additional parameters as arguments and returns a search stream generator (<code>SearchStreamGen</code>).</p> <p>Returns:</p> Type Description <code>_ParametricPromptingPolicy[A]</code> <p>A function that takes the additional parameters of <code>fn</code> as</p> <code>_ParametricPromptingPolicy[A]</code> <p>arguments and returns a prompting policy (<code>PromptingPolicy</code>).</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>def prompting_policy[**A](\n    fn: _ParametricPromptingPolicyFn[A],\n) -&gt; _ParametricPromptingPolicy[A]:\n    \"\"\"\n    Convenience decorator for creating parametric prompting policies\n    (i.e., functions that return prompting policies).\n\n    See the definition of `few_shot` for an example.\n\n    Attributes:\n        fn: A function that takes an attached query, a policy\n            environment, and additional parameters as arguments and\n            returns a search stream generator (`SearchStreamGen`).\n\n    Returns:\n        A function that takes the additional parameters of `fn` as\n        arguments and returns a prompting policy (`PromptingPolicy`).\n    \"\"\"\n\n    def parametric(*args: A.args, **kwargs: A.kwargs) -&gt; PromptingPolicy:\n        def policy[T](\n            query: dp.AttachedQuery[T], env: PolicyEnv\n        ) -&gt; dp.StreamGen[T]:\n            return fn(query, env, *args, **kwargs)\n\n        return PromptingPolicy(policy)\n\n    return parametric\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.stdlib.policies._PromptingPolicyFn","title":"_PromptingPolicyFn","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>class _PromptingPolicyFn(Protocol):\n    def __call__[T](\n        self,\n        query: dp.AttachedQuery[T],\n        env: PolicyEnv,\n    ) -&gt; dp.StreamGen[T]: ...\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.stdlib.policies._ParametricPromptingPolicyFn","title":"_ParametricPromptingPolicyFn","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>class _ParametricPromptingPolicyFn[**A](Protocol):\n    def __call__[T](\n        self,\n        query: dp.AttachedQuery[T],\n        env: PolicyEnv,\n        *args: A.args,\n        **kwargs: A.kwargs,\n    ) -&gt; dp.StreamGen[T]: ...\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.stdlib.policies._ParametricPromptingPolicy","title":"_ParametricPromptingPolicy","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>class _ParametricPromptingPolicy[**A](Protocol):\n    def __call__(\n        self, *args: A.args, **kwargs: A.kwargs\n    ) -&gt; PromptingPolicy: ...\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.contextual_tree_transformer","title":"contextual_tree_transformer","text":"<pre><code>contextual_tree_transformer(\n    f: _ParametricContextualTreeTransformerFn[A, B, C],\n) -&gt; Callable[C, ContextualTreeTransformer[A, B]]\n</code></pre> <p>A convenience decorator for defining contextual tree transformers.</p> <p>See the implementation of <code>elim_messages</code> for an example.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>_ParametricContextualTreeTransformerFn[A, B, C]</code> <p>A function that takes a policy environment, an inner policy, and additional parameters as arguments and returns a pure tree transformer (<code>PureTreeTransformerFn</code>).</p> required <p>Returns:</p> Type Description <code>Callable[C, ContextualTreeTransformer[A, B]]</code> <p>A function that takes the additional parameters of <code>f</code> as</p> <code>Callable[C, ContextualTreeTransformer[A, B]]</code> <p>arguments and returns a contextual tree transformer</p> <code>Callable[C, ContextualTreeTransformer[A, B]]</code> <p>(<code>ContextualTreeTransformer</code>).</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>def contextual_tree_transformer[A: Node, B: Node, **C](\n    f: _ParametricContextualTreeTransformerFn[A, B, C], /\n) -&gt; Callable[C, ContextualTreeTransformer[A, B]]:\n    \"\"\"\n    A convenience decorator for defining contextual tree transformers.\n\n    See the implementation of `elim_messages` for an example.\n\n    Arguments:\n        f: A function that takes a policy environment, an inner policy,\n            and additional parameters as arguments and returns a pure\n            tree transformer (`PureTreeTransformerFn`).\n\n    Returns:\n        A function that takes the additional parameters of `f` as\n        arguments and returns a contextual tree transformer\n        (`ContextualTreeTransformer`).\n    \"\"\"\n\n    def parametric(*args: C.args, **kwargs: C.kwargs):\n        def contextual(env: PolicyEnv, policy: Any):\n            return f(env, policy, *args, **kwargs)\n\n        return ContextualTreeTransformer(contextual)\n\n    return parametric\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.stdlib.policies.PureTreeTransformerFn","title":"PureTreeTransformerFn","text":"<p>               Bases: <code>Protocol</code></p> <p>A function that maps any tree with signature <code>A | N</code> to a tree with signature <code>B | N</code>, for all <code>N</code>.</p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>class PureTreeTransformerFn[A: Node, B: Node](Protocol):\n    \"\"\"\n    A function that maps any tree with signature `A | N` to a tree with\n    signature `B | N`, for all `N`.\n    \"\"\"\n\n    def __call__[N: Node, P, T](\n        self, tree: dp.Tree[A | N, P, T]\n    ) -&gt; dp.Tree[B | N, P, T]: ...\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.stdlib.policies._ContextualTreeTransformerFn","title":"_ContextualTreeTransformerFn","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>class _ContextualTreeTransformerFn[A: Node, B: Node](Protocol):\n    def __call__(\n        self, env: PolicyEnv, policy: Any\n    ) -&gt; PureTreeTransformerFn[A, B]: ...\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.stdlib.policies._ParametricContextualTreeTransformerFn","title":"_ParametricContextualTreeTransformerFn","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/delphyne/stdlib/policies.py</code> <pre><code>class _ParametricContextualTreeTransformerFn[A: Node, B: Node, **C](Protocol):\n    def __call__(\n        self, env: PolicyEnv, policy: Any, *args: C.args, **kwargs: C.kwargs\n    ) -&gt; PureTreeTransformerFn[A, B]: ...\n</code></pre>"},{"location":"reference/stdlib/basic/#strategies","title":"Strategies","text":""},{"location":"reference/stdlib/basic/#delphyne.StrategyInstance","title":"StrategyInstance  <code>dataclass</code>","text":"<p>               Bases: <code>StrategyComp[N, P, T]</code></p> <p>A strategy computation that can be reified into a search tree, obtained by instantiating a strategy function.</p> <p><code>StrategyInstance</code> is a subclass of <code>StrategyComp</code> that adds convenience features such as the <code>using</code> method for building opaque spaces. The <code>strategy</code> decorator can be used to wrap strategy functions so as to have them return <code>StrategyInstance</code> objects.</p> <p>          Class Type Parameters:        </p> Name Bound or Constraints Description Default <code>N</code> <code>Node</code> <p>Signature of the strategy.</p> required <code>P</code> <p>Inner policy type associated with the strategy.</p> required <code>T</code> <p>Return type of the strategy.</p> required Source code in <code>src/delphyne/stdlib/strategies.py</code> <pre><code>@dataclass(frozen=True)\nclass StrategyInstance[N: dp.Node, P, T](dp.StrategyComp[N, P, T]):\n    \"\"\"\n    A *strategy computation* that can be reified into a search tree,\n    obtained by instantiating a strategy function.\n\n    `StrategyInstance` is a subclass of `StrategyComp` that adds\n    convenience features such as the `using` method for building opaque\n    spaces. The `strategy` decorator can be used to wrap strategy\n    functions so as to have them return `StrategyInstance` objects.\n\n    Type Parameters:\n        N: Signature of the strategy.\n        P: Inner policy type associated with the strategy.\n        T: Return type of the strategy.\n    \"\"\"\n\n    @overload\n    def using(self, get_policy: EllipsisType, /) -&gt; Opaque[IPDict, T]: ...\n\n    @overload\n    def using[Pout](\n        self,\n        get_policy: Callable[[Pout], Policy[N, P]] | EllipsisType,\n        /,\n        inner_policy_type: type[Pout] | None = None,\n    ) -&gt; Opaque[Pout, T]: ...\n\n    def using[Pout](\n        self,\n        get_policy: Callable[[Pout], Policy[N, P]] | EllipsisType,\n        /,\n        inner_policy_type: type[Pout] | None = None,\n    ) -&gt; Opaque[Pout, T]:\n        \"\"\"\n        Turn a strategy instance into an opaque space by providing a\n        mapping from the ambient inner policy to an appropriate policy.\n\n        Attributes:\n            get_policy: A function that maps the ambient inner policy to\n                a policy (i.e., a pair of a search policy and of an\n                inner policy) to use for answering the query.\n                Alternatively, if the ellipsis value `...` is passed,\n                the inner policy type is assumed to be `IPDict`, and\n                sub-policies are automatically selected using tags (see\n                `IPDict` documentation).\n            inner_policy_type: Ambient inner policy type for the outer\n                strategy from which the strategy is called. This\n                information is not used at runtime but it can be\n                provided to help type inference when necessary.\n\n        Type Parameters:\n            Pout: Ambient inner policy type associated with the outer\n                strategy from which the strategy is called.\n        \"\"\"\n\n        # Using operators such as `&amp;` or `@` instead of using does not\n        # work well since some type checkers (e.g., Pyright) perform\n        # worse inference when using those instead of a standard method.\n        if isinstance(get_policy, EllipsisType):\n            return OpaqueSpace[Pout, T].from_strategy(\n                self, cast(Any, pol.dict_subpolicy)\n            )\n        return OpaqueSpace[Pout, T].from_strategy(\n            self, lambda p, _: get_policy(p)\n        )\n\n    def run_toplevel(\n        self,\n        env: PolicyEnv,\n        policy: Policy[N, P],\n        monitor: dp.TreeMonitor = dp.TreeMonitor(),\n    ) -&gt; Stream[T]:\n        \"\"\"\n        Reify a strategy into a tree and run it using a given policy.\n        \"\"\"\n        tree = dp.reify(self, monitor)\n        return policy.search(tree, env, policy.inner)\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.StrategyInstance.using","title":"using","text":"<pre><code>using(get_policy: EllipsisType) -&gt; Opaque[IPDict, T]\n</code></pre><pre><code>using(\n    get_policy: Callable[[Pout], Policy[N, P]] | EllipsisType,\n    /,\n    inner_policy_type: type[Pout] | None = None,\n) -&gt; Opaque[Pout, T]\n</code></pre> <pre><code>using(\n    get_policy: Callable[[Pout], Policy[N, P]] | EllipsisType,\n    /,\n    inner_policy_type: type[Pout] | None = None,\n) -&gt; Opaque[Pout, T]\n</code></pre> <p>Turn a strategy instance into an opaque space by providing a mapping from the ambient inner policy to an appropriate policy.</p> <p>Attributes:</p> Name Type Description <code>get_policy</code> <p>A function that maps the ambient inner policy to a policy (i.e., a pair of a search policy and of an inner policy) to use for answering the query. Alternatively, if the ellipsis value <code>...</code> is passed, the inner policy type is assumed to be <code>IPDict</code>, and sub-policies are automatically selected using tags (see <code>IPDict</code> documentation).</p> <code>inner_policy_type</code> <p>Ambient inner policy type for the outer strategy from which the strategy is called. This information is not used at runtime but it can be provided to help type inference when necessary.</p> <p>          Type Parameters:        </p> Name Bound or Constraints Description Default <code>Pout</code> <p>Ambient inner policy type associated with the outer strategy from which the strategy is called.</p> required Source code in <code>src/delphyne/stdlib/strategies.py</code> <pre><code>def using[Pout](\n    self,\n    get_policy: Callable[[Pout], Policy[N, P]] | EllipsisType,\n    /,\n    inner_policy_type: type[Pout] | None = None,\n) -&gt; Opaque[Pout, T]:\n    \"\"\"\n    Turn a strategy instance into an opaque space by providing a\n    mapping from the ambient inner policy to an appropriate policy.\n\n    Attributes:\n        get_policy: A function that maps the ambient inner policy to\n            a policy (i.e., a pair of a search policy and of an\n            inner policy) to use for answering the query.\n            Alternatively, if the ellipsis value `...` is passed,\n            the inner policy type is assumed to be `IPDict`, and\n            sub-policies are automatically selected using tags (see\n            `IPDict` documentation).\n        inner_policy_type: Ambient inner policy type for the outer\n            strategy from which the strategy is called. This\n            information is not used at runtime but it can be\n            provided to help type inference when necessary.\n\n    Type Parameters:\n        Pout: Ambient inner policy type associated with the outer\n            strategy from which the strategy is called.\n    \"\"\"\n\n    # Using operators such as `&amp;` or `@` instead of using does not\n    # work well since some type checkers (e.g., Pyright) perform\n    # worse inference when using those instead of a standard method.\n    if isinstance(get_policy, EllipsisType):\n        return OpaqueSpace[Pout, T].from_strategy(\n            self, cast(Any, pol.dict_subpolicy)\n        )\n    return OpaqueSpace[Pout, T].from_strategy(\n        self, lambda p, _: get_policy(p)\n    )\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.StrategyInstance.run_toplevel","title":"run_toplevel","text":"<pre><code>run_toplevel(\n    env: PolicyEnv, policy: Policy[N, P], monitor: TreeMonitor = TreeMonitor()\n) -&gt; Stream[T]\n</code></pre> <p>Reify a strategy into a tree and run it using a given policy.</p> Source code in <code>src/delphyne/stdlib/strategies.py</code> <pre><code>def run_toplevel(\n    self,\n    env: PolicyEnv,\n    policy: Policy[N, P],\n    monitor: dp.TreeMonitor = dp.TreeMonitor(),\n) -&gt; Stream[T]:\n    \"\"\"\n    Reify a strategy into a tree and run it using a given policy.\n    \"\"\"\n    tree = dp.reify(self, monitor)\n    return policy.search(tree, env, policy.inner)\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.strategy","title":"strategy","text":"<pre><code>strategy(\n    f: Callable[A, Strategy[N, P, T]],\n) -&gt; Callable[A, StrategyInstance[N, P, T]]\n</code></pre><pre><code>strategy(\n    *,\n    name: str | None = None,\n    ret: TypeAnnot[Any] | NoTypeInfo = NoTypeInfo(),\n    inherit_tags: Callable[..., Sequence[SpaceBuilder[Any]]] | None = None,\n) -&gt; _StrategyDecorator\n</code></pre> <pre><code>strategy(\n    f: Callable[..., Any] | None = None,\n    /,\n    *,\n    name: str | None = None,\n    ret: TypeAnnot[Any] | NoTypeInfo = NoTypeInfo(),\n    inherit_tags: Callable[..., Sequence[SpaceBuilder[Any]]] | None = None,\n) -&gt; Any\n</code></pre> <p>Standard parametric decorator for wrapping strategy functions into functions returning <code>StrategyInstance</code> objects.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>optional</code> <p>Name of the strategy. If not provided, the name attribute of the strategy function is used instead. The name of the strategy is used in defining default tags and when visualizing traces.</p> <code>None</code> <code>ret</code> <code>optional</code> <p>Return type of the strategy function. If not provided, it is obtained by inspecting type annotations. This information is used when visualizing traces and for serializing top-level success values when running commands.</p> <code>NoTypeInfo()</code> <code>inherit_tags</code> <code>optional</code> <p>A function that maps all arguments from the decorated strategy function to a sequence of space builders from which tags must be inherited. By default, nothing is inherited.</p> <code>None</code> <p>Info</p> <p><code>strategy()(f)</code> can be shortened as <code>@strategy(f)</code>, hence the overloading of the type of <code>strategy</code>.</p> Runtime use of type annotations <p>The type annotations for the arguments and return type of a strategy function are leveraged at runtime in two ways:</p> <ul> <li>To improve the rendering of values when visualizing traces   (e.g., using YAML serialization instead of <code>pprint</code>).</li> <li>To unserialize arguments for the top-level strategy when   specified in JSON or YAML and serialize its return value.</li> </ul> <p>In summary, type annotations are fully optional, except when trying to unserialize (resp. serialize) the arguments (resp. return type) of a top-level strategy involving custom data types (and not just JSON values such as integers, strings, dictionaries...).</p> Source code in <code>src/delphyne/stdlib/strategies.py</code> <pre><code>def strategy(\n    f: Callable[..., Any] | None = None,\n    /,\n    *,\n    name: str | None = None,\n    ret: TypeAnnot[Any] | NoTypeInfo = NoTypeInfo(),\n    inherit_tags: Callable[..., Sequence[dp.SpaceBuilder[Any]]] | None = None,\n) -&gt; Any:\n    \"\"\"\n    Standard parametric decorator for wrapping strategy functions into\n    functions returning `StrategyInstance` objects.\n\n    Parameters:\n        name (optional): Name of the strategy. If not provided, the\n            __name__ attribute of the strategy function is used instead.\n            The name of the strategy is used in defining default tags\n            and when visualizing traces.\n        ret (optional): Return type of the strategy function. If not\n            provided, it is obtained by inspecting type annotations.\n            This information is used when visualizing traces and for\n            serializing top-level success values when running commands.\n        inherit_tags (optional): A function that maps all arguments from\n            the decorated strategy function to a sequence of space\n            builders from which tags must be inherited. By default,\n            nothing is inherited.\n\n    !!! info\n        `strategy()(f)` can be shortened as `@strategy(f)`, hence the\n        overloading of the type of `strategy`.\n\n    ??? info \"Runtime use of type annotations\"\n        The type annotations for the arguments and return type of a\n        strategy function are leveraged at runtime in two ways:\n\n        - To improve the rendering of values when visualizing traces\n          (e.g., using YAML serialization instead of `pprint`).\n        - To unserialize arguments for the top-level strategy when\n          specified in JSON or YAML and serialize its return value.\n\n        In summary, type annotations are fully optional, except when\n        trying to unserialize (resp. serialize) the arguments (resp.\n        return type) of a top-level strategy involving custom data types\n        (and not just JSON values such as integers, strings,\n        dictionaries...).\n    \"\"\"\n\n    # Using functools.wraps is important so that the object loader can\n    # get the type hints to properly instantiate arguments.\n\n    # @strategy(f) case\n    if f is not None:\n        assert name is None\n        assert isinstance(ret, NoTypeInfo)\n        assert inherit_tags is None\n        name = inspect.function_name(f)\n        tags = (name,) if name else ()\n\n        def wrapped(*args: Any, **kwargs: Any):\n            return StrategyInstance(\n                f,\n                args,\n                kwargs,\n                _name=None,\n                _return_type=NoTypeInfo(),\n                _tags=tags,\n            )\n\n        return functools.wraps(f)(wrapped)\n\n    # @strategy(...)(f) case\n    else:\n\n        def decorator(f: Any):\n            def wrapped(*args: Any, **kwargs: Any):\n                nonlocal name\n                if name is None:\n                    name = inspect.function_name(f)\n                tags = (name,) if name else ()\n                # Inherit tags from space arguments if needed.\n                if inherit_tags is not None:\n                    inherited = inherit_tags(*args, **kwargs)\n                    for space in inherited:\n                        assert isinstance(space, dp.SpaceBuilder)\n                        tags = (*tags, *space.tags)\n                return StrategyInstance(\n                    f,\n                    args,\n                    kwargs,\n                    _name=name,\n                    _return_type=ret,\n                    _tags=tags,\n                )\n\n            return functools.wraps(f)(wrapped)\n\n        return decorator\n</code></pre>"},{"location":"reference/stdlib/basic/#delphyne.stdlib.strategies._StrategyDecorator","title":"_StrategyDecorator","text":"<p>               Bases: <code>Protocol</code></p> <p>Type of the <code>strategy</code> decorator, after is optional arguments are instantiated.</p> Source code in <code>src/delphyne/stdlib/strategies.py</code> <pre><code>class _StrategyDecorator(Protocol):\n    \"\"\"\n    Type of the `strategy` decorator, after is optional arguments are\n    instantiated.\n    \"\"\"\n\n    # Note that this definition cannot be inlined in the return type of\n    # `@strategy`, without which variables such as `P` and `T` would not\n    # be correctly scoped and inferred (type checkers such as Pyright\n    # would set them to `Unknown` if they cannot be inferred from `args`\n    # in `@strategy(*args)(f)`).\n\n    def __call__[**A, N: dp.Node, P, T](\n        self,\n        f: Callable[A, dp.Strategy[N, P, T]],\n    ) -&gt; Callable[A, StrategyInstance[N, P, T]]: ...\n</code></pre>"},{"location":"reference/stdlib/commands/","title":"Commands","text":""},{"location":"reference/stdlib/commands/#tasks-and-commands","title":"Tasks and Commands","text":""},{"location":"reference/stdlib/commands/#delphyne.CommandExecutionContext","title":"CommandExecutionContext  <code>dataclass</code>","text":"<p>Context information available to all commands.</p> <p>This information is usually specified in <code>delphyne.yaml</code> project files, and also locally in <code>@config</code> blocks. All values have defaults. All paths are usually expressed relative to a single workspace root directory, and can be made absolute using the <code>with_root</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>strategy_dirs</code> <code>Sequence[Path]</code> <p>A sequence of directories in which strategy modules can be found.</p> <code>DEFAULT_STRATEGY_DIRS</code> <code>modules</code> <code>Sequence[str]</code> <p>A sequence of module in which Python object identifiers can be resolved (module names can feature <code>.</code>).</p> <code>()</code> <code>demo_files</code> <code>Sequence[Path]</code> <p>A sequence of demonstration files (either including or excluding the <code>*.demo.yaml</code> extension).</p> <code>()</code> <code>prompt_dirs</code> <code>Sequence[Path]</code> <p>A sequence of directories in which to look for prompt templates.</p> <code>DEFAULT_PROMPTS_DIRS</code> <code>data_dirs</code> <code>Sequence[Path]</code> <p>A sequence of directories in which to look for data files.</p> <code>DEFAULT_DATA_DIRS</code> <code>cache_root</code> <code>Path | None</code> <p>The directory in which to store all request cache subdirectories.</p> <code>None</code> <code>result_refresh_period</code> <code>float | None</code> <p>The period in seconds at which the current result is computed and communicated to the UI (e.g., the period at which the current trace is exported when running oracular programs). If <code>None</code>, the result is never refreshed (until the command terminates).</p> <code>None</code> <code>status_refresh_period</code> <code>float | None</code> <p>The period in seconds at which the current status message is communicated to the UI. If <code>None</code>, the status is never refreshed (until the command terminates).</p> <code>None</code> <p>Local conguration blocks</p> <p>Demonstration and command files can override some configuration information from the <code>delphyne.yaml</code> file by featuring a comment block such as:</p> <pre><code># @config\n# modules: [\"my_strategy_module\"]\n# demo_files: [\"demo.yaml\"]\n# @end\n</code></pre> <p>The comment block must be placed at the start of the file, possibly after other comments.</p> Source code in <code>src/delphyne/stdlib/tasks.py</code> <pre><code>@dataclass(frozen=True, kw_only=True)\nclass CommandExecutionContext:\n    \"\"\"\n    Context information available to all commands.\n\n    This information is usually specified in `delphyne.yaml` project\n    files, and also locally in `@config` blocks. All values have\n    defaults. All paths are usually expressed relative to a single\n    workspace root directory, and can be made absolute using the\n    `with_root` method.\n\n    Parameters:\n        strategy_dirs: A sequence of directories in which strategy\n            modules can be found.\n        modules: A sequence of module in which Python object identifiers\n            can be resolved (module names can feature `.`).\n        demo_files: A sequence of demonstration files (either including or\n            excluding the `*.demo.yaml` extension).\n        prompt_dirs: A sequence of directories in which to look for\n            prompt templates.\n        data_dirs: A sequence of directories in which to look for data\n            files.\n        cache_root: The directory in which to store all request cache\n            subdirectories.\n        result_refresh_period: The period in seconds at which the\n            current result is computed and communicated to the UI (e.g.,\n            the period at which the current trace is exported when\n            running oracular programs). If `None`, the result is never\n            refreshed (until the command terminates).\n        status_refresh_period: The period in seconds at which the\n            current status message is communicated to the UI. If `None`,\n            the status is never refreshed (until the command\n            terminates).\n\n    !!! info \"Local conguration blocks\"\n        Demonstration and command files can override some configuration\n        information from the `delphyne.yaml` file by featuring a comment\n        block such as:\n\n        ```yaml\n        # @config\n        # modules: [\"my_strategy_module\"]\n        # demo_files: [\"demo.yaml\"]\n        # @end\n        ```\n\n        The comment block must be placed at the start of the file,\n        possibly after other comments.\n    \"\"\"\n\n    strategy_dirs: Sequence[Path] = DEFAULT_STRATEGY_DIRS\n    modules: Sequence[str] = ()\n    demo_files: Sequence[Path] = ()\n    prompt_dirs: Sequence[Path] = DEFAULT_PROMPTS_DIRS\n    data_dirs: Sequence[Path] = DEFAULT_DATA_DIRS\n    cache_root: Path | None = None\n    result_refresh_period: float | None = None\n    status_refresh_period: float | None = None\n\n    @property\n    def base(self) -&gt; analysis.DemoExecutionContext:\n        \"\"\"\n        Obtain a demonstration execution context.\n        \"\"\"\n        return analysis.DemoExecutionContext(self.strategy_dirs, self.modules)\n\n    def with_root(self, root: Path) -&gt; \"CommandExecutionContext\":\n        \"\"\"\n        Make all paths absolute given a path to the workspace root.\n        \"\"\"\n        return CommandExecutionContext(\n            modules=self.modules,\n            demo_files=[root / f for f in self.demo_files],\n            strategy_dirs=[root / d for d in self.strategy_dirs],\n            prompt_dirs=[root / d for d in self.prompt_dirs],\n            data_dirs=[root / d for d in self.data_dirs],\n            cache_root=None if self.cache_root is None else self.cache_root,\n            result_refresh_period=self.result_refresh_period,\n            status_refresh_period=self.status_refresh_period,\n        )\n</code></pre>"},{"location":"reference/stdlib/commands/#delphyne.CommandExecutionContext.base","title":"base  <code>property</code>","text":"<pre><code>base: DemoExecutionContext\n</code></pre> <p>Obtain a demonstration execution context.</p>"},{"location":"reference/stdlib/commands/#delphyne.CommandExecutionContext.with_root","title":"with_root","text":"<pre><code>with_root(root: Path) -&gt; CommandExecutionContext\n</code></pre> <p>Make all paths absolute given a path to the workspace root.</p> Source code in <code>src/delphyne/stdlib/tasks.py</code> <pre><code>def with_root(self, root: Path) -&gt; \"CommandExecutionContext\":\n    \"\"\"\n    Make all paths absolute given a path to the workspace root.\n    \"\"\"\n    return CommandExecutionContext(\n        modules=self.modules,\n        demo_files=[root / f for f in self.demo_files],\n        strategy_dirs=[root / d for d in self.strategy_dirs],\n        prompt_dirs=[root / d for d in self.prompt_dirs],\n        data_dirs=[root / d for d in self.data_dirs],\n        cache_root=None if self.cache_root is None else self.cache_root,\n        result_refresh_period=self.result_refresh_period,\n        status_refresh_period=self.status_refresh_period,\n    )\n</code></pre>"},{"location":"reference/stdlib/commands/#delphyne.stdlib.tasks.DEFAULT_STRATEGY_DIRS","title":"DEFAULT_STRATEGY_DIRS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_STRATEGY_DIRS = (Path('.'),)\n</code></pre>"},{"location":"reference/stdlib/commands/#delphyne.stdlib.tasks.DEFAULT_PROMPTS_DIRS","title":"DEFAULT_PROMPTS_DIRS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PROMPTS_DIRS = (Path('prompts'),)\n</code></pre>"},{"location":"reference/stdlib/commands/#delphyne.stdlib.tasks.DEFAULT_DATA_DIRS","title":"DEFAULT_DATA_DIRS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_DATA_DIRS = (Path('data'),)\n</code></pre>"},{"location":"reference/stdlib/commands/#delphyne.TaskContext","title":"TaskContext","text":"<p>               Bases: <code>Protocol</code></p> <p>Context object accessible to all tasks for reporting progress and intermediate results.</p> Source code in <code>src/delphyne/stdlib/tasks.py</code> <pre><code>class TaskContext[T](typing.Protocol):\n    \"\"\"\n    Context object accessible to all tasks for reporting progress and\n    intermediate results.\n    \"\"\"\n\n    # To be called externally\n    def interrupt(self) -&gt; None: ...\n\n    # To be called internally\n    def interruption_requested(self) -&gt; bool: ...\n    def log(self, message: str) -&gt; None: ...\n    def set_status(self, message: str) -&gt; None: ...\n    def set_result(self, result: T) -&gt; None: ...\n    def raise_internal_error(self, message: str) -&gt; None: ...\n</code></pre>"},{"location":"reference/stdlib/commands/#delphyne.run_command","title":"run_command","text":"<pre><code>run_command(\n    command: Command[A, T],\n    args: A,\n    ctx: CommandExecutionContext,\n    dump_statuses: Path | None = None,\n    dump_result: Path | None = None,\n    dump_log: Path | None = None,\n    on_status: Callable[[str], None] | None = None,\n    add_header: bool = True,\n    handle_sigint: bool = False,\n) -&gt; CommandResult[T | None]\n</code></pre> <p>A simple command runner.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>Command[A, T]</code> <p>The command to run.</p> required <code>args</code> <code>A</code> <p>The arguments to pass to the command.</p> required <code>ctx</code> <code>CommandExecutionContext</code> <p>The command execution context.</p> required <code>dump_statuses</code> <code>Path | None</code> <p>A file in which to dump status messages at regular intervals.</p> <code>None</code> <code>dump_result</code> <code>Path | None</code> <p>A file in which to dump intermediate and final results, whose content is refreshed at regular intervals.</p> <code>None</code> <code>dump_log</code> <code>Path | None</code> <p>A file in which to dump log messages.</p> <code>None</code> <code>on_status</code> <code>Callable[[str], None] | None</code> <p>A function to call every time a status message is issued.</p> <code>None</code> <code>add_header</code> <code>bool</code> <p>If <code>True</code>, the dumped result is prefixed with a header containing the command name and arguments.</p> <code>True</code> <code>handle_sigint</code> <code>bool</code> <p>If <code>True</code>, pressing <code>Ctrl+C</code> sends the command task an interruption request by calling <code>TaskContext.interrupt</code>, allowing it to gracefully terminate instead of abruptly interrupting it.</p> <code>False</code> <p>Non-existing directories are created automatically.</p> Source code in <code>src/delphyne/stdlib/tasks.py</code> <pre><code>def run_command[A, T](\n    command: Command[A, T],\n    args: A,\n    ctx: CommandExecutionContext,\n    dump_statuses: Path | None = None,\n    dump_result: Path | None = None,\n    dump_log: Path | None = None,\n    on_status: Callable[[str], None] | None = None,\n    add_header: bool = True,\n    handle_sigint: bool = False,\n) -&gt; CommandResult[T | None]:\n    \"\"\"\n    A simple command runner.\n\n    Arguments:\n        command: The command to run.\n        args: The arguments to pass to the command.\n        ctx: The command execution context.\n        dump_statuses: A file in which to dump status messages at\n            regular intervals.\n        dump_result: A file in which to dump intermediate and final\n            results, whose content is refreshed at regular intervals.\n        dump_log: A file in which to dump log messages.\n        on_status: A function to call every time a status message is\n            issued.\n        add_header: If `True`, the dumped result is prefixed with a\n            header containing the command name and arguments.\n        handle_sigint: If `True`, pressing `Ctrl+C` sends the command\n            task an interruption request by calling\n            `TaskContext.interrupt`, allowing it to gracefully terminate\n            instead of abruptly interrupting it.\n\n    Non-existing directories are created automatically.\n    \"\"\"\n\n    class Handler:\n        def __init__(self):\n            self.result: CommandResult[T | None] = CommandResult([], None)\n            self.interrupted = False\n\n        def interrupt(self) -&gt; None:\n            self.interrupted = True\n\n        def interruption_requested(self) -&gt; bool:\n            return self.interrupted\n\n        def log(self, message: str) -&gt; None:\n            if dump_log is not None:\n                os.makedirs(dump_log.parent, exist_ok=True)\n                with open(dump_log, \"a\") as f:\n                    f.write(message + \"\\n\")\n\n        def set_status(self, message: str) -&gt; None:\n            if dump_statuses is not None:\n                os.makedirs(dump_statuses.parent, exist_ok=True)\n                with open(dump_statuses, \"a\") as f:\n                    f.write(message + \"\\n\")\n            if on_status is not None:\n                on_status(message)\n\n        def set_result(self, result: CommandResult[T]) -&gt; None:\n            self.result = result\n            if dump_result is not None:\n                ret_ty = command_optional_result_wrapper_type(command)\n                ret: Any = ty.pydantic_dump(ret_ty, result)\n                if add_header:\n                    args_type = command_args_type(command)\n                    ret = {\n                        \"command\": command_name(command),\n                        \"args\": ty.pydantic_dump(args_type, args),\n                        \"outcome\": ret,\n                    }\n                os.makedirs(dump_result.parent, exist_ok=True)\n                with open(dump_result, \"w\") as f:\n                    ret_yaml = pretty_yaml(ret)\n                    f.write(\"# delphyne-command\\n\\n\" + ret_yaml)\n\n        def raise_internal_error(self, message: str) -&gt; None:\n            error = (\"error\", f\"Internal error: {message}\")\n            self.result = CommandResult([error], None)\n\n    handler = Handler()\n    if not handle_sigint:\n        command(handler, ctx, args)\n    else:\n        watch_sigint(\n            task=lambda: command(handler, ctx, args),\n            on_sigint=lambda: handler.interrupt(),\n        )\n    return handler.result\n</code></pre>"},{"location":"reference/stdlib/commands/#standard-commands","title":"Standard Commands","text":""},{"location":"reference/stdlib/commands/#delphyne.stdlib.commands.run_strategy.run_strategy","title":"run_strategy","text":"<pre><code>run_strategy(\n    task: TaskContext[CommandResult[RunStrategyResponse]],\n    exe: CommandExecutionContext,\n    args: RunStrategyArgs,\n)\n</code></pre> <p>Command for running an oracular program from a serialized specification.</p> Source code in <code>src/delphyne/stdlib/commands/run_strategy.py</code> <pre><code>def run_strategy(\n    task: ta.TaskContext[ta.CommandResult[RunStrategyResponse]],\n    exe: ta.CommandExecutionContext,\n    args: RunStrategyArgs,\n):\n    \"\"\"\n    Command for running an oracular program from a serialized\n    specification.\n    \"\"\"\n    loader = analysis.ObjectLoader(exe.base)\n    strategy = loader.load_strategy_instance(args.strategy, args.args)\n    policy = loader.load_and_call_function(args.policy, args.policy_args)\n    assert isinstance(policy, dp.AbstractPolicy)\n    policy = cast(pol.Policy[Any, Any], policy)\n    run_loaded_strategy(\n        task=task,\n        exe=exe,\n        args=RunLoadedStrategyArgs(\n            strategy=strategy,\n            policy=policy,\n            num_generated=args.num_generated,\n            budget=args.budget,\n            cache_dir=args.cache_dir,\n            cache_mode=args.cache_mode,\n            cache_format=args.cache_format,\n            export_raw_trace=args.export_raw_trace,\n            export_log=args.export_log,\n            export_browsable_trace=args.export_browsable_trace,\n        ),\n    )\n</code></pre>"},{"location":"reference/stdlib/commands/#delphyne.stdlib.commands.run_strategy.RunStrategyArgs","title":"RunStrategyArgs  <code>dataclass</code>","text":"<p>Arguments for the <code>run_strategy</code> command that runs an oracular program.</p> <p>Attributes:</p> Name Type Description <code>strategy</code> <code>str</code> <p>Name of the strategy to run.</p> <code>args</code> <code>dict[str, object]</code> <p>Arguments to pass to the strategy constructor.</p> <code>policy</code> <code>str</code> <p>Name of the policy to use.</p> <code>policy_args</code> <code>dict[str, object]</code> <p>Arguments to pass to the policy constructor.</p> <code>num_generated</code> <code>int</code> <p>Number of success values to generate.</p> <code>budget</code> <code>dict[str, float]</code> <p>Budget limit (infinite for unspecified metrics).</p> <code>cache_dir</code> <code>str | None</code> <p>Subdirectory of the global cache directory to use for caching, or <code>None</code> to disable caching.</p> <code>cache_mode</code> <code>CacheMode</code> <p>Cache mode to use.</p> <code>cache_format</code> <code>CacheFormat</code> <p>Cache format to use.</p> <code>export_raw_trace</code> <code>bool</code> <p>Whether to export the raw execution trace.</p> <code>export_log</code> <code>bool</code> <p>Whether to export the log messages.</p> <code>export_browsable_trace</code> <code>bool</code> <p>Whether to export a browsable trace, which can be visualized in the VSCode extension (see delphyne.analysis.feedback.Trace).</p> Source code in <code>src/delphyne/stdlib/commands/run_strategy.py</code> <pre><code>@dataclass(kw_only=True)\nclass RunStrategyArgs:\n    \"\"\"\n    Arguments for the `run_strategy` command that runs an oracular\n    program.\n\n    Attributes:\n        strategy: Name of the strategy to run.\n        args: Arguments to pass to the strategy constructor.\n        policy: Name of the policy to use.\n        policy_args: Arguments to pass to the policy constructor.\n        num_generated: Number of success values to generate.\n        budget: Budget limit (infinite for unspecified metrics).\n        cache_dir: Subdirectory of the global cache directory to use for\n            caching, or `None` to disable caching.\n        cache_mode: Cache mode to use.\n        cache_format: Cache format to use.\n        export_raw_trace: Whether to export the raw execution trace.\n        export_log: Whether to export the log messages.\n        export_browsable_trace: Whether to export a browsable trace,\n            which can be visualized in the VSCode extension (see\n            [delphyne.analysis.feedback.Trace][]).\n    \"\"\"\n\n    strategy: str\n    args: dict[str, object]\n    policy: str\n    policy_args: dict[str, object]\n    budget: dict[str, float]\n    num_generated: int = 1\n    cache_dir: str | None = None\n    cache_mode: ca.CacheMode = \"read_write\"\n    cache_format: CacheFormat = \"yaml\"\n    export_raw_trace: bool = True\n    export_log: bool = True\n    export_browsable_trace: bool = True\n</code></pre>"},{"location":"reference/stdlib/commands/#delphyne.stdlib.commands.answer_query.answer_query","title":"answer_query","text":"<pre><code>answer_query(\n    task: TaskContext[CommandResult[AnswerQueryResponse]],\n    exe: CommandExecutionContext,\n    cmd: AnswerQueryArgs,\n)\n</code></pre> <p>A command for answering a query. See <code>AnswerQueryArgs</code>.</p> Source code in <code>src/delphyne/stdlib/commands/answer_query.py</code> <pre><code>def answer_query(\n    task: ta.TaskContext[ta.CommandResult[AnswerQueryResponse]],\n    exe: ta.CommandExecutionContext,\n    cmd: AnswerQueryArgs,\n):\n    \"\"\"\n    A command for answering a query. See `AnswerQueryArgs`.\n    \"\"\"\n    with_cache_spec(\n        partial(answer_query_with_cache, task, exe, cmd),\n        cache_root=exe.cache_root,\n        cache_dir=cmd.cache_dir,\n        cache_mode=cmd.cache_mode,\n        cache_format=cmd.cache_format,\n    )\n</code></pre>"},{"location":"reference/stdlib/commands/#delphyne.stdlib.commands.answer_query.AnswerQueryArgs","title":"AnswerQueryArgs  <code>dataclass</code>","text":"<p>Arguments for the <code>answer_query</code> command.</p> <p>Attributes:</p> Name Type Description <code>query</code> <code>str</code> <p>The name of the query to answer.</p> <code>args</code> <code>dict[str, object]</code> <p>Arguments for the query, as a dictionary of JSON values.</p> <code>prompt_only</code> <code>bool</code> <p>If <code>True</code>, a dummy model is used that always errors, so that only the prompt can be seen in the logs.</p> <code>model</code> <code>str | None</code> <p>The name of the model to use for answering the query.</p> <code>num_answers</code> <code>int</code> <p>The number of answers to generate.</p> <code>iterative_mode</code> <code>bool</code> <p>Whether to answer the query in iterative mode (see <code>few_shot</code> for details).</p> <code>budget</code> <code>dict[str, float] | None</code> <p>Budget limit (infinite for unspecified metrics).</p> <code>cache_dir</code> <code>str | None</code> <p>Subdirectory of the global cache directory to use for caching, or <code>None</code> to disable caching.</p> <code>cache_mode</code> <code>CacheMode</code> <p>Cache mode to use.</p> <code>cache_format</code> <code>CacheFormat</code> <p>Cache format to use.</p> Source code in <code>src/delphyne/stdlib/commands/answer_query.py</code> <pre><code>@dataclass(kw_only=True)\nclass AnswerQueryArgs:\n    \"\"\"\n    Arguments for the `answer_query` command.\n\n    Attributes:\n        query: The name of the query to answer.\n        args: Arguments for the query, as a dictionary of JSON values.\n        prompt_only: If `True`, a dummy model is used that always\n            errors, so that only the prompt can be seen in the logs.\n        model: The name of the model to use for answering the query.\n        num_answers: The number of answers to generate.\n        iterative_mode: Whether to answer the query in iterative mode\n            (see `few_shot` for details).\n        budget: Budget limit (infinite for unspecified metrics).\n        cache_dir: Subdirectory of the global cache directory to use for\n            caching, or `None` to disable caching.\n        cache_mode: Cache mode to use.\n        cache_format: Cache format to use.\n    \"\"\"\n\n    query: str\n    args: dict[str, object]\n    prompt_only: bool\n    model: str | None = None\n    num_answers: int = 1\n    iterative_mode: bool = False\n    budget: dict[str, float] | None = None\n    cache_dir: str | None = None\n    cache_mode: ca.CacheMode = \"read_write\"\n    cache_format: CacheFormat = \"yaml\"\n</code></pre>"},{"location":"reference/stdlib/effects/","title":"Standard Nodes and Effects","text":""},{"location":"reference/stdlib/effects/#generic-utilities","title":"Generic Utilities","text":""},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.spawn_node","title":"spawn_node","text":"<pre><code>spawn_node(node_type: type[N], **args: Any) -&gt; NodeBuilder[Any, Any]\n</code></pre> <p>A convenience helper to write effect triggering functions.</p> <p>Attributes:</p> Name Type Description <code>node_type</code> <p>The type of the node to spawn (e.g., <code>Branch</code>).</p> <code>args</code> <p>Arguments to populate the node fields, passed to <code>Node.spawn</code>.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>def spawn_node[N: dp.Node](\n    node_type: type[N], **args: Any\n) -&gt; dp.NodeBuilder[Any, Any]:\n    \"\"\"\n    A convenience helper to write effect triggering functions.\n\n    Attributes:\n        node_type: The type of the node to spawn (e.g., `Branch`).\n        args: Arguments to populate the node fields, passed to\n            [`Node.spawn`][delphyne.core.trees.Node.spawn].\n    \"\"\"\n    return dp.NodeBuilder(lambda spawner: node_type.spawn(spawner, **args))\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.FromPolicy","title":"FromPolicy","text":"<pre><code>FromPolicy = Callable[[Any], T]\n</code></pre> <p>Type for an inner-policy-dependent data field.</p> <p>We use <code>Any</code> instead of introducing an inner policy type parameter <code>P</code>, since <code>Node</code> is not parametric either. Thus, this alias is mostly meant for readability and expressing intent.</p>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.NodeMeta","title":"NodeMeta","text":"<p>Abstract base class for node metadata.</p> <p>Nodes can feature fields with arbitrary metadata accessible to policies (e.g., <code>meta</code> field of <code>Branch</code>). Typing those fields with <code>NodeMeta</code> instead of <code>object</code> or <code>Any</code> allows for better type safety. In particular, it prevents errors that arise from accidentally passing uninstantiated parametric inner policy fields.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>class NodeMeta:\n    \"\"\"\n    Abstract base class for node metadata.\n\n    Nodes can feature fields with arbitrary metadata accessible to\n    policies (e.g., `meta` field of `Branch`). Typing those fields with\n    `NodeMeta` instead of `object` or `Any` allows for better type\n    safety. In particular, it prevents errors that arise from\n    accidentally passing uninstantiated parametric inner policy fields.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/stdlib/effects/#branch","title":"Branch","text":""},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.Branch","title":"Branch  <code>dataclass</code>","text":"<p>               Bases: <code>Node</code></p> <p>The standard <code>Branch</code> effect.</p> <p>Can be triggered using the <code>branch</code> function, which allows branching over elements of an opaque space.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>@dataclass(frozen=True)\nclass Branch(dp.Node):\n    \"\"\"\n    The standard `Branch` effect.\n\n    Can be triggered using the `branch` function, which allows branching\n    over elements of an opaque space.\n    \"\"\"\n\n    cands: OpaqueSpace[Any, Any]\n    meta: FromPolicy[NodeMeta] | None\n\n    @override\n    def navigate(self) -&gt; dp.Navigation:\n        return (yield self.cands)\n\n    @override\n    def primary_space(self) -&gt; dp.Space[Any]:\n        return self.cands\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.branch","title":"branch","text":"<pre><code>branch(\n    cands: Opaque[P, T],\n    meta: Callable[[P], NodeMeta] | None = None,\n    inner_policy_type: type[P] | None = None,\n) -&gt; Strategy[Branch, P, T]\n</code></pre> <p>Branch over the elements of an opaque space.</p> <p>Parameters:</p> Name Type Description Default <code>cands</code> <code>Opaque[P, T]</code> <p>An opaque space, which can be defined from either a query or a strategy via the <code>using</code> method.</p> required <code>meta</code> <code>Callable[[P], NodeMeta] | None</code> <p>An optional mapping from the ambient inner policy to arbitrary metadata accessible to search policies.</p> <code>None</code> <code>inner_policy_type</code> <code>type[P] | None</code> <p>Ambient inner policy type. This information is not used at runtime but it can be provided to help type inference when necessary.</p> <code>None</code> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>def branch[P, T](\n    cands: Opaque[P, T],\n    meta: Callable[[P], NodeMeta] | None = None,\n    inner_policy_type: type[P] | None = None,\n) -&gt; dp.Strategy[Branch, P, T]:\n    \"\"\"\n    Branch over the elements of an opaque space.\n\n    Arguments:\n        cands: An opaque space, which can be defined from either a query\n            or a strategy via the `using` method.\n        meta: An optional mapping from the ambient inner policy to\n            arbitrary metadata accessible to search policies.\n        inner_policy_type: Ambient inner policy type. This information\n            is not used at runtime but it can be provided to help type\n            inference when necessary.\n    \"\"\"\n    ret = yield spawn_node(Branch, cands=cands, meta=meta)\n    return cast(T, ret)\n</code></pre>"},{"location":"reference/stdlib/effects/#fail","title":"Fail","text":""},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.Fail","title":"Fail  <code>dataclass</code>","text":"<p>               Bases: <code>Node</code></p> <p>The standard <code>Fail</code> effect.</p> <p>Can be triggered using the <code>fail</code> and <code>ensure</code> functions.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>@dataclass(frozen=True)\nclass Fail(dp.Node):\n    \"\"\"\n    The standard `Fail` effect.\n\n    Can be triggered using the `fail` and `ensure` functions.\n    \"\"\"\n\n    error: dp.Error\n\n    @override\n    def leaf_node(self) -&gt; bool:\n        return True\n\n    @override\n    def navigate(self) -&gt; dp.Navigation:\n        assert False\n        yield\n\n    @override\n    def summary_message(self) -&gt; str:\n        return str(self.error)\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.fail","title":"fail","text":"<pre><code>fail(\n    label: str | None = None, *, message: str | None = None, error: Error | None = None\n) -&gt; Strategy[Fail, object, NoReturn]\n</code></pre> <p>Fail immediately with an error.</p> <p>The error can be specified using the <code>error</code> keyword argument. As a shortcut, the <code>label</code> and <code>message</code> arguments can also be used to directly specify the corresponding fields of the <code>Error</code> type. Those arguments can only be used if <code>error</code> is not provided.</p> <p>Warning</p> <p>Like all effect triggering functions, this function must be invoked as:</p> <pre><code>yield from fail(...)\n</code></pre> <p>Forgetting <code>yield from</code> may not result in a type error but will result in a no-op at runtime.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>def fail(\n    label: str | None = None,\n    *,\n    message: str | None = None,\n    error: dp.Error | None = None,\n) -&gt; dp.Strategy[Fail, object, NoReturn]:\n    \"\"\"\n    Fail immediately with an error.\n\n    The error can be specified using the `error` keyword argument. As a\n    shortcut, the `label` and `message` arguments can also be used to\n    directly specify the corresponding fields of the `Error` type. Those\n    arguments can only be used if `error` is not provided.\n\n    !!! warning\n        Like all effect triggering functions, this function must be\n        invoked as:\n\n            yield from fail(...)\n\n        Forgetting `yield from` may not result in a type error but will\n        result in a no-op at runtime.\n    \"\"\"\n    yield spawn_node(Fail, error=_build_error(message, label, error))\n    assert False\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.ensure","title":"ensure","text":"<pre><code>ensure(\n    prop: bool,\n    label: str | None = None,\n    *,\n    message: str | None = None,\n    error: Error | None = None,\n) -&gt; Strategy[Fail, object, None]\n</code></pre> <p>Ensure that a property holds, otherwise fail with an error.</p> <p>See <code>fail</code> regarding the <code>label</code>, <code>message</code> and <code>error</code> arguments.</p> <p>Warning</p> <p>Like all effect triggering functions, this function must be invoked as:</p> <pre><code>yield from ensure(...)\n</code></pre> <p>Forgetting <code>yield from</code> may not result in a type error but will result in a no-op at runtime.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>def ensure(\n    prop: bool,\n    label: str | None = None,\n    *,\n    message: str | None = None,\n    error: dp.Error | None = None,\n) -&gt; dp.Strategy[Fail, object, None]:\n    \"\"\"\n    Ensure that a property holds, otherwise fail with an error.\n\n    See `fail` regarding the `label`, `message` and `error` arguments.\n\n    !!! warning\n        Like all effect triggering functions, this function must be\n        invoked as:\n\n            yield from ensure(...)\n\n        Forgetting `yield from` may not result in a type error but will\n        result in a no-op at runtime.\n    \"\"\"\n    if not prop:\n        yield from fail(label=label, message=message, error=error)\n</code></pre>"},{"location":"reference/stdlib/effects/#message","title":"Message","text":""},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.Message","title":"Message  <code>dataclass</code>","text":"<p>               Bases: <code>Node</code></p> <p>The standard <code>Message</code> effect.</p> <p>Message nodes are tree nodes carrying a message. They have a unique child. They can be eliminated using the <code>elim_messages</code> tree transformer, which automatically logs their content.</p> <p>This effect is useful for debugging strategies. Using <code>print</code> statements in strategies is discouraged since strategy computations are replayed every time a child of the associated tree is computed, causing the same message to be repeatedly printed.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>@dataclass\nclass Message(dp.Node):\n    \"\"\"\n    The standard `Message` effect.\n\n    Message nodes are tree nodes carrying a message. They have a unique\n    child. They can be eliminated using the `elim_messages` tree\n    transformer, which automatically logs their content.\n\n    This effect is useful for debugging strategies. Using `print`\n    statements in strategies is discouraged since strategy computations\n    are replayed every time a child of the associated tree is computed,\n    causing the same message to be repeatedly printed.\n    \"\"\"\n\n    msg: str\n    data: object | None\n\n    @override\n    def navigate(self) -&gt; dp.Navigation:\n        return None\n        yield\n\n    @override\n    def summary_message(self) -&gt; str:\n        return self.msg\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.message","title":"message","text":"<pre><code>message(msg: str, data: object | None = None) -&gt; Strategy[Message, object, None]\n</code></pre> <p>Log a debugging message. See <code>Message</code> for more details.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>The message to log.</p> required <code>data</code> <code>object | None</code> <p>Optional data to attach to the message.</p> <code>None</code> <p>Warning</p> <p>Like all effect triggering functions, this function must be invoked as:</p> <pre><code>yield from message(...)\n</code></pre> <p>Forgetting <code>yield from</code> may not result in a type error but will result in a no-op at runtime.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>def message(\n    msg: str, data: object | None = None\n) -&gt; dp.Strategy[Message, object, None]:\n    \"\"\"\n    Log a debugging message. See `Message` for more details.\n\n    Arguments:\n        msg: The message to log.\n        data: Optional data to attach to the message.\n\n    !!! warning\n        Like all effect triggering functions, this function must be\n        invoked as:\n\n            yield from message(...)\n\n        Forgetting `yield from` may not result in a type error but will\n        result in a no-op at runtime.\n    \"\"\"\n    yield spawn_node(Message, msg=msg, data=data)\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.elim_messages","title":"elim_messages","text":"<pre><code>elim_messages(\n    env: PolicyEnv, policy: Any, show_in_log: bool = True\n) -&gt; PureTreeTransformerFn[Message, Never]\n</code></pre> <p>Eliminate the <code>Message</code> effect.</p> <p>Parameters:</p> Name Type Description Default <code>show_in_log</code> <code>bool</code> <p>Whether to log the associated content whenever a message node is encountered.</p> <code>True</code> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>@pol.contextual_tree_transformer\ndef elim_messages(\n    env: PolicyEnv,\n    policy: Any,\n    show_in_log: bool = True,\n) -&gt; pol.PureTreeTransformerFn[Message, Never]:\n    \"\"\"\n    Eliminate the `Message` effect.\n\n    Arguments:\n        show_in_log: Whether to log the associated content whenever a\n            message node is encountered.\n    \"\"\"\n\n    def transform[N: dp.Node, P, T](\n        tree: dp.Tree[Message | N, P, T],\n    ) -&gt; dp.Tree[N, P, T]:\n        if isinstance(tree.node, Message):\n            if show_in_log:\n                metadata = {\"attached\": tree.node.data}\n                env.tracer.log(tree.node.msg, metadata=metadata)\n            return transform(tree.child(None))\n        return tree.transform(tree.node, transform)\n\n    return transform\n</code></pre>"},{"location":"reference/stdlib/effects/#factor-and-value","title":"Factor and Value","text":""},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.Factor","title":"Factor  <code>dataclass</code>","text":"<p>               Bases: <code>Node</code></p> <p>The standard <code>Factor</code> effect.</p> <p>A <code>Factor</code> node allows computing a confidence score in the [0, 1] interval. This confidence can be computed by a query or a dedicated strategy but only one element will be generated from the resulting space. Instead of having an oracle compute a numerical value directly, it computes an evaluation object that is then transformed into a number using a policy-provided function. This allows greater flexibility on the policy side. If no such function is given, the whole node is ignored.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>@dataclass(frozen=True)\nclass Factor(dp.Node):\n    \"\"\"\n    The standard `Factor` effect.\n\n    A `Factor` node allows computing a confidence score in the [0, 1]\n    interval. This confidence can be computed by a query or a dedicated\n    strategy but only one element will be generated from the resulting\n    space. Instead of having an oracle compute a numerical value\n    directly, it computes an evaluation object that is then transformed\n    into a number using a policy-provided function. This allows greater\n    flexibility on the policy side. If no such function is given, the\n    whole node is ignored.\n    \"\"\"\n\n    eval: OpaqueSpace[Any, Any]\n    factor: FromPolicy[Callable[[Any], float] | None]\n\n    @override\n    def navigate(self) -&gt; dp.Navigation:\n        return None\n        yield\n\n    @override\n    def primary_space(self):\n        return self.eval\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.factor","title":"factor","text":"<pre><code>factor(\n    eval: Opaque[P, E],\n    factor: Callable[[P], Callable[[E], float] | None],\n    inner_policy_type: type[P] | None = None,\n) -&gt; Strategy[Factor, P, None]\n</code></pre> <p>Apply a multiplicative penalty to the current search branch.</p> <p>Parameters:</p> Name Type Description Default <code>eval</code> <code>Opaque[P, E]</code> <p>An opaque space, typically induced by a strategy or a query whose purpose is to evaluate the current search state, returning an evaluation object of type <code>E</code>. Policies typically extract a single element from this space.</p> required <code>factor</code> <code>Callable[[P], Callable[[E], float] | None]</code> <p>An inner-policy-dependent function that maps an evaluation object of type <code>E</code> to an actual numerical penalty, as a multiplicative factor in the [0, 1] interval. If no function is provided, the whole node is ignored. Separating <code>eval</code> and <code>factor</code> allows greater flexibility for policies to tune how multidimensional state evaluations are reduced into a single numbers.</p> required <p>Warning</p> <p>Like all effect triggering functions, this function must be invoked as:</p> <pre><code>yield from factor(...)\n</code></pre> <p>Forgetting <code>yield from</code> may not result in a type error but will result in a no-op at runtime.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>def factor[E, P](\n    eval: Opaque[P, E],\n    factor: Callable[[P], Callable[[E], float] | None],\n    inner_policy_type: type[P] | None = None,\n) -&gt; dp.Strategy[Factor, P, None]:\n    \"\"\"\n    Apply a multiplicative penalty to the current search branch.\n\n    Arguments:\n        eval: An opaque space, typically induced by a strategy or a\n            query whose purpose is to evaluate the current search state,\n            returning an evaluation object of type `E`. Policies\n            typically extract a single element from this space.\n        factor: An inner-policy-dependent function that maps an\n            evaluation object of type `E` to an actual numerical\n            penalty, as a multiplicative factor in the [0, 1] interval.\n            If no function is provided, the whole node is ignored.\n            Separating `eval` and `factor` allows greater flexibility\n            for policies to tune how multidimensional state evaluations\n            are reduced into a single numbers.\n\n    !!! warning\n        Like all effect triggering functions, this function must be\n        invoked as:\n\n            yield from factor(...)\n\n        Forgetting `yield from` may not result in a type error but will\n        result in a no-op at runtime.\n    \"\"\"\n    yield spawn_node(Factor, eval=eval, factor=factor)\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.Value","title":"Value  <code>dataclass</code>","text":"<p>               Bases: <code>Node</code></p> <p>The standard <code>Value</code> effect.</p> <p>Similar to <code>Factor</code>, except that the resulting number is used to set the whole value of the branch instead of just multiplying it.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>@dataclass(frozen=True)\nclass Value(dp.Node):\n    \"\"\"\n    The standard `Value` effect.\n\n    Similar to `Factor`, except that the resulting number is used to set\n    the whole value of the branch instead of just multiplying it.\n    \"\"\"\n\n    eval: OpaqueSpace[Any, Any]\n    value: FromPolicy[Callable[[Any], float] | None]\n\n    @override\n    def navigate(self) -&gt; dp.Navigation:\n        return None\n        yield\n\n    @override\n    def primary_space(self):\n        return self.eval\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.value","title":"value","text":"<pre><code>value(\n    eval: Opaque[P, E],\n    value: Callable[[P], Callable[[E], float] | None],\n    inner_policy_type: type[P] | None = None,\n) -&gt; Strategy[Value, P, None]\n</code></pre> <p>Set the value of the current search branch.</p> <p>See the similar <code>factor</code> function for more details.</p> <p>Warning</p> <p>Like all effect triggering functions, this function must be invoked as:</p> <pre><code>yield from message(...)\n</code></pre> <p>Forgetting <code>yield from</code> may not result in a type error but will result in a no-op at runtime.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>def value[E, P](\n    eval: Opaque[P, E],\n    value: Callable[[P], Callable[[E], float] | None],\n    inner_policy_type: type[P] | None = None,\n) -&gt; dp.Strategy[Value, P, None]:\n    \"\"\"\n    Set the value of the current search branch.\n\n    See the similar `factor` function for more details.\n\n    !!! warning\n        Like all effect triggering functions, this function must be\n        invoked as:\n\n            yield from message(...)\n\n        Forgetting `yield from` may not result in a type error but will\n        result in a no-op at runtime.\n    \"\"\"\n    yield spawn_node(Value, eval=eval, value=value)\n</code></pre>"},{"location":"reference/stdlib/effects/#join","title":"Join","text":""},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.Join","title":"Join  <code>dataclass</code>","text":"<p>               Bases: <code>Node</code></p> <p>The standard <code>Join</code> effect.</p> <p>This effect can be triggered using the <code>join</code> function. A <code>Join</code> node features a sequence of embedded trees.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>@dataclass(frozen=True)\nclass Join(dp.Node):\n    \"\"\"\n    The standard `Join` effect.\n\n    This effect can be triggered using the `join` function. A `Join`\n    node features a sequence of embedded trees.\n    \"\"\"\n\n    subs: Sequence[dp.EmbeddedTree[Any, Any, Any]]\n    meta: FromPolicy[NodeMeta] | None\n\n    @override\n    def navigate(self) -&gt; dp.Navigation:\n        ret: list[Any] = []\n        for sub in self.subs:\n            ret.append((yield sub))\n        return tuple(ret)\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.nodes.join","title":"join","text":"<pre><code>join(\n    subs: Sequence[StrategyComp[N, P, T]],\n    meta: Callable[[P], NodeMeta] | None = None,\n) -&gt; Strategy[N, P, Sequence[T]]\n</code></pre> <p>Evaluate a sequence of independent strategy computations, possibly in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>subs</code> <code>Sequence[StrategyComp[N, P, T]]</code> <p>A sequence of strategy computations to evaluate.</p> required <code>meta</code> <code>Callable[[P], NodeMeta] | None</code> <p>An optional mapping from the ambient inner policy to arbitrary metadata accessible to search policies.</p> <code>None</code> <p>Returns:</p> Type Description <code>Strategy[N, P, Sequence[T]]</code> <p>A sequence featuring all computation results.</p> Source code in <code>src/delphyne/stdlib/nodes.py</code> <pre><code>def join[N: dp.Node, P, T](\n    subs: Sequence[dp.StrategyComp[N, P, T]],\n    meta: Callable[[P], NodeMeta] | None = None,\n) -&gt; dp.Strategy[N, P, Sequence[T]]:\n    \"\"\"\n    Evaluate a sequence of independent strategy computations, possibly\n    in parallel.\n\n    Arguments:\n        subs: A sequence of strategy computations to evaluate.\n        meta: An optional mapping from the ambient inner policy to\n            arbitrary metadata accessible to search policies.\n\n    Returns:\n        A sequence featuring all computation results.\n    \"\"\"\n    ret = yield spawn_node(Join, subs=subs, meta=meta)\n    return cast(Sequence[T], ret)\n</code></pre>"},{"location":"reference/stdlib/effects/#compute","title":"Compute","text":""},{"location":"reference/stdlib/effects/#delphyne.stdlib.computations.Compute","title":"Compute  <code>dataclass</code>","text":"<p>               Bases: <code>ComputationNode</code></p> <p>The standard <code>Compute</code> effect.</p> <p>For efficiency and replicability reasons, strategies must not directly perform expensive and possibly non-replicable computations. For example, a strategy should not directly call an SMT solver since:</p> <ul> <li>The call may be expensive, and stratgy computations are replayed from scratch every time a child is computed in the corresponding tree (see documentation for <code>reify</code>).</li> <li>SMT solvers using wall-time timeouts may return different results when called repeatedly on the same input.</li> </ul> <p>The <code>Compute</code> effect allows performing an expensive and possibly non-deterministic computation by issuing a special <code>__Computation__</code> query that specifies the computation to be performed. Such a query is not answered by an LLM, but by actually performing the described computation. Special support is available in the demonstration interpreter in the form of implicit answers, allowing <code>__Computation__</code> queries to be automatically answered when running tests. Generated answers can be hardcoded in demonstrations after the fact via proper editor support.</p> Source code in <code>src/delphyne/stdlib/computations.py</code> <pre><code>@dataclass\nclass Compute(dp.ComputationNode):\n    \"\"\"\n    The standard `Compute` effect.\n\n    For efficiency and replicability reasons, strategies must not directly\n    perform expensive and possibly non-replicable computations. For example,\n    a strategy should not directly call an SMT solver since:\n\n    - The call may be expensive, and stratgy computations are replayed from\n    scratch every time a child is computed in the corresponding tree (see\n    documentation for `reify`).\n    - SMT solvers using wall-time timeouts may return different results when\n    called repeatedly on the same input.\n\n    The `Compute` effect allows performing an expensive and possibly\n    non-deterministic computation by issuing a special `__Computation__`\n    query that specifies the computation to be performed. Such a query is\n    not answered by an LLM, but by _actually_ performing the described\n    computation. Special support is available in the demonstration\n    interpreter in the form of *implicit answers*, allowing\n    `__Computation__` queries to be automatically answered when running\n    tests. Generated answers can be hardcoded in demonstrations **after**\n    the fact via proper editor support.\n    \"\"\"\n\n    query: dp.TransparentQuery[Any]\n    _comp: Callable[[], Any]\n    _ret_type: ty.TypeAnnot[Any]\n\n    def navigate(self) -&gt; dp.Navigation:\n        return (yield self.query)\n\n    def run_computation(self) -&gt; str:\n        ret = self._comp()\n        serialized = dump_yaml(self._ret_type, ret)\n        return serialized\n\n    def run_computation_with_cache(self, cache: dp.LLMCache | None) -&gt; str:\n        \"\"\"\n        Run the computation using a fake oracle so that the LLM caching\n        mechanism can be reused.\n        \"\"\"\n        chat = create_prompt(\n            self.query.attached.query,\n            examples=[],\n            params={},\n            mode=None,\n            env=None,\n        )\n        req = dp.LLMRequest(chat=chat, num_completions=1, options={})\n        model = ComputationOracle(self.run_computation)\n        resp = model.send_request(req, cache)\n        assert len(resp.outputs) == 1\n        answer = resp.outputs[0].content\n        assert isinstance(answer, str)\n        return answer\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.computations.compute","title":"compute","text":"<pre><code>compute(\n    f: Callable[P, T], *args: P.args, **kwargs: P.kwargs\n) -&gt; Strategy[Compute, object, T]\n</code></pre> <p>Triggering function for the <code>Compute</code> effect.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>Callable[P, T]</code> <p>Function performing an expensive computation. It must feature type annotations and its arguments must be JSON-serializable. It does not need to be deterministic.</p> required <code>*args</code> <code>P.args</code> <p>Positional arguments to pass to <code>f</code>.</p> <code>()</code> <code>**kwargs</code> <code>P.kwargs</code> <p>Keyword arguments to pass to <code>f</code>.</p> <code>{}</code> Source code in <code>src/delphyne/stdlib/computations.py</code> <pre><code>def compute[**P, T](\n    f: Callable[P, T], *args: P.args, **kwargs: P.kwargs\n) -&gt; dp.Strategy[Compute, object, T]:\n    \"\"\"\n    Triggering function for the `Compute` effect.\n\n    Arguments:\n        f: Function performing an expensive computation. It must feature\n            type annotations and its arguments must be\n            JSON-serializable. It does not need to be deterministic.\n        *args: Positional arguments to pass to `f`.\n        **kwargs: Keyword arguments to pass to `f`.\n    \"\"\"\n    comp = partial(f, *args, **kwargs)\n    ret_type = insp.function_return_type(f)\n    assert not isinstance(ret_type, ty.NoTypeInfo)\n    fun_args = insp.function_args_dict(f, args, kwargs)\n    fun = insp.function_name(f)\n    assert fun is not None\n    query = dp.TransparentQuery.build(__Computation__(fun, fun_args))\n    unparsed = yield spawn_node(\n        Compute, query=query, _comp=comp, _ret_type=ret_type\n    )\n    ret = ty.pydantic_load(ret_type, unparsed)\n    return cast(T, ret)\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.computations.elim_compute","title":"elim_compute","text":"<pre><code>elim_compute(\n    env: PolicyEnv, policy: Any, force_bypass_cache: bool = False\n) -&gt; PureTreeTransformerFn[Compute, Never]\n</code></pre> <p>Eliminate the <code>Compute</code> effect by performing the computation when computing tree children (making the <code>child</code> function possibly nondeterministic).</p> <p>Parameters:</p> Name Type Description Default <code>force_bypass_cache</code> <code>bool</code> <p>if set to <code>True</code>, do not cache computation results, even if a cache is available in the global policy environment.</p> <code>False</code> Source code in <code>src/delphyne/stdlib/computations.py</code> <pre><code>@dp.contextual_tree_transformer\ndef elim_compute(\n    env: PolicyEnv,\n    policy: Any,\n    force_bypass_cache: bool = False,\n) -&gt; dp.PureTreeTransformerFn[Compute, Never]:\n    \"\"\"\n    Eliminate the `Compute` effect by performing the computation when\n    computing tree children (making the `child` function possibly\n    nondeterministic).\n\n    Arguments:\n        force_bypass_cache: if set to `True`, do not cache computation\n            results, even if a cache is available in the global policy\n            environment.\n    \"\"\"\n\n    def transform[N: dp.Node, P, T](\n        tree: dp.Tree[Compute | N, P, T],\n    ) -&gt; dp.Tree[N, P, T]:\n        if isinstance(tree.node, Compute):\n            cache = None\n            if not force_bypass_cache:\n                cache = env.requests_cache\n            answer = tree.node.run_computation_with_cache(cache)\n            tracked = tree.node.query.attached.parse_answer(\n                dp.Answer(None, answer)\n            )\n            assert not isinstance(tracked, dp.ParseError)\n            return transform(tree.child(tracked))\n\n        return tree.transform(tree.node, transform)\n\n    return transform\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.stdlib.computations.__Computation__","title":"__Computation__  <code>dataclass</code>","text":"<p>               Bases: <code>AbstractQuery[object]</code></p> <p>A special query that represents a computation.</p> <p>Returns a parsed JSON result.</p> <p>Attributes:</p> Name Type Description <code>fun</code> <code>str</code> <p>Name of the function to call.</p> <code>args</code> <code>dict[str, Any]</code> <p>Arguments to pass to the function, as a dictionary.</p> Source code in <code>src/delphyne/stdlib/computations.py</code> <pre><code>@dataclass\nclass __Computation__(dp.AbstractQuery[object]):\n    \"\"\"\n    A special query that represents a computation.\n\n    Returns a parsed JSON result.\n\n    Attributes:\n        fun: Name of the function to call.\n        args: Arguments to pass to the function, as a dictionary.\n    \"\"\"\n\n    fun: str\n    args: dict[str, Any]\n\n    @override\n    def generate_prompt(\n        self,\n        *,\n        kind: str,\n        mode: dp.AnswerMode,\n        params: dict[str, object],\n        extra_args: dict[str, object] | None = None,\n        env: dp.AbstractTemplatesManager | None = None,\n    ):\n        return dump_yaml(Any, self.__dict__)\n\n    @override\n    def query_modes(self):\n        return [None]\n\n    @override\n    def answer_type(self):\n        return object\n\n    @override\n    def parse_answer(self, answer: dp.Answer) -&gt; object | dp.ParseError:\n        try:\n            assert isinstance(answer.content, str)\n            return yaml.safe_load(answer.content)\n        except yaml.parser.ParserError as e:\n            return dp.ParseError(description=str(e))\n</code></pre>"},{"location":"reference/stdlib/effects/#flag","title":"Flag","text":""},{"location":"reference/stdlib/effects/#delphyne.Flag","title":"Flag  <code>dataclass</code>","text":"<p>               Bases: <code>Node</code></p> <p>The standard <code>Flag</code> effect.</p> <p>Flags allow providing several implementations for a strategy component, and have policies select which variant to use (or perform search at runtime for selecting variants).</p> <p>For each flag, a subclass of <code>FlagQuery</code> must be defined, which admits a finite set of answers (one per allowed flag value), along with a default answer. Type parameter <code>F</code> denotes the type of the flag query that can be issued. To express a signature wih several flag queries, use <code>Flag[A] | Flag[B]</code> instead of <code>Flag[A | B]</code>, so that both kinds of flags can be eliminated separately.</p> Behavior in demonstrations <p>Because flag queries override <code>AbstractQuery.default_answer</code>, default flag values are automatically selected by the demonstration interpreter. This behaviour can be overriden by adding answers for flag queries in the <code>queries</code> section, or by using value-based hints (i.e., <code>#flag_value</code>, which is possible since flag queries implement <code>AbstractQuery.finite_answer_set</code>).</p> Source code in <code>src/delphyne/stdlib/flags.py</code> <pre><code>@dataclass(frozen=True)\nclass Flag[F: FlagQuery[Any]](dp.Node):\n    \"\"\"\n    The standard `Flag` effect.\n\n    Flags allow providing several implementations for a strategy\n    component, and have policies select which variant to use (or perform\n    search at runtime for selecting variants).\n\n    For each flag, a subclass of `FlagQuery` must be defined, which\n    admits a finite set of answers (one per allowed flag value), along\n    with a default answer. Type parameter `F` denotes the type of the\n    flag query that can be issued. To express a signature wih several\n    flag queries, use `Flag[A] | Flag[B]` instead of `Flag[A | B]`, so\n    that both kinds of flags can be eliminated separately.\n\n    ??? info \"Behavior in demonstrations\"\n        Because flag queries override `AbstractQuery.default_answer`,\n        default flag values are automatically selected by the\n        demonstration interpreter. This behaviour can be overriden by\n        adding answers for flag queries in the `queries` section, or by\n        using value-based hints (i.e., `#flag_value`, which is possible\n        since flag queries implement `AbstractQuery.finite_answer_set`).\n    \"\"\"\n\n    flag: dp.TransparentQuery[Any]\n\n    def summary_message(self) -&gt; str:\n        query = self.flag.attached.query\n        assert isinstance(query, FlagQuery)\n        name = query.query_name()\n        return f\"{name}: {', '.join(query.flag_values())}\"\n\n    def navigate(self) -&gt; dp.Navigation:\n        return (yield self.flag)\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.get_flag","title":"get_flag","text":"<pre><code>get_flag(flag: type[FlagQuery[T]]) -&gt; Strategy[Flag[Any], object, T]\n</code></pre> <p>Triggering function for the <code>Flag</code> effect.</p> <p>Takes a flag query type as an argument and return a flag value.</p> <p>Info</p> <p>A more precise type cannot be given for this function since Python does not support higher-kinded types.</p> Source code in <code>src/delphyne/stdlib/flags.py</code> <pre><code>def get_flag[T: str](\n    flag: type[FlagQuery[T]],\n) -&gt; dp.Strategy[Flag[Any], object, T]:\n    \"\"\"\n    Triggering function for the `Flag` effect.\n\n    Takes a flag query type as an argument and return a flag value.\n\n    !!! info\n        A more precise type cannot be given for this function since\n        Python does not support higher-kinded types.\n    \"\"\"\n    query = dp.TransparentQuery.build(flag())\n    ret = yield spawn_node(Flag, flag=query)\n    return cast(T, ret)\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.elim_flag","title":"elim_flag","text":"<pre><code>elim_flag(\n    env: PolicyEnv, policy: Any, flag: type[F], val: str\n) -&gt; PureTreeTransformerFn[Flag[F], Never]\n</code></pre> Source code in <code>src/delphyne/stdlib/flags.py</code> <pre><code>@dp.contextual_tree_transformer\ndef elim_flag[F: FlagQuery[Any]](\n    env: PolicyEnv,\n    policy: Any,\n    flag: type[F],\n    val: str,\n) -&gt; dp.PureTreeTransformerFn[Flag[F], Never]:\n    assert val in flag.flag_values()\n\n    def transform[N: dp.Node, P, T](\n        tree: dp.Tree[Flag[F] | N, P, T],\n    ) -&gt; dp.Tree[N, P, T]:\n        if isinstance(tree.node, Flag):\n            tree = cast(dp.Tree[Any, P, T], tree)\n            node = cast(Flag[Any], tree.node)\n            if isinstance(query := node.flag.attached.query, flag):\n                node = cast(Flag[F], node)\n                answer = dp.Answer(None, val)\n                assert answer in query.finite_answer_set()\n                tracked = node.flag.attached.parse_answer(answer)\n                assert not isinstance(tracked, dp.ParseError)\n                return transform(tree.child(tracked))\n        tree = cast(dp.Tree[Any, P, T], tree)\n        node = cast(Any, tree.node)\n        return tree.transform(node, transform)\n\n    return transform\n</code></pre>"},{"location":"reference/stdlib/effects/#delphyne.FlagQuery","title":"FlagQuery","text":"<p>               Bases: <code>Query[T]</code></p> <p>Base class for flag queries.</p> <p>Type parameter <code>T</code> must be of the form <code>Literal[s1, ..., sn]</code> where <code>si</code> are string literals. The first value is considered the default.</p> Source code in <code>src/delphyne/stdlib/flags.py</code> <pre><code>class FlagQuery[T: str](Query[T]):\n    \"\"\"\n    Base class for flag queries.\n\n    Type parameter `T` must be of the form `Literal[s1, ..., sn]` where\n    `si` are string literals. The first value is considered the default.\n    \"\"\"\n\n    @classmethod\n    def flag_values(cls) -&gt; Sequence[str]:\n        ans = insp.first_parameter_of_base_class(cls)\n        assert (args := insp.literal_type_args(ans)) is not None\n        assert len(args) &gt; 0\n        assert all(isinstance(a, str) for a in args)\n        return cast(Sequence[str], args)\n\n    def finite_answer_set(self) -&gt; Sequence[dp.Answer]:\n        vals = self.flag_values()\n        return [dp.Answer(None, v) for v in vals]\n\n    def default_answer(self) -&gt; dp.Answer:\n        return self.finite_answer_set()[0]\n\n    def parse_answer(self, answer: dp.Answer) -&gt; T | dp.ParseError:\n        if not isinstance(answer.content, str):\n            return dp.ParseError(description=\"Flag answer must be a string.\")\n        ans = self.flag_values()\n        if answer.content not in ans:\n            msg = f\"Invalid flag value: '{answer.content}'.\"\n            return dp.ParseError(description=msg)\n        return cast(T, answer.content)\n</code></pre>"},{"location":"reference/stdlib/environments/","title":"Policy Environments","text":""},{"location":"reference/stdlib/environments/#main-class","title":"Main Class","text":""},{"location":"reference/stdlib/environments/#delphyne.PolicyEnv","title":"PolicyEnv","text":"<p>The global environment accessible to policies.</p> <p>It can be used for:</p> <ul> <li>Fetching prompts, data, and examples.</li> <li>Caching LLM requests.</li> <li>Tracing nodes, query, answers, and logging information.</li> </ul> <p>Attributes:</p> Name Type Description <code>requests_cache</code> <code>LLMCache | None</code> <p>The requests cache, or <code>None</code> if caching is disabled. The exact type of the request cache is not statically determined and depends on the value of constructor argument <code>make_cache</code>.</p> <code>templates</code> <p>The prompt templates manager.</p> <code>tracer</code> <p>The tracer, which can also be used for logging.</p> <code>examples</code> <p>The example database.</p> Source code in <code>src/delphyne/stdlib/environments.py</code> <pre><code>class PolicyEnv:\n    \"\"\"\n    The global environment accessible to policies.\n\n    It can be used for:\n\n    - Fetching prompts, data, and examples.\n    - Caching LLM requests.\n    - Tracing nodes, query, answers, and logging information.\n\n    Attributes:\n        requests_cache: The requests cache, or `None` if caching is\n            disabled. The exact type of the request cache is not\n            statically determined and depends on the value of\n            constructor argument `make_cache`.\n        templates: The prompt templates manager.\n        tracer: The tracer, which can also be used for logging.\n        examples: The example database.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        prompt_dirs: Sequence[Path] = (),\n        demonstration_files: Sequence[Path] = (),\n        data_dirs: Sequence[Path] = (),\n        cache: CacheSpec | None = None,\n        do_not_match_identical_queries: bool = False,\n    ):\n        \"\"\"\n        Args:\n            prompt_dirs: A sequence of directories where Jinja prompt\n                templates can be found.\n            demonstration_files: A sequence of paths to demonstration\n                files (with or without extension `.demo.yaml`), to\n                create an example database from.\n            data_dirs: A sequence of directories where data files can be\n                found.\n            cache: A cache specification, or `None` to disable caching.\n                When caching is enabled, the `requests_cache` attribute\n                can be accessed by policies to properly wrap LLM models.\n            do_not_match_identical_queries: See `ExampleDatabase`.\n        \"\"\"\n        self.templates = TemplatesManager(prompt_dirs, data_dirs)\n        self.examples = ExampleDatabase(do_not_match_identical_queries)\n        self.tracer = Tracer()\n        self.requests_cache: md.LLMCache | None = None\n        if cache is not None:\n            self.requests_cache = md.LLMCache(cache)\n        for path in demonstration_files:\n            if not path.suffix.endswith(DEMO_FILE_EXT):\n                path = path.with_suffix(DEMO_FILE_EXT)\n            try:\n                with path.open() as f:\n                    content = yaml.safe_load(f)\n                    demos = pydantic_load(list[Demo], content)\n                    for demo in demos:\n                        self.examples.add_demonstration(demo)\n            except Exception as e:\n                raise InvalidDemoFile(path, e)\n</code></pre>"},{"location":"reference/stdlib/environments/#delphyne.PolicyEnv.__init__","title":"__init__","text":"<pre><code>__init__(\n    *,\n    prompt_dirs: Sequence[Path] = (),\n    demonstration_files: Sequence[Path] = (),\n    data_dirs: Sequence[Path] = (),\n    cache: CacheSpec | None = None,\n    do_not_match_identical_queries: bool = False,\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>prompt_dirs</code> <code>Sequence[Path]</code> <p>A sequence of directories where Jinja prompt templates can be found.</p> <code>()</code> <code>demonstration_files</code> <code>Sequence[Path]</code> <p>A sequence of paths to demonstration files (with or without extension <code>.demo.yaml</code>), to create an example database from.</p> <code>()</code> <code>data_dirs</code> <code>Sequence[Path]</code> <p>A sequence of directories where data files can be found.</p> <code>()</code> <code>cache</code> <code>CacheSpec | None</code> <p>A cache specification, or <code>None</code> to disable caching. When caching is enabled, the <code>requests_cache</code> attribute can be accessed by policies to properly wrap LLM models.</p> <code>None</code> <code>do_not_match_identical_queries</code> <code>bool</code> <p>See <code>ExampleDatabase</code>.</p> <code>False</code> Source code in <code>src/delphyne/stdlib/environments.py</code> <pre><code>def __init__(\n    self,\n    *,\n    prompt_dirs: Sequence[Path] = (),\n    demonstration_files: Sequence[Path] = (),\n    data_dirs: Sequence[Path] = (),\n    cache: CacheSpec | None = None,\n    do_not_match_identical_queries: bool = False,\n):\n    \"\"\"\n    Args:\n        prompt_dirs: A sequence of directories where Jinja prompt\n            templates can be found.\n        demonstration_files: A sequence of paths to demonstration\n            files (with or without extension `.demo.yaml`), to\n            create an example database from.\n        data_dirs: A sequence of directories where data files can be\n            found.\n        cache: A cache specification, or `None` to disable caching.\n            When caching is enabled, the `requests_cache` attribute\n            can be accessed by policies to properly wrap LLM models.\n        do_not_match_identical_queries: See `ExampleDatabase`.\n    \"\"\"\n    self.templates = TemplatesManager(prompt_dirs, data_dirs)\n    self.examples = ExampleDatabase(do_not_match_identical_queries)\n    self.tracer = Tracer()\n    self.requests_cache: md.LLMCache | None = None\n    if cache is not None:\n        self.requests_cache = md.LLMCache(cache)\n    for path in demonstration_files:\n        if not path.suffix.endswith(DEMO_FILE_EXT):\n            path = path.with_suffix(DEMO_FILE_EXT)\n        try:\n            with path.open() as f:\n                content = yaml.safe_load(f)\n                demos = pydantic_load(list[Demo], content)\n                for demo in demos:\n                    self.examples.add_demonstration(demo)\n        except Exception as e:\n            raise InvalidDemoFile(path, e)\n</code></pre>"},{"location":"reference/stdlib/environments/#delphyne.utils.caching.CacheSpec","title":"CacheSpec  <code>dataclass</code>","text":"<p>Specification for a function cache.</p> <p>Attributes:</p> Name Type Description <code>info</code> <code>CacheInfo</code> <p>Whether to use a YAML or DBM database, and where this database is located.</p> <code>mode</code> <code>CacheMode</code> <p>Desired caching behavior.</p> Source code in <code>src/delphyne/utils/caching.py</code> <pre><code>@dataclass(frozen=True)\nclass CacheSpec:\n    \"\"\"\n    Specification for a function cache.\n\n    Attributes:\n        info: Whether to use a YAML or DBM database, and where this\n            database is located.\n        mode: Desired caching behavior.\n    \"\"\"\n\n    info: CacheInfo\n    mode: CacheMode = \"read_write\"\n</code></pre>"},{"location":"reference/stdlib/environments/#delphyne.utils.caching.CacheInfo","title":"CacheInfo","text":"<pre><code>CacheInfo = CacheDb | CacheYaml\n</code></pre>"},{"location":"reference/stdlib/environments/#delphyne.utils.caching.CacheMode","title":"CacheMode","text":"<pre><code>CacheMode = Literal['read_write', 'off', 'create', 'replay']\n</code></pre> <p>Caching mode:</p> <ul> <li><code>off</code>: the cache is disabled.</li> <li><code>read_write</code>: values can be read and written to the cache (no extra       check is made).</li> <li><code>create</code>: the cache is used in write-only mode, and an exception is       raided if a cached value already exists.</li> <li><code>replay</code>: all requests must hit the cache or an exception is raised.</li> </ul>"},{"location":"reference/stdlib/environments/#delphyne.InvalidDemoFile","title":"InvalidDemoFile  <code>dataclass</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when a demonstration file could not be parsed.</p> Source code in <code>src/delphyne/stdlib/environments.py</code> <pre><code>@dataclass\nclass InvalidDemoFile(Exception):\n    \"\"\"\n    Exception raised when a demonstration file could not be parsed.\n    \"\"\"\n\n    file: Path\n    exn: Exception\n</code></pre>"},{"location":"reference/stdlib/environments/#example-database","title":"Example Database","text":""},{"location":"reference/stdlib/environments/#delphyne.Example","title":"Example  <code>dataclass</code>","text":"<p>An example, usable for few-shot prompting.</p> <p>Attributes:</p> Name Type Description <code>args</code> <code>QuerySerializedArgs</code> <p>The serialized query arguments.</p> <code>answer</code> <code>Answer</code> <p>The answer to the query.</p> <code>tags</code> <code>Sequence[str]</code> <p>A sequence of tags associated with the example, which policies can use to select appropriate examples.</p> Source code in <code>src/delphyne/stdlib/environments.py</code> <pre><code>@dataclass\nclass Example:\n    \"\"\"\n    An example, usable for few-shot prompting.\n\n    Attributes:\n        args: The serialized query arguments.\n        answer: The answer to the query.\n        tags: A sequence of tags associated with the example, which\n            policies can use to select appropriate examples.\n    \"\"\"\n\n    args: QuerySerializedArgs\n    answer: Answer\n    tags: Sequence[str]\n</code></pre>"},{"location":"reference/stdlib/environments/#delphyne.stdlib.environments.QuerySerializedArgs","title":"QuerySerializedArgs","text":"<pre><code>QuerySerializedArgs = dict[str, Any]\n</code></pre> <p>Serialized query arguments, as a dictionary mapping attributed to JSON values (assemblies of integers, strings, dictionnaries, list, tuples...).</p>"},{"location":"reference/stdlib/environments/#delphyne.ExampleDatabase","title":"ExampleDatabase  <code>dataclass</code>","text":"<p>A simple example database.</p> <p>Attributes:</p> Name Type Description <code>do_not_match_identical_queries</code> <code>bool</code> <p>If set to <code>True</code>, the <code>examples</code> method won't return examples that match identical queries (i.e., with the exact same arguments). This is useful in the context of writing demonstrations, where one may want to see how an LLM would answer a query, even when a ground-truth answer is provided already.</p> <p>TODO: add provenance info for better error messages.</p> Source code in <code>src/delphyne/stdlib/environments.py</code> <pre><code>@dataclass\nclass ExampleDatabase:\n    \"\"\"\n    A simple example database.\n\n    Attributes:\n        do_not_match_identical_queries: If set to `True`, the `examples`\n            method won't return examples that match identical queries\n            (i.e., with the exact same arguments). This is useful in the\n            context of writing demonstrations, where one may want to see\n            how an LLM would answer a query, even when a ground-truth\n            answer is provided already.\n\n    TODO: add provenance info for better error messages.\n    \"\"\"\n\n    do_not_match_identical_queries: bool = False\n\n    # Maps each query name to a list of\n    _examples: dict[_QueryName, list[Example]] = field(\n        default_factory=lambda: defaultdict(list)\n    )\n\n    def add_query_demonstration(self, demo: QueryDemo):\n        \"\"\"\n        Add all examples from a standalone query demonstration to the\n        database.\n        \"\"\"\n        if not demo.answers:\n            return\n        if (ex := demo.answers[0].example) is not None and not ex:\n            # If the user explicitly asked not to include the example.\n            # TODO: What if the user asked to include several answers?\n            # Right now, we only allow the first one to be added.\n            return\n        demo_answer = demo.answers[0]\n        answer = translate_answer(demo_answer)\n        example = Example(demo.args, answer, demo_answer.tags)\n        self._examples[demo.query].append(example)\n\n    def add_demonstration(self, demo: Demo):\n        \"\"\"\n        Add all exmples from a demonstration to the database.\n        \"\"\"\n        if isinstance(demo, QueryDemo):\n            self.add_query_demonstration(demo)\n        else:\n            assert isinstance(demo, StrategyDemo)\n            for q in demo.queries:\n                self.add_query_demonstration(q)\n\n    def examples(\n        self, query_name: str, query_args: QuerySerializedArgs\n    ) -&gt; Iterable[Example]:\n        \"\"\"\n        Obtain all potential examples that can be used for few-shot\n        prompting with a given query.\n        \"\"\"\n        for ex in self._examples[query_name]:\n            if self.do_not_match_identical_queries:\n                if _equal_query_args(ex.args, query_args):\n                    continue\n            yield ex\n</code></pre>"},{"location":"reference/stdlib/environments/#delphyne.ExampleDatabase.add_query_demonstration","title":"add_query_demonstration","text":"<pre><code>add_query_demonstration(demo: QueryDemo)\n</code></pre> <p>Add all examples from a standalone query demonstration to the database.</p> Source code in <code>src/delphyne/stdlib/environments.py</code> <pre><code>def add_query_demonstration(self, demo: QueryDemo):\n    \"\"\"\n    Add all examples from a standalone query demonstration to the\n    database.\n    \"\"\"\n    if not demo.answers:\n        return\n    if (ex := demo.answers[0].example) is not None and not ex:\n        # If the user explicitly asked not to include the example.\n        # TODO: What if the user asked to include several answers?\n        # Right now, we only allow the first one to be added.\n        return\n    demo_answer = demo.answers[0]\n    answer = translate_answer(demo_answer)\n    example = Example(demo.args, answer, demo_answer.tags)\n    self._examples[demo.query].append(example)\n</code></pre>"},{"location":"reference/stdlib/environments/#delphyne.ExampleDatabase.add_demonstration","title":"add_demonstration","text":"<pre><code>add_demonstration(demo: Demo)\n</code></pre> <p>Add all exmples from a demonstration to the database.</p> Source code in <code>src/delphyne/stdlib/environments.py</code> <pre><code>def add_demonstration(self, demo: Demo):\n    \"\"\"\n    Add all exmples from a demonstration to the database.\n    \"\"\"\n    if isinstance(demo, QueryDemo):\n        self.add_query_demonstration(demo)\n    else:\n        assert isinstance(demo, StrategyDemo)\n        for q in demo.queries:\n            self.add_query_demonstration(q)\n</code></pre>"},{"location":"reference/stdlib/environments/#delphyne.ExampleDatabase.examples","title":"examples","text":"<pre><code>examples(query_name: str, query_args: QuerySerializedArgs) -&gt; Iterable[Example]\n</code></pre> <p>Obtain all potential examples that can be used for few-shot prompting with a given query.</p> Source code in <code>src/delphyne/stdlib/environments.py</code> <pre><code>def examples(\n    self, query_name: str, query_args: QuerySerializedArgs\n) -&gt; Iterable[Example]:\n    \"\"\"\n    Obtain all potential examples that can be used for few-shot\n    prompting with a given query.\n    \"\"\"\n    for ex in self._examples[query_name]:\n        if self.do_not_match_identical_queries:\n            if _equal_query_args(ex.args, query_args):\n                continue\n        yield ex\n</code></pre>"},{"location":"reference/stdlib/environments/#tracer","title":"Tracer","text":""},{"location":"reference/stdlib/environments/#delphyne.TemplatesManager","title":"TemplatesManager","text":"<p>               Bases: <code>AbstractTemplatesManager</code></p> <p>A class for managing Jinja prompt templates.</p> <p>Templates are configured with the <code>trim_blocks</code> and <code>lstrip_blocks</code> options set to <code>True</code> (no newlines are inserted after blocks and indentation can be used within blocks without affecting the output). The <code>keep_trailing_newline</code> option is set to <code>False</code> so trailing new lines at the end of template files are ignored.</p> <p>Templates are first searched in the provided prompt folders and then in the standard library (<code>delphyne.stdlib.templates</code>). For example, to show standard formatting instructions, you can include the following in your instance prompts:</p> <pre><code>{% include 'stdlib/format.jinja' %}\n</code></pre> <p>All templates automatically have access to the following global objects:</p> <ul> <li>A <code>yaml</code> filter for converting an object into a YAML string.</li> <li>A <code>json</code> filter for converting an object into a JSON string.</li> <li>A <code>fail</code> function that takes an error message as an argument and   raises an exception on Python side.</li> </ul> Source code in <code>src/delphyne/stdlib/environments.py</code> <pre><code>class TemplatesManager(qu.AbstractTemplatesManager):\n    \"\"\"\n    A class for managing Jinja prompt templates.\n\n    Templates are configured with the `trim_blocks` and `lstrip_blocks`\n    options set to `True` (no newlines are inserted after blocks and\n    indentation can be used within blocks without affecting the output).\n    The `keep_trailing_newline` option is set to `False` so trailing new\n    lines at the end of template files are ignored.\n\n    Templates are first searched in the provided prompt folders and then\n    in the standard library (`delphyne.stdlib.templates`). For example,\n    to show standard formatting instructions, you can include the\n    following in your instance prompts:\n\n    ```jinja\n    {% include 'stdlib/format.jinja' %}\n    ```\n\n    All templates automatically have access to the following global\n    objects:\n\n    - A `yaml` filter for converting an object into a YAML string.\n    - A `json` filter for converting an object into a JSON string.\n    - A `fail` function that takes an error message as an argument and\n      raises an exception on Python side.\n    \"\"\"\n\n    def __init__(self, prompt_dirs: Sequence[Path], data_dirs: Sequence[Path]):\n        \"\"\"\n        Args:\n            prompt_dirs: A sequence of directories where Jinja prompt\n                templates can be found.\n            data_dirs: A sequence of directories where data files can be\n                found.\n        \"\"\"\n        self.prompt_folders = prompt_dirs\n        self.data = _load_data(data_dirs)\n        loader = jinja2.ChoiceLoader(\n            [\n                jinja2.FileSystemLoader(self.prompt_folders),\n                jinja2.PackageLoader(\"delphyne.stdlib\"),\n            ]\n        )\n        self.env = jinja2.Environment(\n            loader=loader,\n            trim_blocks=True,\n            lstrip_blocks=True,\n            keep_trailing_newline=False,\n        )\n        self.env.filters[\"yaml\"] = dump_yaml_object\n        self.env.filters[\"json\"] = _dump_json_object\n        self.env.globals[\"fail\"] = _fail_from_template  # type: ignore\n\n    @override\n    def prompt(\n        self,\n        *,\n        query_name: str,\n        prompt_kind: Literal[\"system\", \"instance\"] | str,\n        template_args: dict[str, Any],\n        default_template: str | None = None,\n    ) -&gt; str:\n        suffix = \".\" + prompt_kind\n        template_name = f\"{query_name}{suffix}{JINJA_EXTENSION}\"\n        try:\n            template = self.env.get_template(template_name)\n        except jinja2.TemplateNotFound:\n            if default_template is not None:\n                template = self.env.from_string(default_template)\n            else:\n                raise qu.TemplateFileMissing(template_name)\n        try:\n            assert \"data\" not in template_args\n            template_args |= {\"data\": self.data}\n            return template.render(template_args)\n        except jinja2.TemplateNotFound as e:\n            raise qu.TemplateError(template_name, e)\n        except jinja2.UndefinedError as e:\n            raise qu.TemplateError(template_name, e)\n        except jinja2.TemplateSyntaxError as e:\n            raise qu.TemplateError(template_name, e)\n</code></pre>"},{"location":"reference/stdlib/environments/#delphyne.TemplatesManager.__init__","title":"__init__","text":"<pre><code>__init__(prompt_dirs: Sequence[Path], data_dirs: Sequence[Path])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>prompt_dirs</code> <code>Sequence[Path]</code> <p>A sequence of directories where Jinja prompt templates can be found.</p> required <code>data_dirs</code> <code>Sequence[Path]</code> <p>A sequence of directories where data files can be found.</p> required Source code in <code>src/delphyne/stdlib/environments.py</code> <pre><code>def __init__(self, prompt_dirs: Sequence[Path], data_dirs: Sequence[Path]):\n    \"\"\"\n    Args:\n        prompt_dirs: A sequence of directories where Jinja prompt\n            templates can be found.\n        data_dirs: A sequence of directories where data files can be\n            found.\n    \"\"\"\n    self.prompt_folders = prompt_dirs\n    self.data = _load_data(data_dirs)\n    loader = jinja2.ChoiceLoader(\n        [\n            jinja2.FileSystemLoader(self.prompt_folders),\n            jinja2.PackageLoader(\"delphyne.stdlib\"),\n        ]\n    )\n    self.env = jinja2.Environment(\n        loader=loader,\n        trim_blocks=True,\n        lstrip_blocks=True,\n        keep_trailing_newline=False,\n    )\n    self.env.filters[\"yaml\"] = dump_yaml_object\n    self.env.filters[\"json\"] = _dump_json_object\n    self.env.globals[\"fail\"] = _fail_from_template  # type: ignore\n</code></pre>"},{"location":"reference/stdlib/environments/#delphyne.TemplateFileMissing","title":"TemplateFileMissing  <code>dataclass</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when a template file is missing.</p> <p>This exception should only be raised when a top-level template file is missing. If an <code>include</code> statement fails within a template, a <code>TemplateError</code> exception should be raised instead.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@dataclass\nclass TemplateFileMissing(Exception):\n    \"\"\"\n    Exception raised when a template file is missing.\n\n    This exception should only be raised when a top-level template file\n    is missing. If an `include` statement fails within a template, a\n    `TemplateError` exception should be raised instead.\n    \"\"\"\n\n    file: str\n</code></pre>"},{"location":"reference/stdlib/experiments/","title":"Experiments","text":""},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment","title":"Experiment  <code>dataclass</code>","text":"<p>An experiment that consists in running an oracular program on a set of different hyperparameter combinations.</p> <p>This class allows defining and running experiments. It supports the use of multiple workers, and allows interrupting and resuming experiments (the persistent experiment state is stored in a file on disk). Failed configurations can be selectively retried. By activating caching, a successful experiment can be replicated (or some of its configurations replayed with a debugger) without issuing calls to LLMs or to tools with non-replicable outputs.</p> <p>          Class Type Parameters:        </p> Name Bound or Constraints Description Default <code>Config</code> <p>Type parameter for the configuration type, which is a dataclass that holds all experiment hyperparameters.</p> required <p>Attributes:</p> Name Type Description <code>experiment</code> <code>ExperimentFun[Config]</code> <p>The experiment function, which defines a run of an oracular program for each configuration.</p> <code>output_dir</code> <code>Path</code> <p>The directory where all experiment data is stored (persistent state, results, logs, caches...). The directory is created if it does not alredy exist.</p> <code>context</code> <code>CommandExecutionContext</code> <p>Command execution context, which contains the kind of information usually provided in the <code>delphyne.yaml</code> file (experiments do not recognize such files). Note that the <code>cache_root</code> argument should not be set, since it is disregarded and overriden by the <code>Experiment</code> class.</p> <code>configs</code> <code>Sequence[Config] | None</code> <p>A sequence of configurations to run. If <code>None</code> is provided and the experiment already has a persistent state stored on disk, the list of configurations is loaded from there upon loading.</p> <code>config_type</code> <code>type[Config] | NoTypeInfo</code> <p>The <code>Config</code> type, which is either passed explicitly or deduced from the <code>configs</code> argument.</p> <code>name</code> <code>str | None</code> <p>Experiment name, which is stored in the persistent state file when provided and is otherwise not used.</p> <code>description</code> <code>str | None</code> <p>Experiment description, which is stored in the persistent state file when provided and is otherwise not used.</p> <code>config_naming</code> <code>Callable[[Config, UUID], str] | None</code> <p>A function for attributing string identifiers to configurations, which maps a configuration along with a fresh UUID to a name. By default, the UUID alone is used.</p> <code>cache_requests</code> <code>bool</code> <p>Whether or not to enable caching of LLM requests and expensive computations (see <code>Compute</code>). When this is done, the experiment can be reliably replicated, without issuing LLM calls.</p> <code>cache_format</code> <code>CacheFormat</code> <p>Whether to cache requests using a DBM database or a directory of YAML files.</p> <code>export_raw_trace</code> <code>bool</code> <p>Whether to export the raw trace for all configuration runs.</p> <code>export_log</code> <code>bool</code> <p>Whether to export the log messages for all configuration runs.</p> <code>export_browsable_trace</code> <code>bool</code> <p>Whether to export a browsable trace for all configuration runs, which can be visualized in the VSCode extension (see <code>delphyne.analysis.feedback.Trace</code>). However, such traces can be large.</p>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment--tips","title":"Tips","text":"<ul> <li>New hyperparameters can be added to the <code>Config</code> type without   invalidating an existing experiment's persistent state, by   providing default values for them.</li> </ul> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>@dataclass(kw_only=True)\nclass Experiment[Config]:\n    \"\"\"\n    An experiment that consists in running an oracular program on a set of\n    different hyperparameter combinations.\n\n    This class allows defining and running experiments. It supports the\n    use of multiple workers, and allows interrupting and resuming\n    experiments (the persistent experiment state is stored in a file on\n    disk). Failed configurations can be selectively retried. By\n    activating caching, a successful experiment can be replicated (or\n    some of its configurations replayed with a debugger) without issuing\n    calls to LLMs or to tools with non-replicable outputs.\n\n    Type Parameters:\n        Config: Type parameter for the configuration type, which is a\n            dataclass that holds all experiment hyperparameters.\n\n    Attributes:\n        experiment: The experiment function, which defines a run of an\n            oracular program for each configuration.\n        output_dir: The directory where all experiment data is stored\n            (persistent state, results, logs, caches...). The directory\n            is created if it does not alredy exist.\n        context: Command execution context, which contains the kind of\n            information usually provided in the `delphyne.yaml` file\n            (experiments do not recognize such files). Note that the\n            `cache_root` argument should not be set, since it is\n            disregarded and overriden by the `Experiment` class.\n        configs: A sequence of configurations to run. If `None` is\n            provided and the experiment already has a persistent state\n            stored on disk, the list of configurations is loaded from\n            there upon loading.\n        config_type: The `Config` type, which is either passed\n            explicitly or deduced from the `configs` argument.\n        name: Experiment name, which is stored in the persistent state\n            file when provided and is otherwise not used.\n        description: Experiment description, which is stored in the\n            persistent state file when provided and is otherwise not used.\n        config_naming: A function for attributing string identifiers to\n            configurations, which maps a configuration along with a\n            fresh UUID to a name. By default, the UUID alone is used.\n        cache_requests: Whether or not to enable caching of LLM requests\n            and expensive computations (see `Compute`). When this is\n            done, the experiment can be reliably replicated, without\n            issuing LLM calls.\n        cache_format: Whether to cache requests using a DBM database or\n            a directory of YAML files.\n        export_raw_trace: Whether to export the raw trace for all\n            configuration runs.\n        export_log: Whether to export the log messages for all\n            configuration runs.\n        export_browsable_trace: Whether to export a browsable trace for\n            all configuration runs, which can be visualized in the VSCode\n            extension (see `delphyne.analysis.feedback.Trace`). However,\n            such traces can be large.\n\n    ## Tips\n\n    - New hyperparameters can be added to the `Config` type without\n      invalidating an existing experiment's persistent state, by\n      providing default values for them.\n    \"\"\"\n\n    experiment: ExperimentFun[Config]\n    output_dir: Path  # absolute path expected\n    context: CommandExecutionContext\n    configs: Sequence[Config] | None = None\n    config_type: type[Config] | NoTypeInfo = NoTypeInfo()\n    name: str | None = None\n    description: str | None = None\n    config_naming: Callable[[Config, uuid.UUID], str] | None = None\n    cache_requests: bool = True\n    cache_format: CacheFormat = \"db\"\n    export_raw_trace: bool = True\n    export_log: bool = True\n    export_browsable_trace: bool = True\n\n    def __post_init__(self):\n        # We override the cache root directory.\n        assert self.context.cache_root is None\n        self.context = replace(self.context, cache_root=self.output_dir)\n        if isinstance(self.config_type, NoTypeInfo):\n            if self.configs:\n                self.config_type = type(self.configs[0])\n\n    def load(self) -&gt; Self:\n        \"\"\"\n        Load the experiment.\n\n        If no persistent state exists on disk, it is created (with all\n        configurations marked with \"todo\" status). If some experiment\n        state exists on disk, it is loaded. If more configurations are\n        specified in `self.configs` than are specified on disk, the\n        missing configurations are added to the persistent state and\n        marked with \"todo\". If the persistent state contains\n        configurations that are not specified in `self.configs`, a\n        warning is shown. Use the `clean_index` method to remove these\n        configurations from the persistent state.\n\n        Return `self`, so as to allow chaining.\n        \"\"\"\n        if not self._dir_exists():\n            # If we create the experiment for the first time\n            print(f\"Creating experiment directory: {self.output_dir}.\")\n            self.output_dir.mkdir(parents=True, exist_ok=True)\n            state = ExperimentState[Config](self.name, self.description, {})\n            self._save_state(state)\n        if self.configs is not None:\n            self._add_configs_if_needed(self.configs)\n            # Print a warning if the state on disk features additional configs.\n            state = self._load_state()\n            assert state is not None\n            assert len(self.configs) &lt;= len(state.configs)\n            if len(self.configs) &lt; len(state.configs):\n                print(\n                    f\"Warning: {len(state.configs) - len(self.configs)} \"\n                    \"additional configuration(s) found in the state.\"\n                )\n        return self\n\n    def is_done(self) -&gt; bool:\n        \"\"\"\n        Check if the experiment is done, i.e., all configurations are\n        marked as \"done\".\n        \"\"\"\n        state = self._load_state()\n        assert state is not None\n        return all(info.status == \"done\" for info in state.configs.values())\n\n    def clean_index(self) -&gt; None:\n        \"\"\"\n        Remove from the persistent state file all configurations that\n        are not mentioned in `self.configs`.\n        \"\"\"\n        state = self._load_state()\n        assert state is not None\n        assert self.configs is not None\n        in_config = set(_config_unique_repr(c) for c in self.configs)\n        to_delete = [\n            c\n            for c, i in state.configs.items()\n            if _config_unique_repr(i.params) not in in_config\n        ]\n        print(f\"Removing {len(to_delete)} configuration(s) from the state.\")\n        for c in to_delete:\n            del state.configs[c]\n        self._save_state(state)\n\n    def mark_errors_as_todos(self):\n        \"\"\"\n        Update the persistent state to mark all configurations with\n        status \"failed\" as \"todo\". They will be retried when the\n        `resume` method is called.\n        \"\"\"\n        state = self._load_state()\n        assert state is not None\n        for _, info in state.configs.items():\n            if info.status == \"failed\":\n                info.status = \"todo\"\n        self._save_state(state)\n\n    def resume(self, max_workers: int = 1, log_progress: bool = True):\n        \"\"\"\n        Resume the experiment, running all configurations with state\n        \"todo\". Every configuration run results in marking the\n        configuration's state with either \"failed\" (in case an uncaught\n        exception was raised) or \"done\".\n\n        The whole process can be interrupted using Ctrl-C, in which case\n        the persistent experiment state is stored on disk, a message is\n        printed saying so, and Ctrl-C can be hit again until all workers\n        are successfully terminated.\n\n        A summary file is produced at the end of the experiment using\n        the `summary_file` method if all configurations were run\n        successfully.\n\n        Attributes:\n            max_workers: Number of parallel process workers to use.\n            log_progress: Whether to show a progress bar in the console.\n        \"\"\"\n        state = self._load_state()\n        assert state is not None\n        with ProcessPoolExecutor(max_workers=max_workers) as executor:\n            futures = [\n                executor.submit(\n                    _run_config,\n                    context=self.context,\n                    experiment=self.experiment,\n                    config_name=name,\n                    config_dir=self._config_dir(name),\n                    config=info.params,\n                    cache_requests=self.cache_requests,\n                    export_raw_trace=self.export_raw_trace,\n                    export_log=self.export_log,\n                    export_browsable_trace=self.export_browsable_trace,\n                    cache_format=self.cache_format,\n                )\n                for name, info in state.configs.items()\n                if info.status == \"todo\"\n            ]\n            if log_progress:\n                _print_progress(state)\n            try:\n                for future in as_completed(futures):\n                    name, success = future.result()\n                    state.configs[name].status = (\n                        \"done\" if success else \"failed\"\n                    )\n                    if log_progress:\n                        _print_progress(state)\n                self._save_state(state)\n                all_successes = all(\n                    info.status == \"done\" for info in state.configs.values()\n                )\n                if all_successes:\n                    print(\n                        \"\\nExperiment successful.\\nProducing summary file...\"\n                    )\n                    self.save_summary()\n                else:\n                    print(\"\\nWarning: some configurations failed.\")\n            except KeyboardInterrupt:\n                print(\"\\nExperiment interrupted. Saving state...\")\n                self._save_state(state)\n                print(\"State saved.\")\n\n    def replay_config_by_name(self, config_name: str) -&gt; None:\n        \"\"\"\n        Replay a configuration with a given name, reusing the cache if\n        it exists.\n\n        This way, one can debug the execution of an experiment after the\n        fact, without any LLMs being called.\n        \"\"\"\n        state = self._load_state()\n        assert state is not None\n        assert config_name is not None\n        info = state.configs[config_name]\n        assert info.status == \"done\"\n        cmdargs = self.experiment(info.params)\n        cmdargs.cache_dir = config_name + \"/\" + CACHE_DIR\n        cmdargs.cache_mode = \"replay\"\n        cmdargs.cache_format = self.cache_format\n        run_command(\n            command=cmd.run_strategy,\n            args=cmdargs,\n            ctx=self.context,\n            dump_statuses=None,\n            dump_result=None,\n            dump_log=None,\n        )\n\n    def replay_config(self, config: Config) -&gt; None:\n        \"\"\"\n        Replay a configuration. See `replay_config_by_name` for details.\n        \"\"\"\n        config_name = self._existing_config_name(config)\n        assert config_name is not None\n        self.replay_config_by_name(config_name)\n\n    def replay_all_configs(self):\n        \"\"\"\n        Replay all configurations, replicating the experiment.\n        \"\"\"\n        state = self._load_state()\n        assert state is not None\n        for config_name in state.configs:\n            print(f\"Replaying configuration: {config_name}...\")\n            self.replay_config_by_name(config_name)\n\n    def save_summary(self, ignore_missing: bool = False):\n        \"\"\"\n        Save a summary of the results in a CSV file.\n\n        Arguments:\n            ignore_missing: If `True`, configurations whose status is\n                \"failed\" or \"todo\" are ignored. Otherwise, an error is\n                raised.\n        \"\"\"\n\n        data = _results_summary(self.output_dir, ignore_missing)\n        frame = pd.DataFrame(data)\n        summary_file = self.output_dir / RESULTS_SUMMARY\n        frame.to_csv(summary_file, index=False)  # type: ignore\n\n    def load_summary(self):\n        \"\"\"\n        Load the summary file into a DataFrame.\n\n        The summary file should have been created before using the\n        `save_summary` method.\n        \"\"\"\n\n        summary_file = self.output_dir / RESULTS_SUMMARY\n        data = pd.DataFrame, pd.read_csv(summary_file)  # type: ignore\n        return data\n\n    def get_status(self) -&gt; dict[str, int]:\n        \"\"\"\n        Get the status of the experiment configurations.\n\n        Returns:\n            A dictionary with keys 'todo', 'done', 'failed' and their\n            counts (i.e., number of configurations with this status).\n        \"\"\"\n        state = self._load_state()\n        assert state is not None\n        statuses = state.configs.values()\n        num_todo = sum(1 for c in statuses if c.status == \"todo\")\n        num_done = sum(1 for c in statuses if c.status == \"done\")\n        num_failed = sum(1 for c in statuses if c.status == \"failed\")\n        return {\"todo\": num_todo, \"done\": num_done, \"failed\": num_failed}\n\n    def run_cli(self):\n        \"\"\"\n        Run a CLI application that allows controlling the experiment\n        from the shell. See `ExperimentCLI` for details.\n        \"\"\"\n        fire.Fire(ExperimentCLI(self))  # type: ignore\n\n    def _config_dir(self, config_name: str) -&gt; Path:\n        return self.output_dir / config_name\n\n    def _add_configs_if_needed(self, configs: Sequence[Config]) -&gt; None:\n        state = self._load_state()\n        assert state is not None\n        rev = state.inverse_mapping()\n        num_added = 0\n        for c in configs:\n            existing_name = rev(c)\n            if existing_name is not None:\n                continue\n            pass\n            num_added += 1\n            id = uuid.uuid4()\n            if self.config_naming is not None:\n                name = self.config_naming(c, id)\n            else:\n                name = str(id)\n            state.configs[name] = ConfigInfo(c, status=\"todo\")\n        if num_added &gt; 0:\n            print(f\"Adding {num_added} new configuration(s).\")\n        self._save_state(state)\n\n    def _dir_exists(self) -&gt; bool:\n        return self.output_dir.exists() and self.output_dir.is_dir()\n\n    def _state_type(self) -&gt; type[ExperimentState[Config]]:\n        assert not isinstance(self.config_type, NoTypeInfo), (\n            \"Please set `Experiment.config_type`.\"\n        )\n        return ExperimentState[self.config_type]\n\n    def _load_state(self) -&gt; ExperimentState[Config] | None:\n        with open(self.output_dir / EXPERIMENT_STATE_FILE, \"r\") as f:\n            parsed = yaml.safe_load(f)\n            return pydantic_load(self._state_type(), parsed)\n\n    def _save_state(self, state: ExperimentState[Config]) -&gt; None:\n        with open(self.output_dir / EXPERIMENT_STATE_FILE, \"w\") as f:\n            to_save = pydantic_dump(self._state_type(), state)\n            yaml.safe_dump(to_save, f, sort_keys=False)\n\n    def _existing_config_name(self, config: Config) -&gt; str | None:\n        state = self._load_state()\n        assert state is not None\n        for name, info in state.configs.items():\n            if info.params == config:\n                return name\n        return None\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.load","title":"load","text":"<pre><code>load() -&gt; Self\n</code></pre> <p>Load the experiment.</p> <p>If no persistent state exists on disk, it is created (with all configurations marked with \"todo\" status). If some experiment state exists on disk, it is loaded. If more configurations are specified in <code>self.configs</code> than are specified on disk, the missing configurations are added to the persistent state and marked with \"todo\". If the persistent state contains configurations that are not specified in <code>self.configs</code>, a warning is shown. Use the <code>clean_index</code> method to remove these configurations from the persistent state.</p> <p>Return <code>self</code>, so as to allow chaining.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def load(self) -&gt; Self:\n    \"\"\"\n    Load the experiment.\n\n    If no persistent state exists on disk, it is created (with all\n    configurations marked with \"todo\" status). If some experiment\n    state exists on disk, it is loaded. If more configurations are\n    specified in `self.configs` than are specified on disk, the\n    missing configurations are added to the persistent state and\n    marked with \"todo\". If the persistent state contains\n    configurations that are not specified in `self.configs`, a\n    warning is shown. Use the `clean_index` method to remove these\n    configurations from the persistent state.\n\n    Return `self`, so as to allow chaining.\n    \"\"\"\n    if not self._dir_exists():\n        # If we create the experiment for the first time\n        print(f\"Creating experiment directory: {self.output_dir}.\")\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        state = ExperimentState[Config](self.name, self.description, {})\n        self._save_state(state)\n    if self.configs is not None:\n        self._add_configs_if_needed(self.configs)\n        # Print a warning if the state on disk features additional configs.\n        state = self._load_state()\n        assert state is not None\n        assert len(self.configs) &lt;= len(state.configs)\n        if len(self.configs) &lt; len(state.configs):\n            print(\n                f\"Warning: {len(state.configs) - len(self.configs)} \"\n                \"additional configuration(s) found in the state.\"\n            )\n    return self\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.is_done","title":"is_done","text":"<pre><code>is_done() -&gt; bool\n</code></pre> <p>Check if the experiment is done, i.e., all configurations are marked as \"done\".</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def is_done(self) -&gt; bool:\n    \"\"\"\n    Check if the experiment is done, i.e., all configurations are\n    marked as \"done\".\n    \"\"\"\n    state = self._load_state()\n    assert state is not None\n    return all(info.status == \"done\" for info in state.configs.values())\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.clean_index","title":"clean_index","text":"<pre><code>clean_index() -&gt; None\n</code></pre> <p>Remove from the persistent state file all configurations that are not mentioned in <code>self.configs</code>.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def clean_index(self) -&gt; None:\n    \"\"\"\n    Remove from the persistent state file all configurations that\n    are not mentioned in `self.configs`.\n    \"\"\"\n    state = self._load_state()\n    assert state is not None\n    assert self.configs is not None\n    in_config = set(_config_unique_repr(c) for c in self.configs)\n    to_delete = [\n        c\n        for c, i in state.configs.items()\n        if _config_unique_repr(i.params) not in in_config\n    ]\n    print(f\"Removing {len(to_delete)} configuration(s) from the state.\")\n    for c in to_delete:\n        del state.configs[c]\n    self._save_state(state)\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.mark_errors_as_todos","title":"mark_errors_as_todos","text":"<pre><code>mark_errors_as_todos()\n</code></pre> <p>Update the persistent state to mark all configurations with status \"failed\" as \"todo\". They will be retried when the <code>resume</code> method is called.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def mark_errors_as_todos(self):\n    \"\"\"\n    Update the persistent state to mark all configurations with\n    status \"failed\" as \"todo\". They will be retried when the\n    `resume` method is called.\n    \"\"\"\n    state = self._load_state()\n    assert state is not None\n    for _, info in state.configs.items():\n        if info.status == \"failed\":\n            info.status = \"todo\"\n    self._save_state(state)\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.resume","title":"resume","text":"<pre><code>resume(max_workers: int = 1, log_progress: bool = True)\n</code></pre> <p>Resume the experiment, running all configurations with state \"todo\". Every configuration run results in marking the configuration's state with either \"failed\" (in case an uncaught exception was raised) or \"done\".</p> <p>The whole process can be interrupted using Ctrl-C, in which case the persistent experiment state is stored on disk, a message is printed saying so, and Ctrl-C can be hit again until all workers are successfully terminated.</p> <p>A summary file is produced at the end of the experiment using the <code>summary_file</code> method if all configurations were run successfully.</p> <p>Attributes:</p> Name Type Description <code>max_workers</code> <p>Number of parallel process workers to use.</p> <code>log_progress</code> <p>Whether to show a progress bar in the console.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def resume(self, max_workers: int = 1, log_progress: bool = True):\n    \"\"\"\n    Resume the experiment, running all configurations with state\n    \"todo\". Every configuration run results in marking the\n    configuration's state with either \"failed\" (in case an uncaught\n    exception was raised) or \"done\".\n\n    The whole process can be interrupted using Ctrl-C, in which case\n    the persistent experiment state is stored on disk, a message is\n    printed saying so, and Ctrl-C can be hit again until all workers\n    are successfully terminated.\n\n    A summary file is produced at the end of the experiment using\n    the `summary_file` method if all configurations were run\n    successfully.\n\n    Attributes:\n        max_workers: Number of parallel process workers to use.\n        log_progress: Whether to show a progress bar in the console.\n    \"\"\"\n    state = self._load_state()\n    assert state is not None\n    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n        futures = [\n            executor.submit(\n                _run_config,\n                context=self.context,\n                experiment=self.experiment,\n                config_name=name,\n                config_dir=self._config_dir(name),\n                config=info.params,\n                cache_requests=self.cache_requests,\n                export_raw_trace=self.export_raw_trace,\n                export_log=self.export_log,\n                export_browsable_trace=self.export_browsable_trace,\n                cache_format=self.cache_format,\n            )\n            for name, info in state.configs.items()\n            if info.status == \"todo\"\n        ]\n        if log_progress:\n            _print_progress(state)\n        try:\n            for future in as_completed(futures):\n                name, success = future.result()\n                state.configs[name].status = (\n                    \"done\" if success else \"failed\"\n                )\n                if log_progress:\n                    _print_progress(state)\n            self._save_state(state)\n            all_successes = all(\n                info.status == \"done\" for info in state.configs.values()\n            )\n            if all_successes:\n                print(\n                    \"\\nExperiment successful.\\nProducing summary file...\"\n                )\n                self.save_summary()\n            else:\n                print(\"\\nWarning: some configurations failed.\")\n        except KeyboardInterrupt:\n            print(\"\\nExperiment interrupted. Saving state...\")\n            self._save_state(state)\n            print(\"State saved.\")\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.replay_config_by_name","title":"replay_config_by_name","text":"<pre><code>replay_config_by_name(config_name: str) -&gt; None\n</code></pre> <p>Replay a configuration with a given name, reusing the cache if it exists.</p> <p>This way, one can debug the execution of an experiment after the fact, without any LLMs being called.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def replay_config_by_name(self, config_name: str) -&gt; None:\n    \"\"\"\n    Replay a configuration with a given name, reusing the cache if\n    it exists.\n\n    This way, one can debug the execution of an experiment after the\n    fact, without any LLMs being called.\n    \"\"\"\n    state = self._load_state()\n    assert state is not None\n    assert config_name is not None\n    info = state.configs[config_name]\n    assert info.status == \"done\"\n    cmdargs = self.experiment(info.params)\n    cmdargs.cache_dir = config_name + \"/\" + CACHE_DIR\n    cmdargs.cache_mode = \"replay\"\n    cmdargs.cache_format = self.cache_format\n    run_command(\n        command=cmd.run_strategy,\n        args=cmdargs,\n        ctx=self.context,\n        dump_statuses=None,\n        dump_result=None,\n        dump_log=None,\n    )\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.replay_config","title":"replay_config","text":"<pre><code>replay_config(config: Config) -&gt; None\n</code></pre> <p>Replay a configuration. See <code>replay_config_by_name</code> for details.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def replay_config(self, config: Config) -&gt; None:\n    \"\"\"\n    Replay a configuration. See `replay_config_by_name` for details.\n    \"\"\"\n    config_name = self._existing_config_name(config)\n    assert config_name is not None\n    self.replay_config_by_name(config_name)\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.replay_all_configs","title":"replay_all_configs","text":"<pre><code>replay_all_configs()\n</code></pre> <p>Replay all configurations, replicating the experiment.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def replay_all_configs(self):\n    \"\"\"\n    Replay all configurations, replicating the experiment.\n    \"\"\"\n    state = self._load_state()\n    assert state is not None\n    for config_name in state.configs:\n        print(f\"Replaying configuration: {config_name}...\")\n        self.replay_config_by_name(config_name)\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.save_summary","title":"save_summary","text":"<pre><code>save_summary(ignore_missing: bool = False)\n</code></pre> <p>Save a summary of the results in a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>ignore_missing</code> <code>bool</code> <p>If <code>True</code>, configurations whose status is \"failed\" or \"todo\" are ignored. Otherwise, an error is raised.</p> <code>False</code> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def save_summary(self, ignore_missing: bool = False):\n    \"\"\"\n    Save a summary of the results in a CSV file.\n\n    Arguments:\n        ignore_missing: If `True`, configurations whose status is\n            \"failed\" or \"todo\" are ignored. Otherwise, an error is\n            raised.\n    \"\"\"\n\n    data = _results_summary(self.output_dir, ignore_missing)\n    frame = pd.DataFrame(data)\n    summary_file = self.output_dir / RESULTS_SUMMARY\n    frame.to_csv(summary_file, index=False)  # type: ignore\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.load_summary","title":"load_summary","text":"<pre><code>load_summary()\n</code></pre> <p>Load the summary file into a DataFrame.</p> <p>The summary file should have been created before using the <code>save_summary</code> method.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def load_summary(self):\n    \"\"\"\n    Load the summary file into a DataFrame.\n\n    The summary file should have been created before using the\n    `save_summary` method.\n    \"\"\"\n\n    summary_file = self.output_dir / RESULTS_SUMMARY\n    data = pd.DataFrame, pd.read_csv(summary_file)  # type: ignore\n    return data\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.get_status","title":"get_status","text":"<pre><code>get_status() -&gt; dict[str, int]\n</code></pre> <p>Get the status of the experiment configurations.</p> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>A dictionary with keys 'todo', 'done', 'failed' and their</p> <code>dict[str, int]</code> <p>counts (i.e., number of configurations with this status).</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def get_status(self) -&gt; dict[str, int]:\n    \"\"\"\n    Get the status of the experiment configurations.\n\n    Returns:\n        A dictionary with keys 'todo', 'done', 'failed' and their\n        counts (i.e., number of configurations with this status).\n    \"\"\"\n    state = self._load_state()\n    assert state is not None\n    statuses = state.configs.values()\n    num_todo = sum(1 for c in statuses if c.status == \"todo\")\n    num_done = sum(1 for c in statuses if c.status == \"done\")\n    num_failed = sum(1 for c in statuses if c.status == \"failed\")\n    return {\"todo\": num_todo, \"done\": num_done, \"failed\": num_failed}\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.Experiment.run_cli","title":"run_cli","text":"<pre><code>run_cli()\n</code></pre> <p>Run a CLI application that allows controlling the experiment from the shell. See <code>ExperimentCLI</code> for details.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def run_cli(self):\n    \"\"\"\n    Run a CLI application that allows controlling the experiment\n    from the shell. See `ExperimentCLI` for details.\n    \"\"\"\n    fire.Fire(ExperimentCLI(self))  # type: ignore\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.ExperimentFun","title":"ExperimentFun","text":"<p>               Bases: <code>Protocol</code></p> <p>A function defining an experiment, which maps a configuration (i.e., a set of parameters) to a set of arguments for the <code>run_strategy</code> command. Note that caching-related arguments do not need to be set since they are overriden by the <code>Experiment</code> class.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>class ExperimentFun[Config](Protocol):\n    \"\"\"\n    A function defining an experiment, which maps a configuration (i.e.,\n    a set of parameters) to a set of arguments for the `run_strategy`\n    command. Note that caching-related arguments do not need to be set\n    since they are overriden by the `Experiment` class.\n    \"\"\"\n\n    def __call__(self, config: Config, /) -&gt; cmd.RunStrategyArgs: ...\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.ExperimentState","title":"ExperimentState  <code>dataclass</code>","text":"<p>Persistent state of an experiment, stored on disk as a YAML file.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>@dataclass\nclass ExperimentState[Config]:\n    \"\"\"\n    Persistent state of an experiment, stored on disk as a YAML file.\n    \"\"\"\n\n    name: str | None\n    description: str | None\n    configs: dict[str, ConfigInfo[Config]]\n\n    def inverse_mapping(self) -&gt; Callable[[Config], str | None]:\n        \"\"\"\n        Compute an inverse function mapping configurations to their\n        unique names (or None if not in the state).\n        \"\"\"\n        tab: dict[str, str] = {}\n        for name, info in self.configs.items():\n            tab[_config_unique_repr(info.params)] = name\n\n        def reverse(config: Config) -&gt; str | None:\n            return tab.get(_config_unique_repr(config), None)\n\n        return reverse\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.ExperimentState.inverse_mapping","title":"inverse_mapping","text":"<pre><code>inverse_mapping() -&gt; Callable[[Config], str | None]\n</code></pre> <p>Compute an inverse function mapping configurations to their unique names (or None if not in the state).</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def inverse_mapping(self) -&gt; Callable[[Config], str | None]:\n    \"\"\"\n    Compute an inverse function mapping configurations to their\n    unique names (or None if not in the state).\n    \"\"\"\n    tab: dict[str, str] = {}\n    for name, info in self.configs.items():\n        tab[_config_unique_repr(info.params)] = name\n\n    def reverse(config: Config) -&gt; str | None:\n        return tab.get(_config_unique_repr(config), None)\n\n    return reverse\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.ConfigInfo","title":"ConfigInfo  <code>dataclass</code>","text":"<p>Information stored in the persistent configuration state for each configuration.</p> <p>Attributes:</p> Name Type Description <code>params</code> <code>Config</code> <p>The configuration.</p> <code>status</code> <code>Literal['todo', 'done', 'failed']</code> <p>Status of the configuration.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>@dataclass\nclass ConfigInfo[Config]:\n    \"\"\"\n    Information stored in the persistent configuration state for each\n    configuration.\n\n    Attributes:\n        params: The configuration.\n        status: Status of the configuration.\n    \"\"\"\n\n    params: Config\n    status: Literal[\"todo\", \"done\", \"failed\"]\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.ExperimentCLI","title":"ExperimentCLI","text":"<p>A CLI application for controlling an experiment from the shell.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>class ExperimentCLI:\n    \"\"\"\n    A CLI application for controlling an experiment from the shell.\n    \"\"\"\n\n    def __init__(self, experiment: Experiment[Any]):\n        self.experiment = experiment\n\n    def __call__(self):\n        \"\"\"\n        If no argument is provided, the `run` method is called.\n        \"\"\"\n        self.run()\n\n    def run(\n        self,\n        *,\n        max_workers: int = 1,\n        retry_errors: bool = False,\n        cache: bool = True,\n        verbose_output: bool = False,\n    ):\n        \"\"\"\n        Start or resume the experiment.\n\n        Attributes:\n            max_workers: Number of parallel process workers to use.\n            retry_errors: Mark failed configurations to be retried.\n            cache: Enable caching of LLM requests and potentially\n                non-replicable computations.\n            verbose_output: Export raw traces and browsable traces in\n                result files, enabling inspection by the Delphyne VSCode\n                extension's tree view.\n        \"\"\"\n        self.experiment.cache_requests = cache\n        self.experiment.export_raw_trace = verbose_output\n        self.experiment.export_browsable_trace = verbose_output\n        self.experiment.export_log = True\n\n        self.experiment.load()\n        if retry_errors:\n            self.experiment.mark_errors_as_todos()\n        self.experiment.resume(max_workers=max_workers)\n\n    def status(self):\n        \"\"\"\n        Print the status of the experiment.\n        \"\"\"\n        status_counts = self.experiment.get_status()\n        print(\n            f\"Experiment '{self.experiment.name}':\\n\"\n            f\"  - {status_counts['todo']} configurations to do\\n\"\n            f\"  - {status_counts['done']} configurations done\\n\"\n            f\"  - {status_counts['failed']} configurations failed\"\n        )\n\n    def replay(self, config: str | None = None):\n        \"\"\"\n        Replay one or all configurations.\n\n        Arguments:\n            config: The name of the configuration to replay. If not\n                provided, all configurations are replayed.\n        \"\"\"\n        self.experiment.load()\n        if config is None:\n            self.experiment.replay_all_configs()\n        else:\n            self.experiment.replay_config_by_name(config)\n\n    def clean_index(self):\n        \"\"\"\n        Clean unregistered configurations from the persistent state\n        file.\n        \"\"\"\n        self.experiment.load().clean_index()\n\n    def force_summary(self):\n        \"\"\"\n        Force the generation of a summary file, even if not all\n        configurations were successfully run.\n        \"\"\"\n        self.experiment.load().save_summary(ignore_missing=True)\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.ExperimentCLI.__call__","title":"__call__","text":"<pre><code>__call__()\n</code></pre> <p>If no argument is provided, the <code>run</code> method is called.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def __call__(self):\n    \"\"\"\n    If no argument is provided, the `run` method is called.\n    \"\"\"\n    self.run()\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.ExperimentCLI.run","title":"run","text":"<pre><code>run(\n    *,\n    max_workers: int = 1,\n    retry_errors: bool = False,\n    cache: bool = True,\n    verbose_output: bool = False,\n)\n</code></pre> <p>Start or resume the experiment.</p> <p>Attributes:</p> Name Type Description <code>max_workers</code> <p>Number of parallel process workers to use.</p> <code>retry_errors</code> <p>Mark failed configurations to be retried.</p> <code>cache</code> <p>Enable caching of LLM requests and potentially non-replicable computations.</p> <code>verbose_output</code> <p>Export raw traces and browsable traces in result files, enabling inspection by the Delphyne VSCode extension's tree view.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def run(\n    self,\n    *,\n    max_workers: int = 1,\n    retry_errors: bool = False,\n    cache: bool = True,\n    verbose_output: bool = False,\n):\n    \"\"\"\n    Start or resume the experiment.\n\n    Attributes:\n        max_workers: Number of parallel process workers to use.\n        retry_errors: Mark failed configurations to be retried.\n        cache: Enable caching of LLM requests and potentially\n            non-replicable computations.\n        verbose_output: Export raw traces and browsable traces in\n            result files, enabling inspection by the Delphyne VSCode\n            extension's tree view.\n    \"\"\"\n    self.experiment.cache_requests = cache\n    self.experiment.export_raw_trace = verbose_output\n    self.experiment.export_browsable_trace = verbose_output\n    self.experiment.export_log = True\n\n    self.experiment.load()\n    if retry_errors:\n        self.experiment.mark_errors_as_todos()\n    self.experiment.resume(max_workers=max_workers)\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.ExperimentCLI.status","title":"status","text":"<pre><code>status()\n</code></pre> <p>Print the status of the experiment.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def status(self):\n    \"\"\"\n    Print the status of the experiment.\n    \"\"\"\n    status_counts = self.experiment.get_status()\n    print(\n        f\"Experiment '{self.experiment.name}':\\n\"\n        f\"  - {status_counts['todo']} configurations to do\\n\"\n        f\"  - {status_counts['done']} configurations done\\n\"\n        f\"  - {status_counts['failed']} configurations failed\"\n    )\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.ExperimentCLI.replay","title":"replay","text":"<pre><code>replay(config: str | None = None)\n</code></pre> <p>Replay one or all configurations.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>str | None</code> <p>The name of the configuration to replay. If not provided, all configurations are replayed.</p> <code>None</code> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def replay(self, config: str | None = None):\n    \"\"\"\n    Replay one or all configurations.\n\n    Arguments:\n        config: The name of the configuration to replay. If not\n            provided, all configurations are replayed.\n    \"\"\"\n    self.experiment.load()\n    if config is None:\n        self.experiment.replay_all_configs()\n    else:\n        self.experiment.replay_config_by_name(config)\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.ExperimentCLI.clean_index","title":"clean_index","text":"<pre><code>clean_index()\n</code></pre> <p>Clean unregistered configurations from the persistent state file.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def clean_index(self):\n    \"\"\"\n    Clean unregistered configurations from the persistent state\n    file.\n    \"\"\"\n    self.experiment.load().clean_index()\n</code></pre>"},{"location":"reference/stdlib/experiments/#delphyne.stdlib.experiments.experiment_launcher.ExperimentCLI.force_summary","title":"force_summary","text":"<pre><code>force_summary()\n</code></pre> <p>Force the generation of a summary file, even if not all configurations were successfully run.</p> Source code in <code>src/delphyne/stdlib/experiments/experiment_launcher.py</code> <pre><code>def force_summary(self):\n    \"\"\"\n    Force the generation of a summary file, even if not all\n    configurations were successfully run.\n    \"\"\"\n    self.experiment.load().save_summary(ignore_missing=True)\n</code></pre>"},{"location":"reference/stdlib/queries/","title":"Queries and Prompting Policies","text":""},{"location":"reference/stdlib/queries/#queries","title":"Queries","text":""},{"location":"reference/stdlib/queries/#delphyne.Query","title":"Query","text":"<p>               Bases: <code>AbstractQuery[T]</code></p> <p>Base class for queries.</p> <p>This class adds standard convenience features on top of <code>AbstractQuery</code>, using reflection to allow queries to be defined concisely. Here is a simple example of a query type definition:</p> <pre><code>@dataclass class MakeSum(Query[list[int]]):\n    '''Given a list of allowed numbers and a target number, you\n    must find a sub-list whose elements sum up to the target.\n    Just answer with a list of numbers as a JSON object and\n    nothing else.'''\n\n    allowed: list[int] target: int\n</code></pre> <p>In general, a query type is a dataclass that inherits <code>Query[T]</code>, where <code>T</code> is the query's answer type. In the example above, no parser is specified and so oracles are requested to provide structured answers as JSON objects, which are automatically parsed into the answer type (<code>list[int]</code>) using pydantic. Assuming that no Jinja prompt file is provided, the docstring is used as a system prompt and instance prompts are generated by simply serializing <code>MakeSum</code> instances into YAML.</p> <p>All attributes of a query must be serializable by pydantic. They can be builtin types (int, list, dict...), custom dataclasses...</p>"},{"location":"reference/stdlib/queries/#delphyne.Query--customizing-prompts","title":"Customizing Prompts","text":"<p>System and instance prompts can be specified via Jinja templates. The templates manager (<code>TemplatesManager</code>) looks for templates named \"..jinja\". Templates can also be provided by defining the <code>__system_prompt__</code> and/or <code>__instance_prompt__</code> class attributes. If none of these are provided, the query's docstring is used as a system prompt and <code>DEFAULT_INSTANCE_PROMPT</code> is used as an instance prompt template. All attributes from <code>QueryTemplateArgs</code> are made available to templates, with possibly extra ones."},{"location":"reference/stdlib/queries/#delphyne.Query--answer-modes-and-configurations","title":"Answer Modes and Configurations","text":"<p>A query can define several answer modes (<code>AnswerMode</code>), each of which can be associated with a different parser and set of settings. By default, the only answer mode is <code>None</code>. More answer modes can be defined by setting class variable <code>__modes__</code>.</p> <p>The <code>parser_for</code> method maps modes to parser specifications. Its default implementation first checks whether the <code>parser</code> method is overriden, in which case it is used. Otherwise, the <code>__parser__</code> attribute is checked. If none of these conditions hold, <code>structured</code> is used as a default parser.</p>"},{"location":"reference/stdlib/queries/#delphyne.Query--allowing-multi-message-exchanges-and-tool-calls","title":"Allowing Multi-Message Exchanges and Tool Calls","text":"<p>A common pattern for interacting with LLMs is to have multi-message exchanges where the full conversation history is resent repeatedly. LLMs are also often allowed to request tool call. This interaction pattern is implemented in the <code>interact</code> standard strategy. It is enabled by several features on the <code>Query</code> side.</p>"},{"location":"reference/stdlib/queries/#delphyne.Query--answer-prefixes","title":"Answer Prefixes","text":"<p>If a query type has a prefix attribute with type <code>AnswerPrefix</code>, this attribute can be used to provide a chat history, to be added to the query's prompt.</p>"},{"location":"reference/stdlib/queries/#delphyne.Query--the-response-type","title":"The <code>Response</code> Type","text":"<p>If the query answer type is <code>Response</code>, the query does not only return a parsed answer, but also the LLM raw answer (which can be appended to a chat history), and possibly a sequence of tool calls.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>class Query[T](dp.AbstractQuery[T]):\n    \"\"\"\n    Base class for queries.\n\n    This class adds standard convenience features on top of\n    `AbstractQuery`, using reflection to allow queries to be defined\n    concisely. Here is a simple example of a query type definition:\n\n    ```python\n    @dataclass class MakeSum(Query[list[int]]):\n        '''Given a list of allowed numbers and a target number, you\n        must find a sub-list whose elements sum up to the target.\n        Just answer with a list of numbers as a JSON object and\n        nothing else.'''\n\n        allowed: list[int] target: int\n    ```\n\n    In general, a query type is a dataclass that inherits `Query[T]`,\n    where `T` is the query's answer type. In the example above, no\n    parser is specified and so oracles are requested to provide\n    structured answers as JSON objects, which are automatically parsed\n    into the answer type (`list[int]`) using pydantic. Assuming that no\n    Jinja prompt file is provided, the docstring is used as a system\n    prompt and instance prompts are generated by simply serializing\n    `MakeSum` instances into YAML.\n\n    All attributes of a query must be serializable by pydantic. They can\n    be builtin types (int, list, dict...), custom dataclasses...\n\n    ## Customizing Prompts\n\n    System and instance prompts can be specified via Jinja templates.\n    The templates manager (`TemplatesManager`) looks for templates named\n    \"&lt;QueryName&gt;.&lt;instance|system&gt;.jinja\". Templates can also be\n    provided by defining the `__system_prompt__` and/or\n    `__instance_prompt__` class attributes. If none of these are\n    provided, the query's docstring is used as a system prompt and\n    `DEFAULT_INSTANCE_PROMPT` is used as an instance prompt template.\n    All attributes from `QueryTemplateArgs` are made available to\n    templates, with possibly extra ones.\n\n    ## Answer Modes and Configurations\n\n    A query can define several answer modes (`AnswerMode`), each of\n    which can be associated with a different parser and set of settings.\n    By default, the only answer mode is `None`. More answer modes can be\n    defined by setting class variable `__modes__`.\n\n    The `parser_for` method maps modes to parser specifications. Its\n    default implementation first checks whether the `parser` method is\n    overriden, in which case it is used. Otherwise, the `__parser__`\n    attribute is checked. If none of these conditions hold, `structured`\n    is used as a default parser.\n\n    ## Allowing Multi-Message Exchanges and Tool Calls\n\n    A common pattern for interacting with LLMs is to have multi-message\n    exchanges where the full conversation history is resent repeatedly.\n    LLMs are also often allowed to request tool call. This interaction\n    pattern is implemented in the `interact` standard strategy. It is\n    enabled by several features on the `Query` side.\n\n    ### Answer Prefixes\n\n    If a query type has a prefix attribute with type `AnswerPrefix`,\n    this attribute can be used to provide a chat history, to be added to\n    the query's prompt.\n\n    ### The `Response` Type\n\n    If the query answer type is `Response`, the query does not only\n    return a parsed answer, but also the LLM raw answer (which can be\n    appended to a chat history), and possibly a sequence of tool calls.\n    \"\"\"\n\n    __modes__: ClassVar[Sequence[dp.AnswerMode] | None] = None\n    __parser__: ClassVar[Parser[Any] | GenericParser | ParserDict | None] = (\n        None\n    )\n\n    ### Parsing Answers\n\n    def parser(self) -&gt; Parser[T] | GenericParser:\n        \"\"\"\n        Method to override to provide a parser specification common to\n        all modes. Alternatively, the `__parser__` class attribute can\n        be set. The first method allows more flexibility since parser\n        specifications can then depend on query attributes.\n        \"\"\"\n        assert False, (\n            \"Please provide `__parser__`, `parser` or \"\n            + f\"`parser_for` for query type {type(self)}\"\n        )\n\n    def parser_for(self, mode: dp.AnswerMode) -&gt; Parser[T] | GenericParser:\n        \"\"\"\n        Obtain a parser speficiation for a given answer mode.\n\n        This method can be overriden. By default, it does the following:\n\n        1. If the `parser` method is overriden, it uses it.\n        2. If `__parser__` is set as a parser, it is used.\n        2. If `__parser__` is set as a dictionary, the mode is used as a\n           key to obtain a parser.\n        3. Otherwise, `structured` is used as a default parser.\n        \"\"\"\n        if dpi.is_method_overridden(Query, type(self), \"parser\"):\n            assert self.__parser__ is None, (\n                f\"Both `__parser__` and `parser` are provided for {type(self)}.\"\n            )\n            return self.parser()\n        elif self.__parser__ is None:\n            return structured  # default parser\n        else:\n            assert not dpi.is_method_overridden(\n                Query, type(self), \"parser_for\"\n            ), (\n                \"Both `__parser__` and `parser_for` are \"\n                + f\"provided for {type(self)}.\"\n            )\n            parser_attr = self.__parser__\n            if isinstance(parser_attr, dict):\n                parser = parser_attr[mode]\n            else:\n                parser = parser_attr\n            assert isinstance(parser, (Parser, GenericParser)), (\n                \"Expected parser type, got: \" + f\"{type(parser)}.\"\n            )\n            return cast(Any, parser)\n\n    def _instantiated_parser_for(self, mode: dp.AnswerMode) -&gt; Parser[T]:\n        parser = self.parser_for(mode)\n        if isinstance(parser, GenericParser):\n            return parser.for_type(self._answer_type())\n        else:\n            return parser\n\n    @override\n    def parse_answer(self, answer: dp.Answer) -&gt; T | dp.ParseError:\n        assert answer.mode in self.query_modes(), (\n            f\"Unknown mode: {answer.mode}\"\n        )\n        try:\n            parser = self._instantiated_parser_for(answer.mode)\n            return parser.parse(answer)\n        except dp.ParseError as e:\n            return e\n\n    @override\n    def query_settings(self, mode: dp.AnswerMode) -&gt; dp.QuerySettings:\n        parser = self._instantiated_parser_for(mode)\n        return parser.settings\n\n    ### Query Prefixes\n\n    @classmethod\n    def _has_special_prefix_attr(cls):\n        annots = typing.get_type_hints(cls)\n        return \"prefix\" in annots and annots[\"prefix\"] is ct.AnswerPrefix\n\n    @override\n    def query_prefix(self) -&gt; ct.AnswerPrefix | None:\n        \"\"\"\n        Return the value of the `prefix` attribute if it has type\n        annotation `AnswerPrefix` or return `None`.\n        \"\"\"\n        if self._has_special_prefix_attr():\n            return getattr(self, \"prefix\")\n        return None\n\n    ### Producing Prompts\n\n    @override\n    def generate_prompt(\n        self,\n        *,\n        kind: Literal[\"system\", \"instance\"] | str,\n        mode: dp.AnswerMode,\n        params: dict[str, object],\n        extra_args: dict[str, object] | None = None,\n        env: dp.AbstractTemplatesManager | None = None,\n    ) -&gt; str:\n        assert env is not None, _no_prompt_manager_error()\n        args_min: QueryTemplateArgs = {\n            \"query\": self,\n            \"mode\": mode,\n            \"available_modes\": self.query_modes(),\n            \"params\": params,\n            \"format\": self._instantiated_parser_for(mode).formatting,\n        }\n        args: dict[str, object] = {**args_min}\n        if extra_args:\n            args.update(extra_args)\n        if (glob := self.globals()) is not None:\n            args[\"globals\"] = glob\n        return env.prompt(\n            query_name=self.query_name(),\n            prompt_kind=kind,\n            template_args=args,\n            default_template=self._default_prompt(kind),\n        )\n\n    @classmethod\n    def _default_prompt(\n        cls, kind: Literal[\"system\", \"instance\"] | str\n    ) -&gt; str | None:\n        attr_name = f\"__{kind}_prompt__\"\n        if hasattr(cls, attr_name):\n            res = getattr(cls, attr_name)\n            assert isinstance(res, str)\n            return textwrap.dedent(res).strip()\n        if kind == \"instance\":\n            if cls._has_special_prefix_attr():\n                return DEFAULT_INSTANCE_PROMPT_WITH_PREFIX\n            else:\n                return DEFAULT_INSTANCE_PROMPT\n        if kind == \"system\" and (doc := inspect.getdoc(cls)) is not None:\n            return doc\n        if kind == \"feedback\":\n            return DEFAULT_FEEDBACK_PROMPT\n        return None\n\n    def globals(self) -&gt; dict[str, object] | None:\n        \"\"\"\n        Return global objects accessible in prompts via the `globals`\n        attribute.\n        \"\"\"\n        return None\n\n    ### Other Simple Overrides\n\n    @override\n    def serialize_args(self) -&gt; dict[str, object]:\n        return cast(dict[str, object], ty.pydantic_dump(type(self), self))\n\n    @classmethod\n    def _answer_type(cls) -&gt; TypeAnnot[T]:\n        return dpi.first_parameter_of_base_class(cls)\n\n    @override\n    def answer_type(self) -&gt; TypeAnnot[T]:\n        return self._answer_type()\n\n    @override\n    def finite_answer_set(self) -&gt; Sequence[dp.Answer] | None:\n        # We handle the special case where the return type is a literal\n        # type that is a subtype of str.\n        ans = self.answer_type()\n        if (res := _match_string_literal_type(ans)) is not None:\n            return [dp.Answer(None, v) for v in res]\n        return None\n\n    @override\n    def query_modes(self) -&gt; Sequence[dp.AnswerMode]:\n        if self.__modes__ is not None:\n            return self.__modes__\n        return [None]\n\n    ### Generating Opaque Spaces\n\n    @overload\n    def using(self, get_policy: EllipsisType, /) -&gt; Opaque[IPDict, T]: ...\n\n    @overload\n    def using[P](\n        self,\n        get_policy: Callable[[P], pol.PromptingPolicy] | EllipsisType,\n        /,\n        inner_policy_type: type[P] | None = None,\n    ) -&gt; Opaque[P, T]: ...\n\n    def using[P](\n        self,\n        get_policy: Callable[[P], pol.PromptingPolicy] | EllipsisType,\n        /,\n        inner_policy_type: type[P] | None = None,\n    ) -&gt; Opaque[P, T]:\n        \"\"\"\n        Turn a query into an opaque space by providing a mapping from\n        the ambient inner policy to a prompting policy.\n\n        Attributes:\n            get_policy: A function that maps the ambient inner policy to\n                a prompting policy to use for answering the query.\n                Alternatively, if the ellipsis value `...` is passed, the\n                inner policy type is assumed to be `IPDict`, and\n                prompting policies are automatically selected using tags\n                (see `IPDict` documentation).\n            inner_policy_type: Ambient inner policy type. This information\n                is not used at runtime but it can be provided to help type\n                inference when necessary.\n\n        The optional `inner_policy_type` argument is ignored at runtime\n        and can be used to help type checkers infer the type of the\n        ambient inner policy.\n        \"\"\"\n        if isinstance(get_policy, EllipsisType):\n            return OpaqueSpace[P, T].from_query(\n                self, cast(Any, pol.dict_subpolicy)\n            )\n        return OpaqueSpace[P, T].from_query(self, lambda p, _: get_policy(p))\n\n    def run_toplevel(\n        self,\n        env: PolicyEnv,\n        policy: pol.PromptingPolicy,\n    ) -&gt; Stream[T]:\n        \"\"\"\n        Obtain a search stream of query answers, given a prompting\n        policy.\n        \"\"\"\n        attached = dp.spawn_standalone_query(self)\n        return policy(attached, env)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Query.parser","title":"parser","text":"<pre><code>parser() -&gt; Parser[T] | GenericParser\n</code></pre> <p>Method to override to provide a parser specification common to all modes. Alternatively, the <code>__parser__</code> class attribute can be set. The first method allows more flexibility since parser specifications can then depend on query attributes.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def parser(self) -&gt; Parser[T] | GenericParser:\n    \"\"\"\n    Method to override to provide a parser specification common to\n    all modes. Alternatively, the `__parser__` class attribute can\n    be set. The first method allows more flexibility since parser\n    specifications can then depend on query attributes.\n    \"\"\"\n    assert False, (\n        \"Please provide `__parser__`, `parser` or \"\n        + f\"`parser_for` for query type {type(self)}\"\n    )\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Query.parser_for","title":"parser_for","text":"<pre><code>parser_for(mode: AnswerMode) -&gt; Parser[T] | GenericParser\n</code></pre> <p>Obtain a parser speficiation for a given answer mode.</p> <p>This method can be overriden. By default, it does the following:</p> <ol> <li>If the <code>parser</code> method is overriden, it uses it.</li> <li>If <code>__parser__</code> is set as a parser, it is used.</li> <li>If <code>__parser__</code> is set as a dictionary, the mode is used as a    key to obtain a parser.</li> <li>Otherwise, <code>structured</code> is used as a default parser.</li> </ol> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def parser_for(self, mode: dp.AnswerMode) -&gt; Parser[T] | GenericParser:\n    \"\"\"\n    Obtain a parser speficiation for a given answer mode.\n\n    This method can be overriden. By default, it does the following:\n\n    1. If the `parser` method is overriden, it uses it.\n    2. If `__parser__` is set as a parser, it is used.\n    2. If `__parser__` is set as a dictionary, the mode is used as a\n       key to obtain a parser.\n    3. Otherwise, `structured` is used as a default parser.\n    \"\"\"\n    if dpi.is_method_overridden(Query, type(self), \"parser\"):\n        assert self.__parser__ is None, (\n            f\"Both `__parser__` and `parser` are provided for {type(self)}.\"\n        )\n        return self.parser()\n    elif self.__parser__ is None:\n        return structured  # default parser\n    else:\n        assert not dpi.is_method_overridden(\n            Query, type(self), \"parser_for\"\n        ), (\n            \"Both `__parser__` and `parser_for` are \"\n            + f\"provided for {type(self)}.\"\n        )\n        parser_attr = self.__parser__\n        if isinstance(parser_attr, dict):\n            parser = parser_attr[mode]\n        else:\n            parser = parser_attr\n        assert isinstance(parser, (Parser, GenericParser)), (\n            \"Expected parser type, got: \" + f\"{type(parser)}.\"\n        )\n        return cast(Any, parser)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Query.query_prefix","title":"query_prefix","text":"<pre><code>query_prefix() -&gt; AnswerPrefix | None\n</code></pre> <p>Return the value of the <code>prefix</code> attribute if it has type annotation <code>AnswerPrefix</code> or return <code>None</code>.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@override\ndef query_prefix(self) -&gt; ct.AnswerPrefix | None:\n    \"\"\"\n    Return the value of the `prefix` attribute if it has type\n    annotation `AnswerPrefix` or return `None`.\n    \"\"\"\n    if self._has_special_prefix_attr():\n        return getattr(self, \"prefix\")\n    return None\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Query.globals","title":"globals","text":"<pre><code>globals() -&gt; dict[str, object] | None\n</code></pre> <p>Return global objects accessible in prompts via the <code>globals</code> attribute.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def globals(self) -&gt; dict[str, object] | None:\n    \"\"\"\n    Return global objects accessible in prompts via the `globals`\n    attribute.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Query.using","title":"using","text":"<pre><code>using(get_policy: EllipsisType) -&gt; Opaque[IPDict, T]\n</code></pre><pre><code>using(\n    get_policy: Callable[[P], PromptingPolicy] | EllipsisType,\n    /,\n    inner_policy_type: type[P] | None = None,\n) -&gt; Opaque[P, T]\n</code></pre> <pre><code>using(\n    get_policy: Callable[[P], PromptingPolicy] | EllipsisType,\n    /,\n    inner_policy_type: type[P] | None = None,\n) -&gt; Opaque[P, T]\n</code></pre> <p>Turn a query into an opaque space by providing a mapping from the ambient inner policy to a prompting policy.</p> <p>Attributes:</p> Name Type Description <code>get_policy</code> <p>A function that maps the ambient inner policy to a prompting policy to use for answering the query. Alternatively, if the ellipsis value <code>...</code> is passed, the inner policy type is assumed to be <code>IPDict</code>, and prompting policies are automatically selected using tags (see <code>IPDict</code> documentation).</p> <code>inner_policy_type</code> <p>Ambient inner policy type. This information is not used at runtime but it can be provided to help type inference when necessary.</p> <p>The optional <code>inner_policy_type</code> argument is ignored at runtime and can be used to help type checkers infer the type of the ambient inner policy.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def using[P](\n    self,\n    get_policy: Callable[[P], pol.PromptingPolicy] | EllipsisType,\n    /,\n    inner_policy_type: type[P] | None = None,\n) -&gt; Opaque[P, T]:\n    \"\"\"\n    Turn a query into an opaque space by providing a mapping from\n    the ambient inner policy to a prompting policy.\n\n    Attributes:\n        get_policy: A function that maps the ambient inner policy to\n            a prompting policy to use for answering the query.\n            Alternatively, if the ellipsis value `...` is passed, the\n            inner policy type is assumed to be `IPDict`, and\n            prompting policies are automatically selected using tags\n            (see `IPDict` documentation).\n        inner_policy_type: Ambient inner policy type. This information\n            is not used at runtime but it can be provided to help type\n            inference when necessary.\n\n    The optional `inner_policy_type` argument is ignored at runtime\n    and can be used to help type checkers infer the type of the\n    ambient inner policy.\n    \"\"\"\n    if isinstance(get_policy, EllipsisType):\n        return OpaqueSpace[P, T].from_query(\n            self, cast(Any, pol.dict_subpolicy)\n        )\n    return OpaqueSpace[P, T].from_query(self, lambda p, _: get_policy(p))\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Query.run_toplevel","title":"run_toplevel","text":"<pre><code>run_toplevel(env: PolicyEnv, policy: PromptingPolicy) -&gt; Stream[T]\n</code></pre> <p>Obtain a search stream of query answers, given a prompting policy.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def run_toplevel(\n    self,\n    env: PolicyEnv,\n    policy: pol.PromptingPolicy,\n) -&gt; Stream[T]:\n    \"\"\"\n    Obtain a search stream of query answers, given a prompting\n    policy.\n    \"\"\"\n    attached = dp.spawn_standalone_query(self)\n    return policy(attached, env)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Parser","title":"Parser  <code>dataclass</code>","text":"<p>A parser specification.</p> <p>In addition to a mapping from answers to answer type <code>A</code>, a parser also specifies query settings to be passed to oracles, along with special formatting instructions to be rendered into the prompt. Indeed, these components are typically tied and so specifying them together in a single place is clearer.</p> <p>Attributes:</p> Name Type Description <code>settings</code> <code>QuerySettings</code> <p>The query settings associated with the parser.</p> <code>formatting</code> <code>FormattingMetadata</code> <p>Formatting metadata.</p> <code>parse</code> <code>Callable[[Answer], A]</code> <p>The parsing function, which is allowed to raise the <code>ParseError</code> exception.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@dataclass(frozen=True)\nclass Parser[A]:\n    \"\"\"\n    A parser specification.\n\n    In addition to a mapping from answers to answer type `A`, a parser\n    also specifies query settings to be passed to oracles, along with\n    special formatting instructions to be rendered into the prompt.\n    Indeed, these components are typically tied and so specifying them\n    together in a single place is clearer.\n\n    Attributes:\n        settings: The query settings associated with the parser.\n        formatting: Formatting metadata.\n        parse: The parsing function, which is allowed to raise\n            the `ParseError` exception.\n    \"\"\"\n\n    settings: dp.QuerySettings\n    formatting: FormattingMetadata\n    parse: Callable[[dp.Answer], A]\n\n    def update_formatting(\n        self, f: Callable[[FormattingMetadata], FormattingMetadata], /\n    ) -&gt; \"Parser[A]\":\n        return replace(self, formatting=f(self.formatting))\n\n    def map[B](\n        self,\n        f: Callable[[A], B | dp.ParseError],\n        /,\n        *,\n        catch_exn: bool = False,\n    ) -&gt; \"Parser[B]\":\n        \"\"\"\n        Apply a function to the parser's output.\n\n        Arguments:\n            f: The function to apply, which is allowed to raise or\n                return `ParseError`.\n            catch_exn: If `True`, any other exception raised by `f` is\n                caught and wrapped into a `ParseError`.\n        \"\"\"\n\n        def parse(ans: dp.Answer) -&gt; B:\n            res = self.parse(ans)\n            try:\n                ret = f(res)\n            except dp.ParseError as e:\n                raise e\n            except Exception as e:\n                if catch_exn:\n                    raise dp.ParseError(description=str(e))\n                else:\n                    raise e\n            if isinstance(ret, dp.ParseError):\n                raise ret\n            return ret\n\n        return Parser(\n            settings=self.settings, formatting=self.formatting, parse=parse\n        )\n\n    def validate(\n        self,\n        f: Callable[[A], dp.ParseError | None],\n        /,\n        *,\n        catch_exn: bool = False,\n    ) -&gt; \"Parser[A]\":\n        \"\"\"\n        Check that the parser's output satisfies a given property.\n\n        If the property is satisfied, function `f` must return `None`.\n        Otherwise, it may return or raise a `ParseError`.\n        \"\"\"\n\n        def parse(ans: dp.Answer) -&gt; A:\n            res = self.parse(ans)\n            try:\n                opt_err = f(res)\n            except dp.ParseError as e:\n                raise e\n            except Exception as e:\n                if catch_exn:\n                    raise dp.ParseError(description=str(e))\n                else:\n                    raise e\n            if opt_err:\n                raise opt_err\n            return res\n\n        return Parser(\n            settings=self.settings, formatting=self.formatting, parse=parse\n        )\n\n    @property\n    def wrap_errors(self) -&gt; \"Parser[A | WrappedParseError]\":\n        \"\"\"\n        Wrap parse errors into `WrappedParseError`.\n        \"\"\"\n\n        def parse(ans: dp.Answer) -&gt; A | WrappedParseError:\n            try:\n                return self.parse(ans)\n            except dp.ParseError as e:\n                return WrappedParseError(e)\n\n        return Parser(\n            settings=self.settings, formatting=self.formatting, parse=parse\n        )\n\n    def response_with[T: md.AbstractTool[Any]](\n        self, tools: TypeAnnot[T]\n    ) -&gt; \"Parser[Response[A, T]]\":\n        \"\"\"\n        Wrap answers into full `Response` objects.\n        \"\"\"\n\n        tools_raw = dpi.union_components(tools)\n        tools_types: list[type[md.AbstractTool[Any]]] = [\n            a for a in tools_raw if issubclass(a, md.AbstractTool)\n        ]\n        assert len(tools_types) == len(tools_raw), (\n            f\"Invalid tools union: {tools}\"\n        )\n        if self.settings.tools is None:\n            tools_settings = dp.ToolSettings(\n                tool_types=tools_types, force_tool_call=False\n            )\n        else:\n            tools_settings = dp.ToolSettings(\n                tool_types=[*tools_types, *self.settings.tools.tool_types],\n                force_tool_call=self.settings.tools.force_tool_call,\n            )\n        settings = replace(self.settings, tools=tools_settings)\n\n        def parse(ans: dp.Answer) -&gt; Response[A, T]:\n            # If the answer is one of the provided tool types, we\n            # return. Otherwise, we call the parser recursively.\n            tcs: list[T] = []\n            for tc in ans.tool_calls:\n                for t in tools_types:\n                    if tc.name == t.tool_name():\n                        tcs.append(_parse_or_raise(t, tc.args))\n                        break\n            if tcs:\n                return Response[A, T](ans, ToolRequests(tcs))\n            else:\n                parsed = self.parse(ans)\n                return Response[A, T](ans, FinalAnswer(parsed))\n\n        return Parser(\n            settings=settings, formatting=self.formatting, parse=parse\n        )\n\n    @property\n    def response(self) -&gt; \"GenericParser\":\n        \"\"\"\n        Wrap answers into full `Response` objects.\n\n        Return a `GenericParser` so that the list of supported tools can\n        be extracted from the query's answer type.\n        \"\"\"\n\n        def parser(annot: TypeAnnot[Any], /) -&gt; Parser[Any]:\n            assert typing.get_origin(annot) is Response, (\n                f\"Response type expected: {annot}\"\n            )\n            args = typing.get_args(annot)\n            assert len(args) == 2\n            return self.response_with(args[1])\n\n        return GenericParser(parser)\n\n    @property\n    def trim(self: \"Parser[str]\") -&gt; \"Parser[str]\":\n        \"\"\"\n        Trim the output of a string parser.\n        \"\"\"\n        return self.map(str.strip)\n\n    @property\n    def json(self: \"Parser[str]\") -&gt; \"GenericParser\":\n        \"\"\"\n        Parse a string as a JSON object.\n\n        Return a `GenericParser` so that the target type can be\n        extracted from the query's answer type.\n        \"\"\"\n\n        return GenericParser(self.json_as)\n\n    @property\n    def yaml(self: \"Parser[str]\") -&gt; \"GenericParser\":\n        \"\"\"\n        Parse a string as a YAML object.\n\n        Return a `GenericParser` so that the target type can be\n        extracted from the query's answer type.\n        \"\"\"\n\n        return GenericParser(self.yaml_as)\n\n    def json_as[U](self: \"Parser[str]\", type: TypeAnnot[U]) -&gt; \"Parser[U]\":\n        \"\"\"\n        Parse a string as a JSON object.\n\n        !!! info\n            This method currently does not work very well with type\n            inference since its arguments do not allow inferring the\n            type of `U`. This should work better once `TypeAnnot` can be\n            replaced with `TypeExpr` (incoming in Python 3.14).\n        \"\"\"\n\n        _assert_not_response_type(type, where=\"json_as\")\n        schema = md.Schema.make(type)\n        return self.map(partial(_parse_json_as, type)).update_formatting(\n            lambda f: replace(f, what=\"json\", schema=schema)\n        )\n\n    def yaml_as[U](self: \"Parser[str]\", type: TypeAnnot[U]) -&gt; \"Parser[U]\":\n        \"\"\"\n        Parse a string as a YAML object.\n\n        !!! info\n            This method currently does not work very well with type\n            inference since its arguments do not allow inferring the\n            type of `U`. This should work better once `TypeAnnot` can be\n            replaced with `TypeExpr` (incoming in Python 3.14).\n        \"\"\"\n        _assert_not_response_type(type, where=\"yaml_as\")\n        schema = md.Schema.make(type)\n        return self.map(partial(_parse_yaml_as, type)).update_formatting(\n            lambda f: replace(f, what=\"yaml\", schema=schema)\n        )\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Parser.wrap_errors","title":"wrap_errors  <code>property</code>","text":"<pre><code>wrap_errors: Parser[A | WrappedParseError]\n</code></pre> <p>Wrap parse errors into <code>WrappedParseError</code>.</p>"},{"location":"reference/stdlib/queries/#delphyne.Parser.response","title":"response  <code>property</code>","text":"<pre><code>response: GenericParser\n</code></pre> <p>Wrap answers into full <code>Response</code> objects.</p> <p>Return a <code>GenericParser</code> so that the list of supported tools can be extracted from the query's answer type.</p>"},{"location":"reference/stdlib/queries/#delphyne.Parser.trim","title":"trim  <code>property</code>","text":"<pre><code>trim: Parser[str]\n</code></pre> <p>Trim the output of a string parser.</p>"},{"location":"reference/stdlib/queries/#delphyne.Parser.json","title":"json  <code>property</code>","text":"<pre><code>json: GenericParser\n</code></pre> <p>Parse a string as a JSON object.</p> <p>Return a <code>GenericParser</code> so that the target type can be extracted from the query's answer type.</p>"},{"location":"reference/stdlib/queries/#delphyne.Parser.yaml","title":"yaml  <code>property</code>","text":"<pre><code>yaml: GenericParser\n</code></pre> <p>Parse a string as a YAML object.</p> <p>Return a <code>GenericParser</code> so that the target type can be extracted from the query's answer type.</p>"},{"location":"reference/stdlib/queries/#delphyne.Parser.map","title":"map","text":"<pre><code>map(f: Callable[[A], B | ParseError], /, *, catch_exn: bool = False) -&gt; Parser[B]\n</code></pre> <p>Apply a function to the parser's output.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>Callable[[A], B | ParseError]</code> <p>The function to apply, which is allowed to raise or return <code>ParseError</code>.</p> required <code>catch_exn</code> <code>bool</code> <p>If <code>True</code>, any other exception raised by <code>f</code> is caught and wrapped into a <code>ParseError</code>.</p> <code>False</code> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def map[B](\n    self,\n    f: Callable[[A], B | dp.ParseError],\n    /,\n    *,\n    catch_exn: bool = False,\n) -&gt; \"Parser[B]\":\n    \"\"\"\n    Apply a function to the parser's output.\n\n    Arguments:\n        f: The function to apply, which is allowed to raise or\n            return `ParseError`.\n        catch_exn: If `True`, any other exception raised by `f` is\n            caught and wrapped into a `ParseError`.\n    \"\"\"\n\n    def parse(ans: dp.Answer) -&gt; B:\n        res = self.parse(ans)\n        try:\n            ret = f(res)\n        except dp.ParseError as e:\n            raise e\n        except Exception as e:\n            if catch_exn:\n                raise dp.ParseError(description=str(e))\n            else:\n                raise e\n        if isinstance(ret, dp.ParseError):\n            raise ret\n        return ret\n\n    return Parser(\n        settings=self.settings, formatting=self.formatting, parse=parse\n    )\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Parser.validate","title":"validate","text":"<pre><code>validate(\n    f: Callable[[A], ParseError | None], /, *, catch_exn: bool = False\n) -&gt; Parser[A]\n</code></pre> <p>Check that the parser's output satisfies a given property.</p> <p>If the property is satisfied, function <code>f</code> must return <code>None</code>. Otherwise, it may return or raise a <code>ParseError</code>.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def validate(\n    self,\n    f: Callable[[A], dp.ParseError | None],\n    /,\n    *,\n    catch_exn: bool = False,\n) -&gt; \"Parser[A]\":\n    \"\"\"\n    Check that the parser's output satisfies a given property.\n\n    If the property is satisfied, function `f` must return `None`.\n    Otherwise, it may return or raise a `ParseError`.\n    \"\"\"\n\n    def parse(ans: dp.Answer) -&gt; A:\n        res = self.parse(ans)\n        try:\n            opt_err = f(res)\n        except dp.ParseError as e:\n            raise e\n        except Exception as e:\n            if catch_exn:\n                raise dp.ParseError(description=str(e))\n            else:\n                raise e\n        if opt_err:\n            raise opt_err\n        return res\n\n    return Parser(\n        settings=self.settings, formatting=self.formatting, parse=parse\n    )\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Parser.response_with","title":"response_with","text":"<pre><code>response_with(tools: TypeAnnot[T]) -&gt; Parser[Response[A, T]]\n</code></pre> <p>Wrap answers into full <code>Response</code> objects.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def response_with[T: md.AbstractTool[Any]](\n    self, tools: TypeAnnot[T]\n) -&gt; \"Parser[Response[A, T]]\":\n    \"\"\"\n    Wrap answers into full `Response` objects.\n    \"\"\"\n\n    tools_raw = dpi.union_components(tools)\n    tools_types: list[type[md.AbstractTool[Any]]] = [\n        a for a in tools_raw if issubclass(a, md.AbstractTool)\n    ]\n    assert len(tools_types) == len(tools_raw), (\n        f\"Invalid tools union: {tools}\"\n    )\n    if self.settings.tools is None:\n        tools_settings = dp.ToolSettings(\n            tool_types=tools_types, force_tool_call=False\n        )\n    else:\n        tools_settings = dp.ToolSettings(\n            tool_types=[*tools_types, *self.settings.tools.tool_types],\n            force_tool_call=self.settings.tools.force_tool_call,\n        )\n    settings = replace(self.settings, tools=tools_settings)\n\n    def parse(ans: dp.Answer) -&gt; Response[A, T]:\n        # If the answer is one of the provided tool types, we\n        # return. Otherwise, we call the parser recursively.\n        tcs: list[T] = []\n        for tc in ans.tool_calls:\n            for t in tools_types:\n                if tc.name == t.tool_name():\n                    tcs.append(_parse_or_raise(t, tc.args))\n                    break\n        if tcs:\n            return Response[A, T](ans, ToolRequests(tcs))\n        else:\n            parsed = self.parse(ans)\n            return Response[A, T](ans, FinalAnswer(parsed))\n\n    return Parser(\n        settings=settings, formatting=self.formatting, parse=parse\n    )\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Parser.json_as","title":"json_as","text":"<pre><code>json_as(type: TypeAnnot[U]) -&gt; Parser[U]\n</code></pre> <p>Parse a string as a JSON object.</p> <p>Info</p> <p>This method currently does not work very well with type inference since its arguments do not allow inferring the type of <code>U</code>. This should work better once <code>TypeAnnot</code> can be replaced with <code>TypeExpr</code> (incoming in Python 3.14).</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def json_as[U](self: \"Parser[str]\", type: TypeAnnot[U]) -&gt; \"Parser[U]\":\n    \"\"\"\n    Parse a string as a JSON object.\n\n    !!! info\n        This method currently does not work very well with type\n        inference since its arguments do not allow inferring the\n        type of `U`. This should work better once `TypeAnnot` can be\n        replaced with `TypeExpr` (incoming in Python 3.14).\n    \"\"\"\n\n    _assert_not_response_type(type, where=\"json_as\")\n    schema = md.Schema.make(type)\n    return self.map(partial(_parse_json_as, type)).update_formatting(\n        lambda f: replace(f, what=\"json\", schema=schema)\n    )\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.Parser.yaml_as","title":"yaml_as","text":"<pre><code>yaml_as(type: TypeAnnot[U]) -&gt; Parser[U]\n</code></pre> <p>Parse a string as a YAML object.</p> <p>Info</p> <p>This method currently does not work very well with type inference since its arguments do not allow inferring the type of <code>U</code>. This should work better once <code>TypeAnnot</code> can be replaced with <code>TypeExpr</code> (incoming in Python 3.14).</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def yaml_as[U](self: \"Parser[str]\", type: TypeAnnot[U]) -&gt; \"Parser[U]\":\n    \"\"\"\n    Parse a string as a YAML object.\n\n    !!! info\n        This method currently does not work very well with type\n        inference since its arguments do not allow inferring the\n        type of `U`. This should work better once `TypeAnnot` can be\n        replaced with `TypeExpr` (incoming in Python 3.14).\n    \"\"\"\n    _assert_not_response_type(type, where=\"yaml_as\")\n    schema = md.Schema.make(type)\n    return self.map(partial(_parse_yaml_as, type)).update_formatting(\n        lambda f: replace(f, what=\"yaml\", schema=schema)\n    )\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.GenericParser","title":"GenericParser  <code>dataclass</code>","text":"<p>A mapping from a query's answer type to a parser specification.</p> <p>This is useful to avoid redundancy when specifying parsers. In particular, it allows writing:</p> <pre><code>@dataclass\nclass MyQuery(Query[Response[Out, Tool1 | Tool2]]):\n    ...\n    __parser__ = last_block.yaml.response\n</code></pre> <p>instead of:</p> <pre><code>__parser__ = last_block.yaml_as(Out).response_with(Tool1 | Tool2)\n</code></pre> <p>Attributes:</p> Name Type Description <code>for_type</code> <code>_GenericParserFn</code> <p>A function that takes a type annotation and returns a <code>Parser</code> for this type.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@dataclass(frozen=True)\nclass GenericParser:\n    \"\"\"\n    A mapping from a query's answer type to a parser specification.\n\n    This is useful to avoid redundancy when specifying parsers. In\n    particular, it allows writing:\n\n    ```python\n    @dataclass\n    class MyQuery(Query[Response[Out, Tool1 | Tool2]]):\n        ...\n        __parser__ = last_block.yaml.response\n    ```\n\n    instead of:\n\n    ```python\n    __parser__ = last_block.yaml_as(Out).response_with(Tool1 | Tool2)\n    ```\n\n    Attributes:\n        for_type: A function that takes a type annotation and returns a\n            `Parser` for this type.\n    \"\"\"\n\n    for_type: \"_GenericParserFn\"\n\n    @property\n    def wrap_errors(self) -&gt; \"GenericParser\":\n        \"\"\"\n        Wrap parse errors into `WrappedParseError`.\n\n        A runtime check is performed to ensure that the answer type\n        features `WrappedParseError`.\n        \"\"\"\n\n        def parser(annot: TypeAnnot[Any], /) -&gt; Parser[Any]:\n            comps = dpi.union_components(annot)\n            assert len(comps) &gt;= 2 and WrappedParseError in comps, (\n                \"Answer type does not have shape `... | WrappedParseError`: \"\n                + f\"{annot}\"\n            )\n            annot = dpi.make_union(\n                [c for c in comps if c != WrappedParseError]\n            )\n            return self.for_type(annot).wrap_errors\n\n        return GenericParser(parser)\n\n    @property\n    def response(self) -&gt; \"GenericParser\":\n        \"\"\"\n        Wrap answers into full `Response` objects.\n\n        Possible tool calls are extracted from the query's answer type\n        and an exception is raised if this type does not have the form\n        `Response[..., ...]`.\n        \"\"\"\n\n        def parser(annot: TypeAnnot[Any], /) -&gt; Parser[Any]:\n            assert typing.get_origin(annot) is Response, (\n                f\"Response type expected: {annot}\"\n            )\n            args = typing.get_args(annot)\n            assert len(args) == 2\n            return self.for_type(args[0]).response_with(args[1])\n\n        return GenericParser(parser)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.GenericParser.wrap_errors","title":"wrap_errors  <code>property</code>","text":"<pre><code>wrap_errors: GenericParser\n</code></pre> <p>Wrap parse errors into <code>WrappedParseError</code>.</p> <p>A runtime check is performed to ensure that the answer type features <code>WrappedParseError</code>.</p>"},{"location":"reference/stdlib/queries/#delphyne.GenericParser.response","title":"response  <code>property</code>","text":"<pre><code>response: GenericParser\n</code></pre> <p>Wrap answers into full <code>Response</code> objects.</p> <p>Possible tool calls are extracted from the query's answer type and an exception is raised if this type does not have the form <code>Response[..., ...]</code>.</p>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.queries._GenericParserFn","title":"_GenericParserFn","text":"<p>               Bases: <code>Protocol</code></p> <p>Type of functions wrapped by <code>GenericParser</code>.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>class _GenericParserFn(Protocol):\n    \"\"\"\n    Type of functions wrapped by `GenericParser`.\n    \"\"\"\n\n    def __call__[T](self, type: TypeAnnot[T], /) -&gt; Parser[T]: ...\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.ParserDict","title":"ParserDict","text":"<pre><code>ParserDict = dict[AnswerMode, Parser[Any] | GenericParser]\n</code></pre> <p>A mapping from answer modes to parser specifications.</p> <p>Can be used as a value for the <code>__parser__</code> class attribute of queries.</p>"},{"location":"reference/stdlib/queries/#delphyne.Response","title":"Response  <code>dataclass</code>","text":"<p>Answer type for queries that allow follow-ups.</p> <p><code>Response</code> values give access to both the raw LLM response (to be passed pass in <code>AnswerPrefix</code>) and to eventual tool calls. See the <code>Parser.response</code>, <code>Parser.response_with</code>, and <code>GenericParser.response</code> methods for creating parsers that produce <code>Response</code> values.</p> <p>Attributes:</p> Name Type Description <code>answer</code> <code>Answer</code> <p>The raw, unparsed LLM answer.</p> <code>parsed</code> <code>FinalAnswer[F] | ToolRequests[T]</code> <p>Either the parsed answer wrapped in <code>FinalAnswer</code> or some tool call requests wrapped in <code>ToolRequests</code>.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@dataclass(frozen=True)\nclass Response[F, T: md.AbstractTool[Any]]:\n    \"\"\"\n    Answer type for queries that allow follow-ups.\n\n    `Response` values give access to both the raw LLM response (to be\n    passed pass in `AnswerPrefix`) and to eventual tool calls. See the\n    `Parser.response`, `Parser.response_with`, and\n    `GenericParser.response` methods for creating parsers that produce\n    `Response` values.\n\n    Attributes:\n        answer: The raw, unparsed LLM answer.\n        parsed: Either the parsed answer wrapped in `FinalAnswer` or\n            some tool call requests wrapped in `ToolRequests`.\n    \"\"\"\n\n    answer: dp.Answer\n    parsed: FinalAnswer[F] | ToolRequests[T]\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.FinalAnswer","title":"FinalAnswer  <code>dataclass</code>","text":"<p>See <code>Response</code>.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@dataclass(frozen=True)\nclass FinalAnswer[F]:\n    \"\"\"\n    See `Response`.\n    \"\"\"\n\n    final: F\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.ToolRequests","title":"ToolRequests  <code>dataclass</code>","text":"<p>See <code>Response</code>.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@dataclass(frozen=True)\nclass ToolRequests[T: md.AbstractTool[Any]]:\n    \"\"\"\n    See `Response`.\n    \"\"\"\n\n    tool_calls: Sequence[T]\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.WrappedParseError","title":"WrappedParseError  <code>dataclass</code>","text":"<p>A wrapped parse error that is returned to a strategy instead of causing a failure.</p> <p>For queries that declare a return type of the form <code>Response[... | WrappedParseError, ...]</code>, parse errors do not result in failures but are instead wrapped and returned, to be handled explicitly by the surrounding strategy. For example, when building conversational agents with <code>interact</code>, having the query include <code>WrappedParseError</code> in its return type allows explicitly asking the agent to fix parse errors instead of failing (or having the policy retry an identical prompt).</p> <p>See the <code>Parser.wrap_errors</code> and <code>GenericParser.wrap_errors</code> methods for creating parsers that produce <code>WrappedParseError</code> values.</p> <p>Attributes:</p> Name Type Description <code>error</code> <code>ParseError</code> <p>The wrapped parse error.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@dataclass\nclass WrappedParseError:\n    \"\"\"\n    A wrapped parse error that is returned to a strategy instead of\n    causing a failure.\n\n    For queries that declare a return type of the form `Response[... |\n    WrappedParseError, ...]`, parse errors do not result in failures but\n    are instead wrapped and returned, to be handled explicitly by the\n    surrounding strategy. For example, when building conversational\n    agents with `interact`, having the query include `WrappedParseError`\n    in its return type allows explicitly asking the agent to fix parse\n    errors instead of failing (or having the policy retry an identical\n    prompt).\n\n    See the `Parser.wrap_errors` and `GenericParser.wrap_errors` methods\n    for creating parsers that produce `WrappedParseError` values.\n\n    Attributes:\n        error: The wrapped parse error.\n    \"\"\"\n\n    error: dp.ParseError\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.queries.QueryTemplateArgs","title":"QueryTemplateArgs","text":"<p>               Bases: <code>TypedDict</code></p> <p>Template arguments passed to all query templates.</p> <p>For particular kinds of templates, additional arguments may be provided (e.g., <code>feedback</code> for feedback prompts).</p> <p>Attributes:</p> Name Type Description <code>query</code> <code>Query[Any]</code> <p>The query instance.</p> <code>mode</code> <code>AnswerMode</code> <p>The requested answer mode.</p> <code>available_modes</code> <code>Sequence[AnswerMode]</code> <p>The sequence of all available answer modes for the query type.</p> <code>params</code> <code>dict[str, Any]</code> <p>The query hyperparameters (e.g., as passed to <code>few_shot</code>)</p> <code>format</code> <code>FormattingMetadata</code> <p>Formatting metadata.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>class QueryTemplateArgs(typing.TypedDict):\n    \"\"\"\n    Template arguments passed to all query templates.\n\n    For particular kinds of templates, additional arguments may be\n    provided (e.g., `feedback` for feedback prompts).\n\n    Attributes:\n        query: The query instance.\n        mode: The requested answer mode.\n        available_modes: The sequence of all available answer modes for\n            the query type.\n        params: The query hyperparameters (e.g., as passed to `few_shot`)\n        format: Formatting metadata.\n    \"\"\"\n\n    # TODO: in future Python versions, use `extra_items=Any` (PEP 728)\n\n    query: \"Query[Any]\"\n    mode: dp.AnswerMode\n    available_modes: Sequence[dp.AnswerMode]\n    params: dict[str, Any]\n    format: FormattingMetadata\n</code></pre>"},{"location":"reference/stdlib/queries/#standard-parsers","title":"Standard Parsers","text":""},{"location":"reference/stdlib/queries/#delphyne.structured_as","title":"structured_as","text":"<pre><code>structured_as(type: TypeAnnot[T]) -&gt; Parser[T]\n</code></pre> <p>Parse an LLM structured answer into a given target type.</p> <p>Warning</p> <p>Only dataclass types are supported, since most LLM providers only support structured output and tool calls for JSON objects.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def structured_as[T](type: TypeAnnot[T], /) -&gt; Parser[T]:\n    \"\"\"\n    Parse an LLM structured answer into a given target type.\n\n    !!! warning\n        Only dataclass types are supported, since most LLM providers\n        only support structured output and tool calls for JSON objects.\n    \"\"\"\n    _assert_not_response_type(type, where=\"structured_as\")\n    _check_valid_structured_output_type(type)\n    settings = dp.QuerySettings(dp.StructuredOutputSettings(type))\n    formatting = FormattingMetadata(\n        where=\"full_answer\", what=\"json\", schema=md.Schema.make(type)\n    )\n    return Parser(\n        settings, formatting, lambda ans: _parse_structured_output(type, ans)\n    )\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.final_tool_call_as","title":"final_tool_call_as","text":"<pre><code>final_tool_call_as(annot: TypeAnnot[T]) -&gt; Parser[T]\n</code></pre> <p>Variant of <code>structured_as</code>, where the query answer type is presented to oracles as a tool, which must be called to produce the final answer. This provides an alternative to \"structured\", which additionally allows a chain of thoughts to precede the final answer.</p> <p>Warning</p> <p>Only dataclass types are supported, since most LLM providers only support structured output and tool calls for JSON objects.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>def final_tool_call_as[T](annot: TypeAnnot[T], /) -&gt; Parser[T]:\n    \"\"\"\n    Variant of `structured_as`, where the query answer type is presented\n    to oracles as a tool, which must be called to produce the final\n    answer. This provides an alternative to \"structured\", which\n    additionally allows a chain of thoughts to precede the final answer.\n\n    !!! warning\n        Only dataclass types are supported, since most LLM providers\n        only support structured output and tool calls for JSON objects.\n    \"\"\"\n    _check_valid_structured_output_type(annot)\n    assert isinstance(annot, type)  # redundant with previous check\n    tool = cast(type[Any], annot)\n    tool_settings = dp.ToolSettings(tool_types=[tool], force_tool_call=True)\n    settings = dp.QuerySettings(None, tool_settings)\n    formatting = FormattingMetadata(\n        where=\"tool_call\", what=\"json\", schema=md.Schema.make(annot)\n    )\n\n    def parse(ans: dp.Answer) -&gt; T:\n        assert len(ans.tool_calls) == 1, (\n            f\"Expected one final tool call, got answer: {ans}\"\n        )\n        return _parse_or_raise(tool, ans.tool_calls[0].args)\n\n    return Parser(settings, formatting, parse)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.structured","title":"structured  <code>module-attribute</code>","text":"<pre><code>structured = GenericParser(structured_as)\n</code></pre> <p>Generic parser associated with <code>structured_as</code>.</p>"},{"location":"reference/stdlib/queries/#delphyne.final_tool_call","title":"final_tool_call  <code>module-attribute</code>","text":"<pre><code>final_tool_call = GenericParser(final_tool_call_as)\n</code></pre> <p>Generic parser associated with <code>final_tool_call_as</code>.</p>"},{"location":"reference/stdlib/queries/#delphyne.last_code_block","title":"last_code_block  <code>module-attribute</code>","text":"<pre><code>last_code_block: Parser[str] = update_formatting(\n    lambda f: replace(f, where=\"last_code_block\")\n)\n</code></pre> <p>Parser that extracts the last code block from a text answer.</p>"},{"location":"reference/stdlib/queries/#delphyne.get_text","title":"get_text  <code>module-attribute</code>","text":"<pre><code>get_text = Parser[str](\n    QuerySettings(),\n    FormattingMetadata(where=\"full_answer\", what=\"text\"),\n    _get_text_answer,\n)\n</code></pre> <p>Parser that extracts the text content of an answer.</p> <p>A runtime error is raised if the answer contains structured content.</p>"},{"location":"reference/stdlib/queries/#prompting-policies","title":"Prompting Policies","text":""},{"location":"reference/stdlib/queries/#delphyne.few_shot","title":"few_shot","text":"<pre><code>few_shot(\n    query: AttachedQuery[T],\n    env: PolicyEnv,\n    model: LLM,\n    *,\n    params: dict[str, object] | None = None,\n    select_examples: Sequence[ExampleSelector] = (),\n    mode: AnswerMode = None,\n    enable_logging: bool = True,\n    temperature: float | None = None,\n    num_completions: int = 1,\n    max_requests: int | None = None,\n    no_wrap_parse_errors: bool = False,\n    iterative_mode: bool = False,\n) -&gt; StreamGen[T]\n</code></pre> <p>The standard few-shot prompting policy.</p> <p>A prompt is formed by concatenating a system prompt, a series of examples (each of which consists in an instance prompt followed by an answer), and a final answer prompt. Then, answers are repeatedly sampled and parsed, until a spending request is declined.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>AttachedQuery[T]</code> <p>The query to answer. env: The policy environment.</p> required <code>model</code> <code>LLM</code> <p>The LLM to use for answering the query</p> required <code>params</code> <code>dict[str, object] | None</code> <p>Prompt hyperparameters, which are passed to prompt templates as a <code>params</code> dictionary.</p> <code>None</code> <code>select_examples</code> <code>Sequence[ExampleSelector]</code> <p>A series of filters for selecting examples, to be applied in sequence. By default, no filter is used and so all available examples are fetched.</p> <code>()</code> <code>mode</code> <code>AnswerMode</code> <p>The answer mode to use for parsing the query answer.</p> <code>None</code> <code>enable_logging</code> <code>bool</code> <p>Whether to log raw oracle responses.</p> <code>True</code> <code>temperature</code> <code>float | None</code> <p>The temperature parameter to use with the LLM, as a number from 0 to 2.</p> <code>None</code> <code>num_completions</code> <code>int</code> <p>The number of completions to request for each LLM call. Note that most LLM providers only bill input tokens once, regardless of the number of completions.</p> <code>1</code> <code>max_requests</code> <code>int | None</code> <p>The maximum number of LLM requests to perform before the resulting seach stream terminates, if any.</p> <code>None</code> <code>no_wrap_parse_errors</code> <code>bool</code> <p>If set to <code>True</code>, then parser results of type <code>WrappedParseError</code> are unwrapped and treated as normal parse errors.</p> <code>False</code> <code>iterative_mode</code> <code>bool</code> <p>If set to <code>False</code> (default), answers are repeatedly and independently sampled. If set to <code>True</code>, a single chat conversation occurs instead: Whenever a parse error occurs, a message is issued by rendering the <code>&lt;QueryName&gt;.repair.jinja</code> template, asking for a new attempt to be made (the <code>ParseError</code> object is available as an <code>error</code> template variable). After an answer is successfully generated and parsed, a message is issued by rendering the <code>&lt;QueryName&gt;.more.jinja</code> template, asking for another different answer to be generated.</p> <p>This special mode allows creating simple conversational agents with very little effort, by only defining a single query. However, it does not support tool calls, and the demonstration language cannot be used to illustrate how <code>repair</code> and <code>more</code> messages should be handled. For implementing more advanced conversational agents, see the standard <code>interact</code> strategy.</p> <code>False</code> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@prompting_policy\ndef few_shot[T](\n    query: dp.AttachedQuery[T],\n    env: PolicyEnv,\n    model: md.LLM,\n    *,\n    params: dict[str, object] | None = None,\n    select_examples: Sequence[ExampleSelector] = (),\n    mode: dp.AnswerMode = None,\n    enable_logging: bool = True,\n    temperature: float | None = None,\n    num_completions: int = 1,\n    max_requests: int | None = None,\n    no_wrap_parse_errors: bool = False,\n    iterative_mode: bool = False,\n) -&gt; dp.StreamGen[T]:\n    \"\"\"\n    The standard few-shot prompting policy.\n\n    A prompt is formed by concatenating a system prompt, a series of\n    examples (each of which consists in an instance prompt followed by\n    an answer), and a final answer prompt. Then, answers are repeatedly\n    sampled and parsed, until a spending request is declined.\n\n    Arguments:\n        query: The query to answer. env: The policy environment.\n        model: The LLM to use for answering the query\n        params: Prompt hyperparameters, which are passed to prompt\n            templates as a `params` dictionary.\n        select_examples: A series of filters for selecting examples, to\n            be applied in sequence. By default, no filter is used and so\n            all available examples are fetched.\n        mode: The answer mode to use for parsing the query answer.\n        enable_logging: Whether to log raw oracle responses.\n        temperature: The temperature parameter to use with the LLM, as a\n            number from 0 to 2.\n        num_completions: The number of completions to request for each\n            LLM call. Note that most LLM providers only bill input\n            tokens once, regardless of the number of completions.\n        max_requests: The maximum number of LLM requests to perform\n            before the resulting seach stream terminates, if any.\n        no_wrap_parse_errors: If set to `True`, then parser results of\n            type `WrappedParseError` are unwrapped and treated as normal\n            parse errors.\n        iterative_mode: If set to `False` (default), answers are\n            repeatedly and independently sampled. If set to `True`, a\n            single chat conversation occurs instead: Whenever a parse\n            error occurs, a message is issued by rendering the\n            `&lt;QueryName&gt;.repair.jinja` template, asking for a new\n            attempt to be made (the `ParseError` object is available as\n            an `error` template variable). After an answer is\n            successfully generated and parsed, a message is issued by\n            rendering the `&lt;QueryName&gt;.more.jinja` template, asking for\n            another different answer to be generated.\n\n            This special mode allows creating simple conversational\n            agents with very little effort, by only defining a single\n            query. However, it does not support tool calls, and the\n            demonstration language cannot be used to illustrate how\n            `repair` and `more` messages should be handled. For\n            implementing more advanced conversational agents, see\n            the standard `interact` strategy.\n    \"\"\"\n    assert not iterative_mode or num_completions == 1\n    assert max_requests is None or max_requests &gt; 0\n    env.tracer.trace_query(query.ref)\n    examples = fetch_examples(env.examples, query.query, select_examples)\n    mngr = env.templates\n    if params is None:\n        params = {}\n    prompt = create_prompt(query.query, examples, params, mode, mngr)\n    settings = query.query.query_settings(mode)\n    options: md.RequestOptions = {}\n    if temperature is not None:\n        options[\"temperature\"] = temperature\n    structured_output = None\n    if settings.structured_output is not None:\n        out_type = settings.structured_output.type\n        structured_output = md.Schema.make(out_type)\n    tools = []\n    if settings.tools is not None:\n        if settings.tools.force_tool_call:\n            options[\"tool_choice\"] = \"required\"\n        tools = [md.Schema.make(t) for t in settings.tools.tool_types]\n    num_reqs = 0\n    while max_requests is None or num_reqs &lt; max_requests:\n        num_reqs += 1\n        req = md.LLMRequest(\n            prompt,\n            num_completions=num_completions,\n            options=options,\n            tools=tools,\n            structured_output=structured_output,\n        )\n        resp = yield from _send_request(model, req, env)\n        if isinstance(resp, SpendingDeclined):\n            return\n        log_oracle_response(env, query, req, resp, verbose=enable_logging)\n        if not resp.outputs:\n            log(env, \"llm_no_output\", loc=query)\n            continue\n        elements: list[dp.Tracked[T] | dp.ParseError] = []\n        answers: list[dp.Answer] = []\n        for output in resp.outputs:\n            answer = dp.Answer(mode, output.content, tuple(output.tool_calls))\n            answers.append(answer)\n            element = query.parse_answer(answer)\n            if no_wrap_parse_errors:\n                element = _unwrap_parse_error(element)\n            env.tracer.trace_answer(query.ref, answer)\n            if isinstance(element, dp.ParseError):\n                log(env, \"parse_error\", {\"error\": element}, loc=query)\n            elements.append(element)\n        for element in elements:\n            if not isinstance(element, dp.ParseError):\n                yield dp.Solution(element)\n        # In iterative mode, we want to keep the conversation going\n        if iterative_mode:\n            assert len(elements) == 1 and len(answers) == 1\n            element = elements[0]\n            if isinstance(element, dp.ParseError):\n                try:\n                    repair = query.query.generate_prompt(\n                        kind=REPAIR_PROMPT,\n                        mode=mode,\n                        params={\"params\": params, \"error\": element},\n                        env=mngr,\n                    )\n                except dp.TemplateFileMissing:\n                    repair = (\n                        \"Invalid answer. Please consider the following\"\n                        + f\" feedback and try again:\\n\\n{element}\"\n                    )\n                new_message = md.UserMessage(repair)\n            else:\n                try:\n                    gen_new = query.query.generate_prompt(\n                        kind=REQUEST_OTHER_PROMPT,\n                        mode=mode,\n                        params={\"params\": params},\n                        env=mngr,\n                    )\n                except dp.TemplateFileMissing:\n                    gen_new = \"Good! Can you generate a different answer now?\"\n                new_message = md.UserMessage(gen_new)\n\n            prompt = (*prompt, md.AssistantMessage(answers[0]), new_message)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.classify","title":"classify","text":"<pre><code>classify(\n    query: AttachedQuery[T],\n    env: PolicyEnv,\n    model: LLM,\n    params: dict[str, object] | None = None,\n    select_examples: Sequence[ExampleSelector] = (),\n    mode: AnswerMode = None,\n    enable_logging: bool = True,\n    top_logprobs: int = 20,\n    temperature: float = 1.0,\n    bias: tuple[str, float] | None = None,\n) -&gt; StreamGen[T]\n</code></pre> <p>Execute a classification query, attaching a probability distribution to the attached answer.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>AttachedQuery[T]</code> <p>The query to answer.</p> required <code>env</code> <code>PolicyEnv</code> <p>The global policy environment.</p> required <code>model</code> <code>LLM</code> <p>The LLM to use for answering the query.</p> required <code>params</code> <code>dict[str, object] | None</code> <p>Prompt hyperparameters.</p> <code>None</code> <code>select_examples</code> <code>Sequence[ExampleSelector]</code> <p>Example selector.</p> <code>()</code> <code>mode</code> <code>AnswerMode</code> <p>The answer mode to use for parsing the query answer.</p> <code>None</code> <code>enable_logging</code> <code>bool</code> <p>Whether to log raw oracle responses.</p> <code>True</code> <code>top_logprobs</code> <code>int</code> <p>The number of top logprobs to request from the LLM, putting an upper bound on the support size of the classifier's output distributions.</p> <code>20</code> <code>temperature</code> <code>float</code> <p>A temperature to apply to the classifier's output distribution (a temperature of 0 means that only top elements are assigned a nonzero probability).</p> <code>1.0</code> <code>bias</code> <code>tuple[str, float] | None</code> <p>When <code>bias=(e, p)</code> is provided, the final classifier distribution <code>D</code> is transformed into <code>(1-p)*D + p*dirac(e)</code></p> <code>None</code> <p>See <code>few_shot</code> for details on some of the arguments above.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@prompting_policy\ndef classify[T](\n    query: dp.AttachedQuery[T],\n    env: PolicyEnv,\n    model: md.LLM,\n    params: dict[str, object] | None = None,\n    select_examples: Sequence[ExampleSelector] = (),\n    mode: dp.AnswerMode = None,\n    enable_logging: bool = True,\n    top_logprobs: int = 20,\n    temperature: float = 1.0,\n    bias: tuple[str, float] | None = None,\n) -&gt; dp.StreamGen[T]:\n    \"\"\"\n    Execute a classification query, attaching a probability distribution\n    to the attached answer.\n\n    Arguments:\n        query: The query to answer.\n        env: The global policy environment.\n        model: The LLM to use for answering the query.\n        params: Prompt hyperparameters.\n        select_examples: Example selector.\n        mode: The answer mode to use for parsing the query answer.\n        enable_logging: Whether to log raw oracle responses.\n        top_logprobs: The number of top logprobs to request from the\n            LLM, putting an upper bound on the support size of the\n            classifier's output distributions.\n        temperature: A temperature to apply to the classifier's output\n            distribution (a temperature of 0 means that only top\n            elements are assigned a nonzero probability).\n        bias: When `bias=(e, p)` is provided, the final classifier\n            distribution `D` is transformed into `(1-p)*D + p*dirac(e)`\n\n    See `few_shot` for details on some of the arguments above.\n    \"\"\"\n    env.tracer.trace_query(query.ref)\n    examples = fetch_examples(env.examples, query.query, select_examples)\n    mngr = env.templates\n    if params is None:\n        params = {}\n    prompt = create_prompt(query.query, examples, params, mode, mngr)\n    aset = query.query.finite_answer_set()\n    assert aset is not None\n    vals: list[str] = []\n    for a in aset:\n        assert isinstance(a.content, str)\n        vals.append(a.content)\n    options: md.RequestOptions = {\n        \"logprobs\": True,\n        \"top_logprobs\": top_logprobs,\n        # TODO: somehow, there seems to be a problem with this, where\n        # one can get an empty answer with \"finish_reason: length\":\n        # \"max_completion_tokens\": 1,\n        \"temperature\": 0.0,\n    }\n    req = md.LLMRequest(\n        prompt,\n        num_completions=1,\n        options=options,\n    )\n    resp = yield from _send_request(model, req, env)\n    if isinstance(resp, SpendingDeclined):\n        return\n    log_oracle_response(env, query, req, resp, verbose=enable_logging)\n    if not resp.outputs:\n        return\n    output = resp.outputs[0]\n    answer = dp.Answer(mode, output.content)\n    env.tracer.trace_answer(query.ref, answer)\n    parse = partial(_parse_or_log_and_raise, query=query, env=env)\n    try:\n        element = parse(answer)\n        lpinfo = output.logprobs\n        assert lpinfo is not None\n        ldistr = _compute_value_distribution(vals, lpinfo[0])\n        if not ldistr:\n            assert isinstance(output.content, str)\n            ldistr = {output.content: 0.0}\n        distr = _apply_temperature(ldistr, temperature)\n        if bias is not None:\n            distr = _apply_bias(distr, bias)\n        distr_tup = [(parse(dp.Answer(mode, k)), p) for k, p in distr.items()]\n        meta = ProbInfo(distr_tup)\n        yield dp.Solution(element, meta)\n    except dp.ParseError:\n        return\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.ProbInfo","title":"ProbInfo  <code>dataclass</code>","text":"<p>               Bases: <code>SearchMeta</code></p> <p>Distribution probability, guaranteed to be nonempty and to sum to 1.</p> Source code in <code>src/delphyne/stdlib/queries.py</code> <pre><code>@dataclass\nclass ProbInfo(dp.SearchMeta):\n    \"\"\"\n    Distribution probability, guaranteed to be nonempty and to sum to 1.\n    \"\"\"\n\n    distr: Sequence[tuple[dp.Tracked[Any], float]]\n</code></pre>"},{"location":"reference/stdlib/queries/#models","title":"Models","text":""},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.LLM","title":"LLM","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for an LLM.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>class LLM(ABC):\n    \"\"\"\n    Base class for an LLM.\n    \"\"\"\n\n    def estimate_budget(self, req: LLMRequest) -&gt; Budget:\n        \"\"\"\n        Estimate the budget that is required to process a request.\n        \"\"\"\n        return Budget({NUM_REQUESTS: 1, NUM_COMPLETIONS: req.num_completions})\n\n    @abstractmethod\n    def add_model_defaults(self, req: LLMRequest) -&gt; LLMRequest:\n        \"\"\"\n        Rewrite a request to take model-specific defaults into account.\n\n        A model can carry default values for some of the request fields\n        (e.g. the model name). Thus, requests must be processed through\n        this function right before they are executed or cached.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _send_final_request(self, req: LLMRequest) -&gt; LLMResponse:\n        \"\"\"\n        Core method for processing a request.\n\n        To be overriden by subclasses to implement the core\n        functionality of `send_request`. The latter additionally handles\n        model=specific defaults and caching.\n\n        This function is allowed to raise exceptions (some\n        provider-specific), including `LLMBusyException` for cases where\n        retrials may be warranted.\n        \"\"\"\n        pass\n\n    def stream_request(\n        self, chat: Chat, options: RequestOptions\n    ) -&gt; AsyncIterable[str]:\n        \"\"\"\n        Stream the text answer to a request.\n\n        This is currently not used but could be leveraged by the VSCode\n        extension in the future.\n        \"\"\"\n        raise StreamingNotImplemented()\n\n    @final\n    def send_request(\n        self, req: LLMRequest, cache: \"LLMCache | None\"\n    ) -&gt; LLMResponse:\n        \"\"\"\n        Send a request to a model and return the response.\n\n        This function is allowed to raise exceptions (some\n        provider-specific), including `LLMBusyException` for cases where\n        retrials may be warranted.\n\n        Attributes:\n            req: The request to send.\n            cache: An optional cache to use for the request.\n        \"\"\"\n        if cache is not None:\n            self = CachedModel(self, cache)\n        full_req = self.add_model_defaults(req)\n        return self._send_final_request(full_req)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.LLM.estimate_budget","title":"estimate_budget","text":"<pre><code>estimate_budget(req: LLMRequest) -&gt; Budget\n</code></pre> <p>Estimate the budget that is required to process a request.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>def estimate_budget(self, req: LLMRequest) -&gt; Budget:\n    \"\"\"\n    Estimate the budget that is required to process a request.\n    \"\"\"\n    return Budget({NUM_REQUESTS: 1, NUM_COMPLETIONS: req.num_completions})\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.LLM.add_model_defaults","title":"add_model_defaults  <code>abstractmethod</code>","text":"<pre><code>add_model_defaults(req: LLMRequest) -&gt; LLMRequest\n</code></pre> <p>Rewrite a request to take model-specific defaults into account.</p> <p>A model can carry default values for some of the request fields (e.g. the model name). Thus, requests must be processed through this function right before they are executed or cached.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@abstractmethod\ndef add_model_defaults(self, req: LLMRequest) -&gt; LLMRequest:\n    \"\"\"\n    Rewrite a request to take model-specific defaults into account.\n\n    A model can carry default values for some of the request fields\n    (e.g. the model name). Thus, requests must be processed through\n    this function right before they are executed or cached.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.LLM.stream_request","title":"stream_request","text":"<pre><code>stream_request(chat: Chat, options: RequestOptions) -&gt; AsyncIterable[str]\n</code></pre> <p>Stream the text answer to a request.</p> <p>This is currently not used but could be leveraged by the VSCode extension in the future.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>def stream_request(\n    self, chat: Chat, options: RequestOptions\n) -&gt; AsyncIterable[str]:\n    \"\"\"\n    Stream the text answer to a request.\n\n    This is currently not used but could be leveraged by the VSCode\n    extension in the future.\n    \"\"\"\n    raise StreamingNotImplemented()\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.LLM.send_request","title":"send_request","text":"<pre><code>send_request(req: LLMRequest, cache: LLMCache | None) -&gt; LLMResponse\n</code></pre> <p>Send a request to a model and return the response.</p> <p>This function is allowed to raise exceptions (some provider-specific), including <code>LLMBusyException</code> for cases where retrials may be warranted.</p> <p>Attributes:</p> Name Type Description <code>req</code> <p>The request to send.</p> <code>cache</code> <p>An optional cache to use for the request.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@final\ndef send_request(\n    self, req: LLMRequest, cache: \"LLMCache | None\"\n) -&gt; LLMResponse:\n    \"\"\"\n    Send a request to a model and return the response.\n\n    This function is allowed to raise exceptions (some\n    provider-specific), including `LLMBusyException` for cases where\n    retrials may be warranted.\n\n    Attributes:\n        req: The request to send.\n        cache: An optional cache to use for the request.\n    \"\"\"\n    if cache is not None:\n        self = CachedModel(self, cache)\n    full_req = self.add_model_defaults(req)\n    return self._send_final_request(full_req)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.LLMRequest","title":"LLMRequest  <code>dataclass</code>","text":"<p>An LLM chat completion request.</p> <p>Attributes:</p> Name Type Description <code>chat</code> <code>Chat</code> <p>The chat history.</p> <code>num_completions</code> <code>int</code> <p>The number of completions to generate. Note that most LLM providers only bill input tokens once, regardless of the number of requested completions.</p> <code>options</code> <code>RequestOptions</code> <p>Request options.</p> <code>tools</code> <code>Sequence[Schema]</code> <p>Available tools.</p> <code>structured_output</code> <code>Schema | None</code> <p>Provide a schema to enable structured output, or <code>None</code> for disabling it.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass(frozen=True)\nclass LLMRequest:\n    \"\"\"\n    An LLM chat completion request.\n\n    Attributes:\n        chat: The chat history.\n        num_completions: The number of completions to generate. Note\n            that most LLM providers only bill input tokens once,\n            regardless of the number of requested completions.\n        options: Request options.\n        tools: Available tools.\n        structured_output: Provide a schema to enable structured output,\n            or `None` for disabling it.\n    \"\"\"\n\n    chat: Chat\n    num_completions: int\n    options: RequestOptions\n    tools: Sequence[Schema] = ()\n    structured_output: Schema | None = None\n\n    def __hash__(self) -&gt; int:\n        # LLMRequest needs to be hashable for `CachedModel` to work.\n        return hash(repr((self.chat, self.num_completions, self.options)))\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.LLMResponse","title":"LLMResponse  <code>dataclass</code>","text":"<p>Response to an LLM request.</p> <p>Attributes:</p> Name Type Description <code>outputs</code> <code>Sequence[LLMOutput]</code> <p>Generated completions.</p> <code>budget</code> <code>Budget</code> <p>Budget consumed by the request.</p> <code>log_items</code> <code>list[LLMResponseLogItem]</code> <p>Log items generated while evaluating the request.</p> <code>model_name</code> <code>str | None</code> <p>The name of the model used for the request, which is sometimes more detailed than the model name passed in <code>RequestOptions</code> (e.g., <code>gpt-4.1-mini-2025-04-14</code> vs <code>gpt-4.1-mini</code>).</p> <code>usage_info</code> <code>dict[str, Any] | None</code> <p>Additional usage info metadata, in a provider-specific format.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass\nclass LLMResponse:\n    \"\"\"\n    Response to an LLM request.\n\n    Attributes:\n        outputs: Generated completions.\n        budget: Budget consumed by the request.\n        log_items: Log items generated while evaluating the request.\n        model_name: The name of the model used for the request, which is\n            sometimes more detailed than the model name passed in\n            `RequestOptions` (e.g., `gpt-4.1-mini-2025-04-14` vs\n            `gpt-4.1-mini`).\n        usage_info: Additional usage info metadata, in a\n            provider-specific format.\n    \"\"\"\n\n    outputs: Sequence[LLMOutput]\n    budget: Budget\n    log_items: list[LLMResponseLogItem]\n    model_name: str | None = None\n    usage_info: dict[str, Any] | None = None\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.AbstractTool","title":"AbstractTool","text":"<p>Base class for an LLM tool interface.</p> <p>A new tool interface can be added by defining a dataclass <code>S</code> that inherits <code>AbstractTool[T]</code>, with <code>T</code> the tool output type. Instances of <code>S</code> correspond to tool calls, and an actual tool implementation maps values of type <code>S</code> to values of type <code>T</code>.</p> <p>A JSON tool specification can be extracted through the <code>tool_name</code>, <code>tool_description</code> and <code>tool_answer_type</code> class methods. The <code>render_result</code> method describes how to render the output of a tool implementation, in a way that can be added back as a message in a chat history.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>class AbstractTool[T]:\n    \"\"\"\n    Base class for an LLM tool interface.\n\n    A new tool interface can be added by defining a dataclass `S` that\n    inherits `AbstractTool[T]`, with `T` the tool output type. Instances\n    of `S` correspond to tool calls, and an actual tool implementation\n    maps values of type `S` to values of type `T`.\n\n    A JSON tool specification can be extracted through the\n    `tool_name`, `tool_description` and `tool_answer_type` class\n    methods. The `render_result` method describes how to render the\n    output of a tool implementation, in a way that can be added back as\n    a message in a chat history.\n    \"\"\"\n\n    @classmethod\n    def tool_name(cls) -&gt; str:\n        return tool_name_of_class_name(cls.__name__)\n\n    @classmethod\n    def tool_description(cls) -&gt; str | None:\n        return inspect.getdoc(cls)\n\n    @classmethod\n    def tool_answer_type(cls) -&gt; TypeAnnot[T]:\n        return dpi.first_parameter_of_base_class(cls)\n\n    def render_result(self, res: T) -&gt; str | Structured:\n        if isinstance(res, str):\n            return res\n        ans_type = self.tool_answer_type()\n        return Structured(pydantic_dump(ans_type, res))\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.Chat","title":"Chat","text":"<pre><code>Chat = Sequence[ChatMessage]\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.ChatMessage","title":"ChatMessage","text":"<pre><code>ChatMessage = SystemMessage | UserMessage | AssistantMessage | ToolMessage\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.SystemMessage","title":"SystemMessage  <code>dataclass</code>","text":"Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass(frozen=True)\nclass SystemMessage:\n    role: Literal[\"system\"]  # for deserialization\n    content: str\n\n    def __init__(self, content: str):\n        # to bypass the frozen dataclass check\n        object.__setattr__(self, \"role\", \"system\")\n        object.__setattr__(self, \"content\", content)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.UserMessage","title":"UserMessage  <code>dataclass</code>","text":"Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass(frozen=True)\nclass UserMessage:\n    role: Literal[\"user\"]\n    content: str\n\n    def __init__(self, content: str):\n        object.__setattr__(self, \"role\", \"user\")\n        object.__setattr__(self, \"content\", content)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.AssistantMessage","title":"AssistantMessage  <code>dataclass</code>","text":"Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass(frozen=True)\nclass AssistantMessage:\n    role: Literal[\"assistant\"]\n    answer: Answer  # Note: the mode does not really matter for the LLM.\n\n    def __init__(self, answer: Answer):\n        # to bypass the frozen dataclass check\n        object.__setattr__(self, \"role\", \"assistant\")\n        object.__setattr__(self, \"answer\", answer)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.ToolMessage","title":"ToolMessage  <code>dataclass</code>","text":"Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass(frozen=True)\nclass ToolMessage:\n    role: Literal[\"tool\"]\n    call: ToolCall\n    result: str | Structured\n\n    def __init__(self, call: ToolCall, result: str | Structured):\n        object.__setattr__(self, \"role\", \"tool\")\n        object.__setattr__(self, \"call\", call)\n        object.__setattr__(self, \"result\", result)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.RequestOptions","title":"RequestOptions","text":"<p>               Bases: <code>TypedDict</code></p> <p>LLM request options, inspired from the OpenAI chat API.</p> <p>All values are optional.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>str</code> <p>The name of the model to use for the request.</p> <code>reasoning_effort</code> <code>Literal['minimal', 'low', 'medium', 'high']</code> <p>The reasoning effort to use for the request, when applicable (e.g., for GPT-5 or o3).</p> <code>tool_choice</code> <code>Literal['auto', 'none', 'required']</code> <p>How the model should select which tool (or tools) to use when generating a response. <code>none</code> means the model will not call any tool and instead generates a message. <code>auto</code> means the model can pick between generating a message or calling one or more tools. <code>required</code> means the model must call one or more tools.</p> <code>temperature</code> <code>float</code> <p>The temperature to use for sampling, as a value between 0 and 2.</p> <code>max_completion_tokens</code> <code>int</code> <p>The maximum number of tokens to generate.</p> <code>logprobs</code> <code>bool</code> <p>Whether to return log probabilities for the generated tokens.</p> <code>top_logprobs</code> <code>int</code> <p>The number of top log probabilities to return for each generated token, as an integer between 0 and 20.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>class RequestOptions(typing.TypedDict, total=False):\n    \"\"\"\n    LLM request options, inspired from the OpenAI chat API.\n\n    All values are optional.\n\n    Attributes:\n        model: The name of the model to use for the request.\n        reasoning_effort: The reasoning effort to use for the request,\n            when applicable (e.g., for GPT-5 or o3).\n        tool_choice: How the model should select which tool (or tools)\n            to use when generating a response. `none` means the model\n            will not call any tool and instead generates a message.\n            `auto` means the model can pick between generating a message\n            or calling one or more tools. `required` means the model must\n            call one or more tools.\n        temperature: The temperature to use for sampling, as a value\n            between 0 and 2.\n        max_completion_tokens: The maximum number of tokens to generate.\n        logprobs: Whether to return log probabilities for the generated\n            tokens.\n        top_logprobs: The number of top log probabilities to return for\n            each generated token, as an integer between 0 and 20.\n    \"\"\"\n\n    model: str\n    reasoning_effort: Literal[\"minimal\", \"low\", \"medium\", \"high\"]\n    tool_choice: Literal[\"auto\", \"none\", \"required\"]\n    temperature: float\n    max_completion_tokens: int\n    logprobs: bool\n    top_logprobs: int  # from 0 to 20\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.Schema","title":"Schema  <code>dataclass</code>","text":"<p>The description of a schema for structured output or tool use.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the tool or structured output type.</p> <code>description</code> <code>str | None</code> <p>Optional description.</p> <code>schema</code> <code>Any</code> <p>The JSON schema of the tool or structured output type, typically generated using pydantic's <code>json_schema</code> method.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass(frozen=True)\nclass Schema:\n    \"\"\"\n    The description of a schema for structured output or tool use.\n\n    Attributes:\n        name: Name of the tool or structured output type.\n        description: Optional description.\n        schema: The JSON schema of the tool or structured output type,\n            typically generated using pydantic's `json_schema` method.\n    \"\"\"\n\n    name: str\n    description: str | None\n    schema: Any\n\n    @staticmethod\n    def make(annot: TypeAnnot[Any], /) -&gt; \"Schema\":\n        \"\"\"\n        Build a schema from a Python type annotation\n        \"\"\"\n        if isinstance(annot, type):\n            if issubclass(annot, AbstractTool):\n                name = annot.tool_name()\n                description = annot.tool_description()\n            else:\n                name = tool_name_of_class_name(annot.__name__)\n                # For a dataclass, if no docstring is provided,\n                # `inspect.getdoc` shows its signature (name, attribute\n                # names and types).\n                description = inspect.getdoc(cast(Any, annot))\n        elif isinstance(annot, typing.TypeAliasType):\n            # TODO: we can do better here.\n            name = str(annot)\n            description = None\n        else:\n            # Any other type annotation, such as a union.\n            name = str(annot)\n            description = None\n        adapter = pydantic.TypeAdapter(cast(Any, annot))\n        return Schema(\n            name=name,\n            description=description,\n            schema=adapter.json_schema(),\n        )\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.Schema.make","title":"make  <code>staticmethod</code>","text":"<pre><code>make(annot: TypeAnnot[Any]) -&gt; Schema\n</code></pre> <p>Build a schema from a Python type annotation</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@staticmethod\ndef make(annot: TypeAnnot[Any], /) -&gt; \"Schema\":\n    \"\"\"\n    Build a schema from a Python type annotation\n    \"\"\"\n    if isinstance(annot, type):\n        if issubclass(annot, AbstractTool):\n            name = annot.tool_name()\n            description = annot.tool_description()\n        else:\n            name = tool_name_of_class_name(annot.__name__)\n            # For a dataclass, if no docstring is provided,\n            # `inspect.getdoc` shows its signature (name, attribute\n            # names and types).\n            description = inspect.getdoc(cast(Any, annot))\n    elif isinstance(annot, typing.TypeAliasType):\n        # TODO: we can do better here.\n        name = str(annot)\n        description = None\n    else:\n        # Any other type annotation, such as a union.\n        name = str(annot)\n        description = None\n    adapter = pydantic.TypeAdapter(cast(Any, annot))\n    return Schema(\n        name=name,\n        description=description,\n        schema=adapter.json_schema(),\n    )\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.LLMOutput","title":"LLMOutput  <code>dataclass</code>","text":"<p>A single LLM chat completion.</p> <p>Attributes:</p> Name Type Description <code>content</code> <code>str | Structured</code> <p>The completion content, as a string or as a structured object (if structured output was requested).</p> <code>tool_calls</code> <code>Sequence[ToolCall]</code> <p>A sequence of tool calls made by the model, if any.</p> <code>finish_reason</code> <code>FinishReason</code> <p>The reason why the model stopped generating content.</p> <code>logprobs</code> <code>Sequence[TokenInfo] | None</code> <p>Optional sequence of token log probabilities, if requested.</p> <code>reasoning_content</code> <code>str | None</code> <p>Reasoning chain of thoughts, if provided (the DeepSeek API returns reasoning tokens, while the OpenAI API generally does not).</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass\nclass LLMOutput:\n    \"\"\"\n    A single LLM chat completion.\n\n    Attributes:\n        content: The completion content, as a string or as a structured\n            object (if structured output was requested).\n        tool_calls: A sequence of tool calls made by the model, if any.\n        finish_reason: The reason why the model stopped generating\n            content.\n        logprobs: Optional sequence of token log probabilities, if\n            requested.\n        reasoning_content: Reasoning chain of thoughts, if provided (the\n            DeepSeek API returns reasoning tokens, while the OpenAI API\n            generally does not).\n    \"\"\"\n\n    content: str | Structured\n    tool_calls: Sequence[ToolCall]\n    finish_reason: FinishReason\n    logprobs: Sequence[TokenInfo] | None = None\n    reasoning_content: str | None = None\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.FinishReason","title":"FinishReason","text":"<pre><code>FinishReason = Literal['stop', 'length', 'content_filter', 'tool_calls']\n</code></pre> <p>Reason why the LLM stopped generating content.</p>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.DummyModel","title":"DummyModel  <code>dataclass</code>","text":"<p>               Bases: <code>LLM</code></p> <p>A model that always fails to generate completions.</p> <p>Used by the <code>answer_query</code> command in particular.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass\nclass DummyModel(LLM):\n    \"\"\"\n    A model that always fails to generate completions.\n\n    Used by the `answer_query` command in particular.\n    \"\"\"\n\n    @override\n    def add_model_defaults(self, req: LLMRequest) -&gt; LLMRequest:\n        return req\n\n    @override\n    def _send_final_request(self, req: LLMRequest) -&gt; LLMResponse:\n        budget = Budget({NUM_REQUESTS: req.num_completions})\n        return LLMResponse(\n            outputs=[], budget=budget, log_items=[], model_name=\"&lt;dummy&gt;\"\n        )\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.WithRetry","title":"WithRetry  <code>dataclass</code>","text":"<p>               Bases: <code>LLM</code></p> <p>Retrying with exponential backoff.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass\nclass WithRetry(LLM):\n    \"\"\"\n    Retrying with exponential backoff.\n    \"\"\"\n\n    model: LLM\n    num_attempts: int = 5\n    base_delay_seconds: float = 1.0\n    exponential_factor: float = 2.0\n    delay_noise: float | None = 0.1\n\n    @override\n    def add_model_defaults(self, req: LLMRequest) -&gt; LLMRequest:\n        return self.model.add_model_defaults(req)\n\n    @override\n    def estimate_budget(self, req: LLMRequest) -&gt; Budget:\n        return self.model.estimate_budget(req)\n\n    def retry_delays(self) -&gt; Iterable[float]:\n        import random\n\n        acc = self.base_delay_seconds\n        for _ in range(self.num_attempts):\n            delay = acc\n            if self.delay_noise is not None:\n                delay += random.uniform(0, self.delay_noise)\n            yield delay\n            acc *= self.exponential_factor\n\n    @override\n    def _send_final_request(self, req: LLMRequest) -&gt; LLMResponse:\n        for i, retry_delay in enumerate([*self.retry_delays(), None]):\n            try:\n                ret = self.model.send_request(req, None)\n                if i &gt; 0:\n                    ret.log_items.append(\n                        LLMResponseLogItem(\n                            \"info\", \"successful_retry\", {\"delay\": retry_delay}\n                        )\n                    )\n                return ret\n            except LLMBusyException as e:\n                if retry_delay is None:\n                    raise e\n                else:\n                    time.sleep(retry_delay)\n        assert False\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.CachedModel","title":"CachedModel  <code>dataclass</code>","text":"<p>               Bases: <code>LLM</code></p> <p>Wrap a model to use a given cache.</p> <p>Note</p> <p>The <code>LLM.send_request</code> method has a <code>cache</code> argument that can be used as a replacement for the <code>CachedModel</code> wrapper. In addition, all standard prompting policies use a global request cache (see <code>PolicyEnv</code>) when available. Thus, external users should rarely need to manually wrap models with <code>CachedModel</code>.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass\nclass CachedModel(LLM):\n    \"\"\"\n    Wrap a model to use a given cache.\n\n    !!! note\n        The `LLM.send_request` method has a `cache` argument that can be\n        used as a replacement for the `CachedModel` wrapper. In\n        addition, all standard prompting policies use a global request\n        cache (see `PolicyEnv`) when available. Thus, external users\n        should rarely need to manually wrap models with `CachedModel`.\n    \"\"\"\n\n    model: LLM\n    cache: LLMCache\n\n    def __post_init__(self):\n        @cache(\n            cache_spec=self.cache.spec,\n            hash_arg=_CachedRequest.stable_repr,\n        )\n        def run_request(req: _CachedRequest) -&gt; LLMResponse:\n            base = req.request\n            return self.model.send_request(base, None)\n\n        self.run_request = run_request\n\n    @override\n    def _send_final_request(self, req: LLMRequest) -&gt; LLMResponse:\n        self.cache.num_seen[req] += 1\n        num_seen = self.cache.num_seen[req]\n        return self.run_request(_CachedRequest(req, num_seen))\n\n    @override\n    def estimate_budget(self, req: LLMRequest) -&gt; Budget:\n        return self.model.estimate_budget(req)\n\n    @override\n    def add_model_defaults(self, req: LLMRequest) -&gt; LLMRequest:\n        return self.model.add_model_defaults(req)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.LLMCache","title":"LLMCache  <code>dataclass</code>","text":"<p>A cache for LLM requests.</p> <p>More precisely, what are cached are <code>(r, i)</code> pairs where <code>r</code> is a request and <code>i</code> is the number of times the request has been answered since the model was instantiated. This way, caching works even when a policy samples multiple answers for the same request.</p> <p>Multiple models can share the same cache.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass\nclass LLMCache:\n    \"\"\"\n    A cache for LLM requests.\n\n    More precisely, what are cached are `(r, i)` pairs where `r` is a\n    request and `i` is the number of times the request has been answered\n    since the model was instantiated. This way, caching works even when\n    a policy samples multiple answers for the same request.\n\n    Multiple models can share the same cache.\n    \"\"\"\n\n    spec: CacheSpec\n    num_seen: dict[LLMRequest, int]\n\n    def __init__(self, spec: CacheSpec):\n        self.spec = spec\n        self.num_seen: dict[LLMRequest, int] = defaultdict(lambda: 0)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.Token","title":"Token  <code>dataclass</code>","text":"<p>A token produced by an LLM.</p> <p>Attributes:</p> Name Type Description <code>token</code> <code>str</code> <p>String representation of the token.</p> <code>bytes</code> <code>Sequence[int] | None</code> <p>Optional sequence of integers representing the token's byte encoding.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass\nclass Token:\n    \"\"\"\n    A token produced by an LLM.\n\n    Attributes:\n        token: String representation of the token.\n        bytes: Optional sequence of integers representing the token's\n            byte encoding.\n    \"\"\"\n\n    token: str\n    bytes: Sequence[int] | None\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.TokenInfo","title":"TokenInfo  <code>dataclass</code>","text":"<p>Logprob information for a single token.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass\nclass TokenInfo:\n    \"\"\"\n    Logprob information for a single token.\n    \"\"\"\n\n    token: Token\n    logprob: float\n    top_logprobs: Sequence[tuple[Token, float]] | None\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.ModelPricing","title":"ModelPricing  <code>dataclass</code>","text":"Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass\nclass ModelPricing:\n    dollars_per_input_token: float\n    dollars_per_cached_input_token: float\n    dollars_per_output_token: float\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.LLMResponseLogItem","title":"LLMResponseLogItem  <code>dataclass</code>","text":"Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass\nclass LLMResponseLogItem:\n    severity: Literal[\"info\", \"warning\", \"error\"]\n    message: str\n    metadata: Any = None\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.LLMBusyException","title":"LLMBusyException  <code>dataclass</code>","text":"<p>               Bases: <code>Exception</code></p> <p>This exception should be raised when an LLM call failed due to a timeout or a rate limit error that warrants a retry. In particular, it should not be raised for ill-formed requests (those assumptions should not be caught) or when the LLM gave a bad answer (in which case budget was consumed and should be counted, while errors are added into <code>LLMResponse</code>).</p> <p>See <code>WithRetry</code> for adding retrial logic to LLMs.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>@dataclass\nclass LLMBusyException(Exception):\n    \"\"\"\n    This exception should be raised when an LLM call failed due to a\n    timeout or a rate limit error that warrants a retry. In particular,\n    it should not be raised for ill-formed requests (those assumptions\n    should not be caught) or when the LLM gave a bad answer (in which\n    case budget was consumed and should be counted, while errors are\n    added into `LLMResponse`).\n\n    See `WithRetry` for adding retrial logic to LLMs.\n    \"\"\"\n\n    exn: Exception\n\n    def __str__(self) -&gt; str:\n        return str(self.exn)\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.BudgetCategory","title":"BudgetCategory","text":"<pre><code>BudgetCategory = Literal[\n    \"num_requests\",\n    \"num_completions\",\n    \"input_tokens\",\n    \"cached_input_tokens\",\n    \"output_tokens\",\n    \"price\",\n]\n</code></pre> <p>Standard metrics to measure LLM inference usage.</p>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.budget_entry","title":"budget_entry","text":"<pre><code>budget_entry(category: BudgetCategory, model_class: str | None = None) -&gt; str\n</code></pre> <p>Return a string that can be used as a key in a budget dictionary.</p> Source code in <code>src/delphyne/stdlib/models.py</code> <pre><code>def budget_entry(\n    category: BudgetCategory, model_class: str | None = None\n) -&gt; str:\n    \"\"\"\n    Return a string that can be used as a key in a budget dictionary.\n    \"\"\"\n    res = category\n    if model_class is not None:\n        res = f\"{res}{BUDGET_ENTRY_SEPARATOR}{model_class}\"\n    return res\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.NUM_REQUESTS","title":"NUM_REQUESTS  <code>module-attribute</code>","text":"<pre><code>NUM_REQUESTS = 'num_requests'\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.NUM_COMPLETIONS","title":"NUM_COMPLETIONS  <code>module-attribute</code>","text":"<pre><code>NUM_COMPLETIONS = 'num_completions'\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.NUM_INPUT_TOKENS","title":"NUM_INPUT_TOKENS  <code>module-attribute</code>","text":"<pre><code>NUM_INPUT_TOKENS = 'input_tokens'\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.NUM_CACHED_INPUT_TOKENS","title":"NUM_CACHED_INPUT_TOKENS  <code>module-attribute</code>","text":"<pre><code>NUM_CACHED_INPUT_TOKENS = 'cached_input_tokens'\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.NUM_OUTPUT_TOKENS","title":"NUM_OUTPUT_TOKENS  <code>module-attribute</code>","text":"<pre><code>NUM_OUTPUT_TOKENS = 'output_tokens'\n</code></pre>"},{"location":"reference/stdlib/queries/#delphyne.stdlib.models.DOLLAR_PRICE","title":"DOLLAR_PRICE  <code>module-attribute</code>","text":"<pre><code>DOLLAR_PRICE = 'price'\n</code></pre>"},{"location":"reference/stdlib/streams/","title":"Stream Combinators","text":""},{"location":"reference/stdlib/streams/#search-streams","title":"Search Streams","text":""},{"location":"reference/stdlib/streams/#delphyne.Stream","title":"Stream  <code>dataclass</code>","text":"<p>               Bases: <code>AbstractStream[T]</code></p> <p>A search stream produced by a search policy or prompting policy.</p> <p>This class inherits <code>AbstractStream</code> and supports various methods and combinators for assembling streams, while guaranteeing adherence to the search stream protocol.</p> <p>Attributes:</p> Name Type Description <code>_generate</code> <code>Callable[[], StreamGen[T]]</code> <p>A zeroary function that produces a stream generator.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>@dataclass(frozen=True)\nclass Stream[T](dp.AbstractStream[T]):\n    \"\"\"\n    A search stream produced by a search policy or prompting policy.\n\n    This class inherits `AbstractStream` and supports various methods\n    and combinators for assembling streams, while guaranteeing adherence\n    to the [search stream protocol][delphyne.core.streams].\n\n    Attributes:\n        _generate: A zeroary function that produces a stream generator.\n    \"\"\"\n\n    _generate: Callable[[], dp.StreamGen[T]]\n\n    @override\n    def gen(self) -&gt; dp.StreamGen[T]:\n        return self._generate()\n\n    ## Collecting all elements\n\n    def collect(\n        self,\n        budget: dp.BudgetLimit | None = None,\n        num_generated: int | None = None,\n    ) -&gt; tuple[Sequence[dp.Solution[T]], dp.Budget]:\n        \"\"\"\n        Exhaust a stream and collect all generated solutions.\n\n        Attributes:\n            budget (optional): Budget limit (see `with_budget` method).\n            num_generated (optional): Number of solutions to generate\n                (see `take` method).\n\n        Returns:\n            A sequence of solutions along with the total spent budget.\n\n        !!! warning\n            This function must only be used at top-level and *not*\n            within the definition of a search stream generator (in which\n            case the consumed resources won't be accounted for in the\n            parent stream). See `Stream.all`.\n        \"\"\"\n        if budget is not None:\n            self = self.with_budget(budget)\n        if num_generated is not None:\n            self = self.take(num_generated)\n        return stream_collect(self.gen())\n\n    ## Transforming the stream\n\n    def with_budget(self, budget: dp.BudgetLimit):\n        \"\"\"\n        Return an identical stream that denies all spending requests\n        once a given amount of budget is spent.\n\n        **Guarantees**: if all budget spending over-estimates passed to\n        `spend_on` are accurate, the given budget limit is rigorously\n        respected. If not, the spent amount may exceed the budget by an\n        amount of `Delta * N`, where `Delta` is the maximum estimation\n        error and `N` is the concurrency level of the stream (1 if\n        `Stream.parallel` is never used).\n        \"\"\"\n        return Stream(lambda: stream_with_budget(self.gen(), budget))\n\n    def take(self, num_generated: int, strict: bool = True):\n        \"\"\"\n        Return an identical stream that terminates once a given number\n        of solution is generated. If `strict` is set to `False`, more\n        solutions can be returned, provided that no additional budget\n        must be spent for generating them.\n        \"\"\"\n        return Stream(lambda: stream_take(self.gen(), num_generated, strict))\n\n    def loop(\n        self, n: int | None = None, *, stop_on_reject: bool = True\n    ) -&gt; \"Stream[T]\":\n        \"\"\"\n        Repeatedly execute a stream.\n\n        Arguments:\n            n (optional): Number of times to repeat the stream. By\n                default, the stream is repeated indefinitely.\n            stop_on_reject: If set to `True` (default), the resulting\n                stream stops after the first iteration during which no\n                spending request was granted. This guarantees\n                termination, even if `n` is `None`.\n        \"\"\"\n        it = itertools.count() if n is None else range(n)\n        return Stream(\n            lambda: stream_sequence(\n                (self.gen for _ in it), stop_on_reject=stop_on_reject\n            )\n        )\n\n    def bind[U](\n        self, f: Callable[[dp.Solution[T]], dp.StreamGen[U]]\n    ) -&gt; \"Stream[U]\":\n        \"\"\"\n        Apply a function to all generated solutions of a stream and\n        concatenate the resulting streams.\n\n        This is analogous to the `concat_map` funtion on lists:\n\n            def concat_map(f, xs):\n                return [y for x in xs for y in f(x)]\n        \"\"\"\n        return Stream(lambda: stream_bind(self.gen(), f))\n\n    ## Monadic Methods\n\n    def first(self) -&gt; dp.StreamContext[dp.Solution[T] | None]:\n        \"\"\"\n        Obtain the first solution from a stream, or return `None` if the\n        stream terminates without yielding any solution.\n        \"\"\"\n        return stream_first(self.gen())\n\n    def all(self) -&gt; dp.StreamContext[Sequence[dp.Solution[T]]]:\n        \"\"\"\n        Obtain all solutions from a stream.\n        \"\"\"\n        return stream_all(self.gen())\n\n    def next(\n        self,\n    ) -&gt; dp.StreamContext[\n        \"tuple[Sequence[dp.Solution[T]], dp.Budget, Stream[T] | None]\"\n    ]:\n        \"\"\"\n        Make an atomic attempt to obtain a solution from the stream,\n        stopping right before a second spending request is made.\n\n        Return a sequence of generated solutions, the total spent\n        budget, and the remaining stream, if any.\n        \"\"\"\n        gen, budg, rest = yield from stream_next(self.gen())\n        new_rest = None if rest is None else Stream(lambda: rest)\n        return gen, budg, new_rest\n\n    ## Static Methods\n\n    @staticmethod\n    def sequence[U](\n        streams: Iterable[\"Stream[U]\"], *, stop_on_reject: bool = True\n    ) -&gt; \"Stream[U]\":\n        \"\"\"\n        Concatenate all streams from a possibly infinite collection.\n\n        If `stop_on_reject` is set to `True` (default), then the\n        resulting stream is stopped as soon as one stream in the\n        collection terminates without a single spending request being\n        granted. This allows guaranteeing termination, even if an\n        infinite collection of streams is passed.\n        \"\"\"\n        return Stream(\n            lambda: stream_sequence(\n                (s.gen for s in streams), stop_on_reject=stop_on_reject\n            )\n        )\n\n    @staticmethod\n    def parallel[U](streams: Sequence[\"Stream[U]\"]) -&gt; \"Stream[U]\":\n        \"\"\"\n        Run all streams of a sequence in separate threads, possibly\n        interleaving the resulting solutions.\n        \"\"\"\n        return Stream(lambda: stream_parallel([s.gen() for s in streams]))\n\n    @staticmethod\n    def or_else[U](main: \"Stream[U]\", fallback: \"Stream[U]\") -&gt; \"Stream[U]\":\n        \"\"\"\n        Run the `main` stream and, if it does not yield any solution,\n        run the `fallback` stream.\n        \"\"\"\n        return Stream(lambda: stream_or_else(main.gen, fallback.gen))\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.Stream.collect","title":"collect","text":"<pre><code>collect(\n    budget: BudgetLimit | None = None, num_generated: int | None = None\n) -&gt; tuple[Sequence[Solution[T]], Budget]\n</code></pre> <p>Exhaust a stream and collect all generated solutions.</p> <p>Attributes:</p> Name Type Description <code>budget</code> <code>optional</code> <p>Budget limit (see <code>with_budget</code> method).</p> <code>num_generated</code> <code>optional</code> <p>Number of solutions to generate (see <code>take</code> method).</p> <p>Returns:</p> Type Description <code>tuple[Sequence[Solution[T]], Budget]</code> <p>A sequence of solutions along with the total spent budget.</p> <p>Warning</p> <p>This function must only be used at top-level and not within the definition of a search stream generator (in which case the consumed resources won't be accounted for in the parent stream). See <code>Stream.all</code>.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>def collect(\n    self,\n    budget: dp.BudgetLimit | None = None,\n    num_generated: int | None = None,\n) -&gt; tuple[Sequence[dp.Solution[T]], dp.Budget]:\n    \"\"\"\n    Exhaust a stream and collect all generated solutions.\n\n    Attributes:\n        budget (optional): Budget limit (see `with_budget` method).\n        num_generated (optional): Number of solutions to generate\n            (see `take` method).\n\n    Returns:\n        A sequence of solutions along with the total spent budget.\n\n    !!! warning\n        This function must only be used at top-level and *not*\n        within the definition of a search stream generator (in which\n        case the consumed resources won't be accounted for in the\n        parent stream). See `Stream.all`.\n    \"\"\"\n    if budget is not None:\n        self = self.with_budget(budget)\n    if num_generated is not None:\n        self = self.take(num_generated)\n    return stream_collect(self.gen())\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.Stream.with_budget","title":"with_budget","text":"<pre><code>with_budget(budget: BudgetLimit)\n</code></pre> <p>Return an identical stream that denies all spending requests once a given amount of budget is spent.</p> <p>Guarantees: if all budget spending over-estimates passed to <code>spend_on</code> are accurate, the given budget limit is rigorously respected. If not, the spent amount may exceed the budget by an amount of <code>Delta * N</code>, where <code>Delta</code> is the maximum estimation error and <code>N</code> is the concurrency level of the stream (1 if <code>Stream.parallel</code> is never used).</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>def with_budget(self, budget: dp.BudgetLimit):\n    \"\"\"\n    Return an identical stream that denies all spending requests\n    once a given amount of budget is spent.\n\n    **Guarantees**: if all budget spending over-estimates passed to\n    `spend_on` are accurate, the given budget limit is rigorously\n    respected. If not, the spent amount may exceed the budget by an\n    amount of `Delta * N`, where `Delta` is the maximum estimation\n    error and `N` is the concurrency level of the stream (1 if\n    `Stream.parallel` is never used).\n    \"\"\"\n    return Stream(lambda: stream_with_budget(self.gen(), budget))\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.Stream.take","title":"take","text":"<pre><code>take(num_generated: int, strict: bool = True)\n</code></pre> <p>Return an identical stream that terminates once a given number of solution is generated. If <code>strict</code> is set to <code>False</code>, more solutions can be returned, provided that no additional budget must be spent for generating them.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>def take(self, num_generated: int, strict: bool = True):\n    \"\"\"\n    Return an identical stream that terminates once a given number\n    of solution is generated. If `strict` is set to `False`, more\n    solutions can be returned, provided that no additional budget\n    must be spent for generating them.\n    \"\"\"\n    return Stream(lambda: stream_take(self.gen(), num_generated, strict))\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.Stream.loop","title":"loop","text":"<pre><code>loop(n: int | None = None, *, stop_on_reject: bool = True) -&gt; Stream[T]\n</code></pre> <p>Repeatedly execute a stream.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>optional</code> <p>Number of times to repeat the stream. By default, the stream is repeated indefinitely.</p> <code>None</code> <code>stop_on_reject</code> <code>bool</code> <p>If set to <code>True</code> (default), the resulting stream stops after the first iteration during which no spending request was granted. This guarantees termination, even if <code>n</code> is <code>None</code>.</p> <code>True</code> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>def loop(\n    self, n: int | None = None, *, stop_on_reject: bool = True\n) -&gt; \"Stream[T]\":\n    \"\"\"\n    Repeatedly execute a stream.\n\n    Arguments:\n        n (optional): Number of times to repeat the stream. By\n            default, the stream is repeated indefinitely.\n        stop_on_reject: If set to `True` (default), the resulting\n            stream stops after the first iteration during which no\n            spending request was granted. This guarantees\n            termination, even if `n` is `None`.\n    \"\"\"\n    it = itertools.count() if n is None else range(n)\n    return Stream(\n        lambda: stream_sequence(\n            (self.gen for _ in it), stop_on_reject=stop_on_reject\n        )\n    )\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.Stream.bind","title":"bind","text":"<pre><code>bind(f: Callable[[Solution[T]], StreamGen[U]]) -&gt; Stream[U]\n</code></pre> <p>Apply a function to all generated solutions of a stream and concatenate the resulting streams.</p> <p>This is analogous to the <code>concat_map</code> funtion on lists:</p> <pre><code>def concat_map(f, xs):\n    return [y for x in xs for y in f(x)]\n</code></pre> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>def bind[U](\n    self, f: Callable[[dp.Solution[T]], dp.StreamGen[U]]\n) -&gt; \"Stream[U]\":\n    \"\"\"\n    Apply a function to all generated solutions of a stream and\n    concatenate the resulting streams.\n\n    This is analogous to the `concat_map` funtion on lists:\n\n        def concat_map(f, xs):\n            return [y for x in xs for y in f(x)]\n    \"\"\"\n    return Stream(lambda: stream_bind(self.gen(), f))\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.Stream.first","title":"first","text":"<pre><code>first() -&gt; StreamContext[Solution[T] | None]\n</code></pre> <p>Obtain the first solution from a stream, or return <code>None</code> if the stream terminates without yielding any solution.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>def first(self) -&gt; dp.StreamContext[dp.Solution[T] | None]:\n    \"\"\"\n    Obtain the first solution from a stream, or return `None` if the\n    stream terminates without yielding any solution.\n    \"\"\"\n    return stream_first(self.gen())\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.Stream.all","title":"all","text":"<pre><code>all() -&gt; StreamContext[Sequence[Solution[T]]]\n</code></pre> <p>Obtain all solutions from a stream.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>def all(self) -&gt; dp.StreamContext[Sequence[dp.Solution[T]]]:\n    \"\"\"\n    Obtain all solutions from a stream.\n    \"\"\"\n    return stream_all(self.gen())\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.Stream.next","title":"next","text":"<pre><code>next() -&gt; StreamContext[tuple[Sequence[Solution[T]], Budget, Stream[T] | None]]\n</code></pre> <p>Make an atomic attempt to obtain a solution from the stream, stopping right before a second spending request is made.</p> <p>Return a sequence of generated solutions, the total spent budget, and the remaining stream, if any.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>def next(\n    self,\n) -&gt; dp.StreamContext[\n    \"tuple[Sequence[dp.Solution[T]], dp.Budget, Stream[T] | None]\"\n]:\n    \"\"\"\n    Make an atomic attempt to obtain a solution from the stream,\n    stopping right before a second spending request is made.\n\n    Return a sequence of generated solutions, the total spent\n    budget, and the remaining stream, if any.\n    \"\"\"\n    gen, budg, rest = yield from stream_next(self.gen())\n    new_rest = None if rest is None else Stream(lambda: rest)\n    return gen, budg, new_rest\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.Stream.sequence","title":"sequence  <code>staticmethod</code>","text":"<pre><code>sequence(streams: Iterable[Stream[U]], *, stop_on_reject: bool = True) -&gt; Stream[U]\n</code></pre> <p>Concatenate all streams from a possibly infinite collection.</p> <p>If <code>stop_on_reject</code> is set to <code>True</code> (default), then the resulting stream is stopped as soon as one stream in the collection terminates without a single spending request being granted. This allows guaranteeing termination, even if an infinite collection of streams is passed.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>@staticmethod\ndef sequence[U](\n    streams: Iterable[\"Stream[U]\"], *, stop_on_reject: bool = True\n) -&gt; \"Stream[U]\":\n    \"\"\"\n    Concatenate all streams from a possibly infinite collection.\n\n    If `stop_on_reject` is set to `True` (default), then the\n    resulting stream is stopped as soon as one stream in the\n    collection terminates without a single spending request being\n    granted. This allows guaranteeing termination, even if an\n    infinite collection of streams is passed.\n    \"\"\"\n    return Stream(\n        lambda: stream_sequence(\n            (s.gen for s in streams), stop_on_reject=stop_on_reject\n        )\n    )\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.Stream.parallel","title":"parallel  <code>staticmethod</code>","text":"<pre><code>parallel(streams: Sequence[Stream[U]]) -&gt; Stream[U]\n</code></pre> <p>Run all streams of a sequence in separate threads, possibly interleaving the resulting solutions.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>@staticmethod\ndef parallel[U](streams: Sequence[\"Stream[U]\"]) -&gt; \"Stream[U]\":\n    \"\"\"\n    Run all streams of a sequence in separate threads, possibly\n    interleaving the resulting solutions.\n    \"\"\"\n    return Stream(lambda: stream_parallel([s.gen() for s in streams]))\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.Stream.or_else","title":"or_else  <code>staticmethod</code>","text":"<pre><code>or_else(main: Stream[U], fallback: Stream[U]) -&gt; Stream[U]\n</code></pre> <p>Run the <code>main</code> stream and, if it does not yield any solution, run the <code>fallback</code> stream.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>@staticmethod\ndef or_else[U](main: \"Stream[U]\", fallback: \"Stream[U]\") -&gt; \"Stream[U]\":\n    \"\"\"\n    Run the `main` stream and, if it does not yield any solution,\n    run the `fallback` stream.\n    \"\"\"\n    return Stream(lambda: stream_or_else(main.gen, fallback.gen))\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.spend_on","title":"spend_on","text":"<pre><code>spend_on(\n    f: Callable[[], tuple[T, Budget]], /, estimate: Budget\n) -&gt; StreamContext[T | SpendingDeclined]\n</code></pre> <p>Perform a computation that requires spending some resources.</p> <p>Attributes:</p> Name Type Description <code>f</code> <p>A zeroary function that returns the computation result, along with the budget spent on the computation.</p> <code>estimate</code> <p>An over-estimate of the budget that is consumed by the computation. This estimate is allowed to be inaccurate. See <code>Stream.with_budget</code> for the provided guarantees.</p> <p>Returns:</p> Type Description <code>StreamContext[T | SpendingDeclined]</code> <p>In a stream context, the value returned by the computation or an</p> <code>StreamContext[T | SpendingDeclined]</code> <p>instance of <code>SpendingDeclined</code> if the spending request was</p> <code>StreamContext[T | SpendingDeclined]</code> <p>declined.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>def spend_on[T](\n    f: Callable[[], tuple[T, dp.Budget]], /, estimate: dp.Budget\n) -&gt; dp.StreamContext[T | SpendingDeclined]:\n    \"\"\"\n    Perform a computation that requires spending some resources.\n\n    Attributes:\n        f: A zeroary function that returns the computation result, along\n            with the budget spent on the computation.\n        estimate: An over-estimate of the budget that is consumed by the\n            computation. This estimate is allowed to be inaccurate. See\n            `Stream.with_budget` for the provided guarantees.\n\n    Returns:\n        In a stream context, the value returned by the computation or an\n        instance of `SpendingDeclined` if the spending request was\n        declined.\n    \"\"\"\n    barrier = Barrier(estimate)\n    yield barrier\n    if barrier.allow:\n        value, spent = f()\n        yield Spent(budget=spent, barrier_id=barrier.id)\n        return value\n    else:\n        yield Spent(budget=dp.Budget.zero(), barrier_id=barrier.id)\n        return SpendingDeclined()\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.SpendingDeclined","title":"SpendingDeclined  <code>dataclass</code>","text":"<p>Sentinel value indicating that a spending request was declined.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>@dataclass(frozen=True)\nclass SpendingDeclined:\n    \"\"\"\n    Sentinel value indicating that a spending request was declined.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/stdlib/streams/#stream-transformers","title":"Stream Transformers","text":""},{"location":"reference/stdlib/streams/#delphyne.StreamTransformer","title":"StreamTransformer  <code>dataclass</code>","text":"<p>Wrapper for a function that maps a stream to another one, possibly depending on the global policy environment. Can be composed with policies, search policies and other stream transformers using the <code>@</code> operator.</p> <p>Attributes:</p> Name Type Description <code>trans</code> <code>_StreamTransformerFn</code> <p>The wrapped stream transformer function.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>@dataclass\nclass StreamTransformer:\n    \"\"\"\n    Wrapper for a function that maps a stream to another one, possibly\n    depending on the global policy environment. Can be composed with\n    policies, search policies and other stream transformers using the\n    `@` operator.\n\n    Attributes:\n        trans: The wrapped stream transformer function.\n    \"\"\"\n\n    trans: _StreamTransformerFn\n\n    def __call__[T](\n        self,\n        stream: Stream[T],\n        env: PolicyEnv,\n    ) -&gt; Stream[T]:\n        return Stream(lambda: self.trans(stream, env))\n\n    def __matmul__(self, other: \"StreamTransformer\") -&gt; \"StreamTransformer\":\n        \"\"\"\n        Compose this transformer with another one.\n        \"\"\"\n        if not isinstance(other, StreamTransformer):  # pyright: ignore[reportUnnecessaryIsInstance]\n            return NotImplemented\n\n        def transformer[T](\n            stream: Stream[T],\n            env: PolicyEnv,\n        ) -&gt; dp.StreamGen[T]:\n            return self(other(stream, env), env).gen()\n\n        return StreamTransformer(transformer)\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.StreamTransformer.__matmul__","title":"__matmul__","text":"<pre><code>__matmul__(other: StreamTransformer) -&gt; StreamTransformer\n</code></pre> <p>Compose this transformer with another one.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>def __matmul__(self, other: \"StreamTransformer\") -&gt; \"StreamTransformer\":\n    \"\"\"\n    Compose this transformer with another one.\n    \"\"\"\n    if not isinstance(other, StreamTransformer):  # pyright: ignore[reportUnnecessaryIsInstance]\n        return NotImplemented\n\n    def transformer[T](\n        stream: Stream[T],\n        env: PolicyEnv,\n    ) -&gt; dp.StreamGen[T]:\n        return self(other(stream, env), env).gen()\n\n    return StreamTransformer(transformer)\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.take","title":"take","text":"<pre><code>take(stream: Stream[T], env: PolicyEnv, num_generated: int, strict: bool = True)\n</code></pre> <p>Stream transformer version of <code>Stream.take</code>.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>@stream_transformer\ndef take[T](\n    stream: Stream[T],\n    env: PolicyEnv,\n    num_generated: int,\n    strict: bool = True,\n):\n    \"\"\"\n    Stream transformer version of `Stream.take`.\n    \"\"\"\n    return stream_take(stream.gen(), num_generated, strict)\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.with_budget","title":"with_budget","text":"<pre><code>with_budget(stream: Stream[T], env: PolicyEnv, budget: BudgetLimit)\n</code></pre> <p>Stream transformer version of <code>Stream.with_budget</code>.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>@stream_transformer\ndef with_budget[T](\n    stream: Stream[T],\n    env: PolicyEnv,\n    budget: dp.BudgetLimit,\n):\n    \"\"\"\n    Stream transformer version of `Stream.with_budget`.\n    \"\"\"\n    return stream_with_budget(stream.gen(), budget)\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.loop","title":"loop","text":"<pre><code>loop(\n    stream: Stream[T],\n    env: PolicyEnv,\n    n: int | None = None,\n    *,\n    stop_on_reject: bool = True,\n) -&gt; StreamGen[T]\n</code></pre> <p>Stream transformer that repeatedly respawns the underlying stream, up to an (optional) limit.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>@stream_transformer\ndef loop[T](\n    stream: Stream[T],\n    env: PolicyEnv,\n    n: int | None = None,\n    *,\n    stop_on_reject: bool = True,\n) -&gt; dp.StreamGen[T]:\n    \"\"\"\n    Stream transformer that repeatedly respawns the underlying stream,\n    up to an (optional) limit.\n    \"\"\"\n\n    return stream.loop(n, stop_on_reject=stop_on_reject).gen()\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.stream_transformer","title":"stream_transformer","text":"<pre><code>stream_transformer(\n    f: _ParametricStreamTransformerFn[A],\n) -&gt; Callable[A, StreamTransformer]\n</code></pre> <p>Convenience decorator for creating parametric stream transformers (i.e., functions that return stream transformers).</p> <p>See <code>take</code> for an example.</p> <p>Attributes:</p> Name Type Description <code>f</code> <p>A function that takes a stream, a policy environment, and additional parameters, and returns a stream generator.</p> <p>Returns:</p> Type Description <code>Callable[A, StreamTransformer]</code> <p>A function that takes the additional parameters of <code>f</code> and</p> <code>Callable[A, StreamTransformer]</code> <p>returns a <code>StreamTransformer</code> object.</p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>def stream_transformer[**A](\n    f: _ParametricStreamTransformerFn[A],\n) -&gt; Callable[A, StreamTransformer]:\n    \"\"\"\n    Convenience decorator for creating parametric stream transformers\n    (i.e., functions that return stream transformers).\n\n    See `take` for an example.\n\n    Attributes:\n        f: A function that takes a stream, a policy environment, and\n            additional parameters, and returns a stream generator.\n\n    Returns:\n        A function that takes the additional parameters of `f` and\n        returns a `StreamTransformer` object.\n    \"\"\"\n\n    def parametric(*args: A.args, **kwargs: A.kwargs) -&gt; StreamTransformer:\n        def transformer[T](\n            stream: Stream[T],\n            env: PolicyEnv,\n        ) -&gt; dp.StreamGen[T]:\n            return f(stream, env, *args, **kwargs)\n\n        return StreamTransformer(transformer)\n\n    return parametric\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.stdlib.streams._StreamTransformerFn","title":"_StreamTransformerFn","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>class _StreamTransformerFn(Protocol):\n    def __call__[T](\n        self,\n        stream: Stream[T],\n        env: PolicyEnv,\n    ) -&gt; dp.StreamGen[T]: ...\n</code></pre>"},{"location":"reference/stdlib/streams/#delphyne.stdlib.streams._ParametricStreamTransformerFn","title":"_ParametricStreamTransformerFn","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/delphyne/stdlib/streams.py</code> <pre><code>class _ParametricStreamTransformerFn[**A](Protocol):\n    def __call__[T](\n        self,\n        stream: Stream[T],\n        env: PolicyEnv,\n        *args: A.args,\n        **kwargs: A.kwargs,\n    ) -&gt; dp.StreamGen[T]: ...\n</code></pre>"},{"location":"reference/strategies/misc/","title":"Miscellaneous","text":""},{"location":"reference/strategies/misc/#delphyne.Error","title":"Error  <code>dataclass</code>","text":"<p>Base class for rich error messages that can be created within strategies, while providing a chance to generate meaningful feedback. Parser errors are a particular case (<code>ParseError</code>).</p> <p>Attributes:</p> Name Type Description <code>label</code> <code>str | None</code> <p>A concise label for the error.</p> <code>description</code> <code>str | None</code> <p>A more detailed description of the error.</p> <code>meta</code> <code>Any | None</code> <p>Additional metadata that can be used to provide more context about the error.</p> Source code in <code>src/delphyne/core/errors.py</code> <pre><code>@dataclass\nclass Error:\n    \"\"\"\n    Base class for rich error messages that can be created within\n    strategies, while providing a chance to generate meaningful\n    feedback. Parser errors are a particular case (`ParseError`).\n\n    Attributes:\n        label: A concise label for the error.\n        description: A more detailed description of the error.\n        meta: Additional metadata that can be used to provide more\n            context about the error.\n    \"\"\"\n\n    label: str | None = None\n    description: str | None = None\n    meta: Any | None = None\n\n    def __init__(\n        self,\n        *,\n        label: str | None = None,\n        description: str | None = None,\n        meta: Any | None = None,\n    ):\n        if label is not None:\n            assert label\n            # Should we prevent some characters in labels?\n            # assert not any(c in label for c in [\" \", \"\\n\", \"\\t\"])\n        # assert label or description\n        self.label = label\n        self.description = description\n        self.meta = meta\n\n    def __str__(self):\n        elts: list[str] = []\n        if self.label:\n            elts.append(self.label)\n        if self.description:\n            elts.append(self.description)\n        if self.meta:\n            elts.append(pprint.pformat(self.meta))\n        return \"\\n\\n\".join(elts)\n</code></pre>"},{"location":"reference/strategies/queries/","title":"Queries and Chats","text":""},{"location":"reference/strategies/queries/#abstract-queries","title":"Abstract Queries","text":""},{"location":"reference/strategies/queries/#delphyne.AbstractQuery","title":"AbstractQuery","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract Class for Delphyne Queries.</p> <p>The type parameter <code>T</code> indicates the type of parsed query answers.</p> <p>A more featureful subclass is provided in the standard library (<code>Query</code>), which uses reflection for convenience.</p> <p>Answer Modes</p> <p>Queries are allowed to define multiple answer modes (<code>AnswerMode</code>), each mode being possibly associated with different settings and with a different parser.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>class AbstractQuery[T](ABC):\n    \"\"\"\n    Abstract Class for Delphyne Queries.\n\n    The type parameter `T` indicates the type of parsed query answers.\n\n    A more featureful subclass is provided in the standard library\n    (`Query`), which uses reflection for convenience.\n\n    !!! info \"Answer Modes\"\n        Queries are allowed to define multiple answer modes\n        (`AnswerMode`), each mode being possibly associated with\n        different settings and with a different parser.\n    \"\"\"\n\n    @abstractmethod\n    def generate_prompt(\n        self,\n        *,\n        kind: Literal[\"system\", \"instance\", \"feedback\"] | str,\n        mode: AnswerMode,\n        params: dict[str, object],\n        extra_args: dict[str, object] | None = None,\n        env: AbstractTemplatesManager | None,\n    ) -&gt; str:\n        \"\"\"\n        Generate a prompt message for the query.\n\n        Args:\n            kind: Kind of prompt to generate. Standard prompt kinds are\n                \"system\", \"instance\", or \"feedback\" but others can be\n                supported (within or outside the standard library).\n            mode: Answer mode selected for the query.\n            params: Query hyperparameters.\n            extra_args: Additional arguments to pass to the template.\n            env: Template manager used to load Jinja templates.\n                Exceptions may be raised when it is needed but not\n                provided.\n        \"\"\"\n        pass\n\n    def serialize_args(self) -&gt; dict[str, object]:\n        \"\"\"\n        Serialize the query arguments as a dictionary of JSON values.\n        \"\"\"\n        return cast(dict[str, object], ty.pydantic_dump(type(self), self))\n\n    @classmethod\n    def parse_instance(cls, args: dict[str, object]) -&gt; Self:\n        \"\"\"\n        Parse a query instance from a dictionary of serialized\n        arguments.\n        \"\"\"\n        return ty.pydantic_load(cls, args)\n\n    @abstractmethod\n    def answer_type(self) -&gt; ty.TypeAnnot[T] | ty.NoTypeInfo:\n        \"\"\"\n        Return the answer type for the query, or `NoTypeInfo()` if this\n        information is not available.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def query_modes(self) -&gt; Sequence[AnswerMode]:\n        \"\"\"\n        Return the sequence of available answer modes.\n        \"\"\"\n        pass\n\n    def query_prefix(self) -&gt; AnswerPrefix | None:\n        \"\"\"\n        Return the chat history featured in the query, if any.\n\n        This is useful to emulate conversational agents by issuing a\n        query repeatedly, passing it the whole, updated conversation\n        history every time (see `interact`).\n        \"\"\"\n        return None\n\n    def query_settings(self, mode: AnswerMode) -&gt; QuerySettings:\n        \"\"\"\n        Return the settings associated with the query.\n        \"\"\"\n        return QuerySettings()\n\n    @final\n    def query_name(self) -&gt; str:\n        \"\"\"\n        Return the name of the query (i.e., the name of the associated\n        class).\n        \"\"\"\n        return self.__class__.__name__\n\n    def default_tags(self) -&gt; Sequence[str]:\n        \"\"\"\n        Return a default set of tags to associate with spaces induced by\n        the query.\n\n        These tags can be overriden (see `SpaceBuilder`).\n        \"\"\"\n        return [self.query_name()]\n\n    @abstractmethod\n    def parse_answer(self, answer: Answer) -&gt; T | ParseError:\n        \"\"\"\n        Parse a query answer.\n        \"\"\"\n        pass\n\n    def finite_answer_set(self) -&gt; Sequence[Answer] | None:\n        \"\"\"\n        For queries with a finite set of possible answers, return this\n        set. Otherwise, return `None`.\n\n        Demonstration tests can use a special `#&lt;val&gt;` hint to select\n        the first answer with content `&lt;val&gt;` from this set.\n\n        Example uses include classification queries (see `classify`)\n        where a distribution of answers is extracted from LLM logits,\n        flag queries...\n        \"\"\"\n        return None\n\n    def default_answer(self) -&gt; Answer | None:\n        \"\"\"\n        Return a default answer for the query, if any.\n\n        Default answers are used to answer queries in demonstration\n        tests when no answer is provided in the `queries` section and no\n        applicable hint is available.\n        \"\"\"\n        return None\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.generate_prompt","title":"generate_prompt  <code>abstractmethod</code>","text":"<pre><code>generate_prompt(\n    *,\n    kind: Literal[\"system\", \"instance\", \"feedback\"] | str,\n    mode: AnswerMode,\n    params: dict[str, object],\n    extra_args: dict[str, object] | None = None,\n    env: AbstractTemplatesManager | None,\n) -&gt; str\n</code></pre> <p>Generate a prompt message for the query.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>Literal['system', 'instance', 'feedback'] | str</code> <p>Kind of prompt to generate. Standard prompt kinds are \"system\", \"instance\", or \"feedback\" but others can be supported (within or outside the standard library).</p> required <code>mode</code> <code>AnswerMode</code> <p>Answer mode selected for the query.</p> required <code>params</code> <code>dict[str, object]</code> <p>Query hyperparameters.</p> required <code>extra_args</code> <code>dict[str, object] | None</code> <p>Additional arguments to pass to the template.</p> <code>None</code> <code>env</code> <code>AbstractTemplatesManager | None</code> <p>Template manager used to load Jinja templates. Exceptions may be raised when it is needed but not provided.</p> required Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@abstractmethod\ndef generate_prompt(\n    self,\n    *,\n    kind: Literal[\"system\", \"instance\", \"feedback\"] | str,\n    mode: AnswerMode,\n    params: dict[str, object],\n    extra_args: dict[str, object] | None = None,\n    env: AbstractTemplatesManager | None,\n) -&gt; str:\n    \"\"\"\n    Generate a prompt message for the query.\n\n    Args:\n        kind: Kind of prompt to generate. Standard prompt kinds are\n            \"system\", \"instance\", or \"feedback\" but others can be\n            supported (within or outside the standard library).\n        mode: Answer mode selected for the query.\n        params: Query hyperparameters.\n        extra_args: Additional arguments to pass to the template.\n        env: Template manager used to load Jinja templates.\n            Exceptions may be raised when it is needed but not\n            provided.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.serialize_args","title":"serialize_args","text":"<pre><code>serialize_args() -&gt; dict[str, object]\n</code></pre> <p>Serialize the query arguments as a dictionary of JSON values.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>def serialize_args(self) -&gt; dict[str, object]:\n    \"\"\"\n    Serialize the query arguments as a dictionary of JSON values.\n    \"\"\"\n    return cast(dict[str, object], ty.pydantic_dump(type(self), self))\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.parse_instance","title":"parse_instance  <code>classmethod</code>","text":"<pre><code>parse_instance(args: dict[str, object]) -&gt; Self\n</code></pre> <p>Parse a query instance from a dictionary of serialized arguments.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@classmethod\ndef parse_instance(cls, args: dict[str, object]) -&gt; Self:\n    \"\"\"\n    Parse a query instance from a dictionary of serialized\n    arguments.\n    \"\"\"\n    return ty.pydantic_load(cls, args)\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.answer_type","title":"answer_type  <code>abstractmethod</code>","text":"<pre><code>answer_type() -&gt; TypeAnnot[T] | NoTypeInfo\n</code></pre> <p>Return the answer type for the query, or <code>NoTypeInfo()</code> if this information is not available.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@abstractmethod\ndef answer_type(self) -&gt; ty.TypeAnnot[T] | ty.NoTypeInfo:\n    \"\"\"\n    Return the answer type for the query, or `NoTypeInfo()` if this\n    information is not available.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.query_modes","title":"query_modes  <code>abstractmethod</code>","text":"<pre><code>query_modes() -&gt; Sequence[AnswerMode]\n</code></pre> <p>Return the sequence of available answer modes.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@abstractmethod\ndef query_modes(self) -&gt; Sequence[AnswerMode]:\n    \"\"\"\n    Return the sequence of available answer modes.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.query_prefix","title":"query_prefix","text":"<pre><code>query_prefix() -&gt; AnswerPrefix | None\n</code></pre> <p>Return the chat history featured in the query, if any.</p> <p>This is useful to emulate conversational agents by issuing a query repeatedly, passing it the whole, updated conversation history every time (see <code>interact</code>).</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>def query_prefix(self) -&gt; AnswerPrefix | None:\n    \"\"\"\n    Return the chat history featured in the query, if any.\n\n    This is useful to emulate conversational agents by issuing a\n    query repeatedly, passing it the whole, updated conversation\n    history every time (see `interact`).\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.query_settings","title":"query_settings","text":"<pre><code>query_settings(mode: AnswerMode) -&gt; QuerySettings\n</code></pre> <p>Return the settings associated with the query.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>def query_settings(self, mode: AnswerMode) -&gt; QuerySettings:\n    \"\"\"\n    Return the settings associated with the query.\n    \"\"\"\n    return QuerySettings()\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.query_name","title":"query_name","text":"<pre><code>query_name() -&gt; str\n</code></pre> <p>Return the name of the query (i.e., the name of the associated class).</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@final\ndef query_name(self) -&gt; str:\n    \"\"\"\n    Return the name of the query (i.e., the name of the associated\n    class).\n    \"\"\"\n    return self.__class__.__name__\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.default_tags","title":"default_tags","text":"<pre><code>default_tags() -&gt; Sequence[str]\n</code></pre> <p>Return a default set of tags to associate with spaces induced by the query.</p> <p>These tags can be overriden (see <code>SpaceBuilder</code>).</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>def default_tags(self) -&gt; Sequence[str]:\n    \"\"\"\n    Return a default set of tags to associate with spaces induced by\n    the query.\n\n    These tags can be overriden (see `SpaceBuilder`).\n    \"\"\"\n    return [self.query_name()]\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.parse_answer","title":"parse_answer  <code>abstractmethod</code>","text":"<pre><code>parse_answer(answer: Answer) -&gt; T | ParseError\n</code></pre> <p>Parse a query answer.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@abstractmethod\ndef parse_answer(self, answer: Answer) -&gt; T | ParseError:\n    \"\"\"\n    Parse a query answer.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.finite_answer_set","title":"finite_answer_set","text":"<pre><code>finite_answer_set() -&gt; Sequence[Answer] | None\n</code></pre> <p>For queries with a finite set of possible answers, return this set. Otherwise, return <code>None</code>.</p> <p>Demonstration tests can use a special <code>#&lt;val&gt;</code> hint to select the first answer with content <code>&lt;val&gt;</code> from this set.</p> <p>Example uses include classification queries (see <code>classify</code>) where a distribution of answers is extracted from LLM logits, flag queries...</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>def finite_answer_set(self) -&gt; Sequence[Answer] | None:\n    \"\"\"\n    For queries with a finite set of possible answers, return this\n    set. Otherwise, return `None`.\n\n    Demonstration tests can use a special `#&lt;val&gt;` hint to select\n    the first answer with content `&lt;val&gt;` from this set.\n\n    Example uses include classification queries (see `classify`)\n    where a distribution of answers is extracted from LLM logits,\n    flag queries...\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractQuery.default_answer","title":"default_answer","text":"<pre><code>default_answer() -&gt; Answer | None\n</code></pre> <p>Return a default answer for the query, if any.</p> <p>Default answers are used to answer queries in demonstration tests when no answer is provided in the <code>queries</code> section and no applicable hint is available.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>def default_answer(self) -&gt; Answer | None:\n    \"\"\"\n    Return a default answer for the query, if any.\n\n    Default answers are used to answer queries in demonstration\n    tests when no answer is provided in the `queries` section and no\n    applicable hint is available.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.ParseError","title":"ParseError  <code>dataclass</code>","text":"<p>               Bases: <code>Error</code>, <code>Exception</code></p> <p>Parse Error.</p> <p>Can be used as an exception or a returned value.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@dataclass\nclass ParseError(Error, Exception):\n    \"\"\"\n    Parse Error.\n\n    Can be used as an exception or a returned value.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        label: str | None = None,\n        description: str | None = None,\n        meta: Any | None = None,\n    ):\n        if label is None:\n            label = \"parse_error\"\n        super().__init__(label=label, description=description, meta=meta)\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.QuerySettings","title":"QuerySettings  <code>dataclass</code>","text":"<p>Settings associated with a query.</p> <p>These settings can accessed by prompting policies so as to make appropriate requests to LLMs.</p> <p>Attributes:</p> Name Type Description <code>structured_output</code> <code>StructuredOutputSettings | None</code> <p>Settings for structured output, or <code>None</code> if structured output is not enabled.</p> <code>tools</code> <code>ToolSettings | None</code> <p>Settings for tool calls, or <code>None</code> if no tools are available.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@dataclass(frozen=True)\nclass QuerySettings:\n    \"\"\"\n    Settings associated with a query.\n\n    These settings can accessed by prompting policies so as to make\n    appropriate requests to LLMs.\n\n    Attributes:\n        structured_output: Settings for structured output, or `None` if\n            structured output is not enabled.\n        tools: Settings for tool calls, or `None` if no tools are\n            available.\n    \"\"\"\n\n    structured_output: StructuredOutputSettings | None = None\n    tools: ToolSettings | None = None\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.StructuredOutputSettings","title":"StructuredOutputSettings  <code>dataclass</code>","text":"<p>Settings for LLM structured output.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>TypeAnnot[Any] | NoTypeInfo</code> <p>Expected type for the output, from which a schema can be derived if provided.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@dataclass(frozen=True)\nclass StructuredOutputSettings:\n    \"\"\"\n    Settings for LLM structured output.\n\n    Attributes:\n        type: Expected type for the output, from which a schema can be\n            derived if provided.\n    \"\"\"\n\n    type: ty.TypeAnnot[Any] | ty.NoTypeInfo\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.ToolSettings","title":"ToolSettings  <code>dataclass</code>","text":"<p>Tool call settings.</p> <p>Attributes:</p> Name Type Description <code>tool_types</code> <code>Sequence[type[Any]]</code> <p>Nonempty sequence of available tools. All tools must be classes, although more constraints can be put by specific queries and prompting policies.</p> <code>force_tool_call</code> <code>bool</code> <p>If True, oracles are informed that a tool call must be made.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@dataclass(frozen=True)\nclass ToolSettings:\n    \"\"\"\n    Tool call settings.\n\n    Attributes:\n        tool_types: Nonempty sequence of available tools. All tools must\n            be classes, although more constraints can be put by specific\n            queries and prompting policies.\n        force_tool_call: If True, oracles are informed that a tool call\n            **must** be made.\n    \"\"\"\n\n    tool_types: Sequence[type[Any]]\n    force_tool_call: bool\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractTemplatesManager","title":"AbstractTemplatesManager","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>class AbstractTemplatesManager(ABC):\n    @abstractmethod\n    def prompt(\n        self,\n        *,\n        query_name: str,\n        prompt_kind: Literal[\"system\", \"instance\"] | str,\n        template_args: dict[str, Any],\n        default_template: str | None = None,\n    ) -&gt; str:\n        \"\"\"\n        Render a prompt message using a template.\n\n        Args:\n            query_name: The name of the query for which the prompt is\n                built. Used to determine the template file name\n                (e.g. \"{query_name}.{prompt_kind}.jinja\").\n            prompt_kind: The kind of prompt (e.g. \"system\" or \"instance\")\n                that is being rendered, used to determine the name of the\n                template file to use.\n            template_args: A dictionary of arguments to pass to the\n                template. It must not contain key \"data\", which is\n                reserved for the data loaded from the data directories.\n            default_template: If provided, this template will be used if\n                no template file is found for the given query name and\n                kind instead of raising an error.\n\n        Raises:\n            TemplateFileMissing: template file not found.\n            TemplateError: error raised while rendering the template.\n        \"\"\"\n\n        pass\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.AbstractTemplatesManager.prompt","title":"prompt  <code>abstractmethod</code>","text":"<pre><code>prompt(\n    *,\n    query_name: str,\n    prompt_kind: Literal[\"system\", \"instance\"] | str,\n    template_args: dict[str, Any],\n    default_template: str | None = None,\n) -&gt; str\n</code></pre> <p>Render a prompt message using a template.</p> <p>Parameters:</p> Name Type Description Default <code>query_name</code> <code>str</code> <p>The name of the query for which the prompt is built. Used to determine the template file name (e.g. \"{query_name}.{prompt_kind}.jinja\").</p> required <code>prompt_kind</code> <code>Literal['system', 'instance'] | str</code> <p>The kind of prompt (e.g. \"system\" or \"instance\") that is being rendered, used to determine the name of the template file to use.</p> required <code>template_args</code> <code>dict[str, Any]</code> <p>A dictionary of arguments to pass to the template. It must not contain key \"data\", which is reserved for the data loaded from the data directories.</p> required <code>default_template</code> <code>str | None</code> <p>If provided, this template will be used if no template file is found for the given query name and kind instead of raising an error.</p> <code>None</code> <p>Raises:</p> Type Description <code>TemplateFileMissing</code> <p>template file not found.</p> <code>TemplateError</code> <p>error raised while rendering the template.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@abstractmethod\ndef prompt(\n    self,\n    *,\n    query_name: str,\n    prompt_kind: Literal[\"system\", \"instance\"] | str,\n    template_args: dict[str, Any],\n    default_template: str | None = None,\n) -&gt; str:\n    \"\"\"\n    Render a prompt message using a template.\n\n    Args:\n        query_name: The name of the query for which the prompt is\n            built. Used to determine the template file name\n            (e.g. \"{query_name}.{prompt_kind}.jinja\").\n        prompt_kind: The kind of prompt (e.g. \"system\" or \"instance\")\n            that is being rendered, used to determine the name of the\n            template file to use.\n        template_args: A dictionary of arguments to pass to the\n            template. It must not contain key \"data\", which is\n            reserved for the data loaded from the data directories.\n        default_template: If provided, this template will be used if\n            no template file is found for the given query name and\n            kind instead of raising an error.\n\n    Raises:\n        TemplateFileMissing: template file not found.\n        TemplateError: error raised while rendering the template.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.TemplateError","title":"TemplateError  <code>dataclass</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Wrapper for template-related exceptions.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@dataclass\nclass TemplateError(Exception):\n    \"\"\"\n    Wrapper for template-related exceptions.\n    \"\"\"\n\n    name: str\n    exn: Exception\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.TemplateFileMissing","title":"TemplateFileMissing  <code>dataclass</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when a template file is missing.</p> <p>This exception should only be raised when a top-level template file is missing. If an <code>include</code> statement fails within a template, a <code>TemplateError</code> exception should be raised instead.</p> Source code in <code>src/delphyne/core/queries.py</code> <pre><code>@dataclass\nclass TemplateFileMissing(Exception):\n    \"\"\"\n    Exception raised when a template file is missing.\n\n    This exception should only be raised when a top-level template file\n    is missing. If an `include` statement fails within a template, a\n    `TemplateError` exception should be raised instead.\n    \"\"\"\n\n    file: str\n</code></pre>"},{"location":"reference/strategies/queries/#chat-histories","title":"Chat Histories","text":""},{"location":"reference/strategies/queries/#delphyne.AnswerPrefix","title":"AnswerPrefix","text":"<pre><code>AnswerPrefix = Sequence[AnswerPrefixElement]\n</code></pre> <p>An LLM chat history, to be passed to a query as an answer prefix (see <code>Query.query_prefix</code>).</p>"},{"location":"reference/strategies/queries/#delphyne.AnswerPrefixElement","title":"AnswerPrefixElement","text":"<pre><code>AnswerPrefixElement = OracleMessage | FeedbackMessage | ToolResult\n</code></pre> <p>LLM chat history element.</p>"},{"location":"reference/strategies/queries/#delphyne.OracleMessage","title":"OracleMessage  <code>dataclass</code>","text":"<p>Messge containing an oracle answer.</p> Source code in <code>src/delphyne/core/chats.py</code> <pre><code>@dataclass(frozen=True)\nclass OracleMessage:\n    \"\"\"\n    Messge containing an oracle answer.\n    \"\"\"\n\n    kind: Literal[\"oracle\"]\n    answer: Answer\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.FeedbackMessage","title":"FeedbackMessage  <code>dataclass</code>","text":"<p>Message containing user feedback.</p> Source code in <code>src/delphyne/core/chats.py</code> <pre><code>@dataclass(frozen=True)\nclass FeedbackMessage:\n    \"\"\"\n    Message containing user feedback.\n    \"\"\"\n\n    kind: Literal[\"feedback\"]\n    label: str | None = None\n    description: str | None = None\n    meta: Any | None = None  # must be serializable\n</code></pre>"},{"location":"reference/strategies/queries/#delphyne.ToolResult","title":"ToolResult  <code>dataclass</code>","text":"<p>User message containing the result of a tool call previously initiated by an LLM.</p> Source code in <code>src/delphyne/core/chats.py</code> <pre><code>@dataclass(frozen=True)\nclass ToolResult:\n    \"\"\"\n    User message containing the result of a tool call previously\n    initiated by an LLM.\n    \"\"\"\n\n    kind: Literal[\"tool\"]\n    call: ToolCall\n    result: str | Structured\n</code></pre>"},{"location":"reference/strategies/strategies/","title":"Strategies and Reification","text":""},{"location":"reference/strategies/strategies/#strategies","title":"Strategies","text":""},{"location":"reference/strategies/strategies/#delphyne.Strategy","title":"Strategy","text":"<pre><code>Strategy = Generator[NodeBuilder[N, P], object, T]\n</code></pre> <p>Type of a strategy computation.</p> <p>A strategy computation is a generator (i.e., a coroutine) that yields node builders and receives corresponding actions, until it returns a success value.</p> <p>          Type Parameters:        </p> Name Bound or Constraints Description Default <code>N</code> <code>Node</code> <p>The strategy's signature, typically a union of node types (covariant).</p> required <code>P</code> <p>The strategy's associated inner policy type (contravariant).</p> required <code>T</code> <p>The strategy's return type (covariant).</p> required <p>Info</p> <p>Node builders are yielded instead of nodes. Indeed, strategy computations cannot create nodes since they are unaware of references. The task of concretely building nodes and maintaining references is delegated to the <code>refine</code> function.</p>"},{"location":"reference/strategies/strategies/#delphyne.NodeBuilder","title":"NodeBuilder  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[N, P]</code></p> <p>Wrapper for a function that builds a node, given the ability of spawning trees and attached queries (<code>AbstractBuilderExecutor</code>).</p> <p>Strategies do not directly yield nodes since building a node requires knowing its reference along with the associated hooks.</p> <p>Phantom type <code>P</code> tracks the ambient inner policy type.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass(frozen=True)\nclass NodeBuilder(Generic[N, P]):\n    \"\"\"\n    Wrapper for a function that builds a node, given the ability of\n    spawning trees and attached queries (`AbstractBuilderExecutor`).\n\n    Strategies do not directly yield nodes since building a node\n    requires knowing its reference along with the associated hooks.\n\n    Phantom type `P` tracks the ambient inner policy type.\n    \"\"\"\n\n    build_node: \"Callable[[AbstractBuilderExecutor], N]\"\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.StrategyComp","title":"StrategyComp  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[N, P, T]</code></p> <p>A strategy computation that can be reified into a search tree, obtained by instantiating a strategy function.</p> <p>Such objects are usually not created directly but using the <code>@strategy</code> decorator from the standard library. Metadata information can be provided, such as: a name for the strategy, a return type and a list of tags.</p> Note <p>The name of the <code>_comp</code> function is inspected by methods such as <code>strategy_name</code>. Its signature (i.e., the name of its arguments) is inspected by <code>strategy_arguments</code>. When provided, type annotations are inspected by methods such as <code>return_type</code> and <code>inner_policy_type</code>. Thus, passing an anonymous function as <code>_comp</code> is not recommended.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass(frozen=True)\nclass StrategyComp(Generic[N, P, T]):\n    \"\"\"\n    A *strategy computation* that can be reified into a search tree,\n    obtained by instantiating a strategy function.\n\n    Such objects are usually not created directly but using the\n    [`@strategy` decorator][delphyne.stdlib.strategy] from the standard\n    library. Metadata information can be provided, such as: a name for\n    the strategy, a return type and a list of tags.\n\n    ??? note\n        The name of the `_comp` function is inspected by methods such as\n        `strategy_name`. Its signature (i.e., the name of its arguments)\n        is inspected by `strategy_arguments`. When provided, type\n        annotations are inspected by methods such as `return_type` and\n        `inner_policy_type`. Thus, passing an anonymous function as\n        `_comp` is not recommended.\n    \"\"\"\n\n    _comp: Callable[..., Strategy[N, P, T]]\n    _args: tuple[Any, ...]\n    _kwargs: dict[str, Any]\n    _name: str | None\n    _return_type: TypeAnnot[T] | NoTypeInfo\n    _tags: Sequence[Tag]\n\n    ##### External API\n\n    def inline(self) -&gt; Strategy[N, P, T]:\n        \"\"\"\n        Inline a strategy computation within another, by executing the\n        underlying coroutine.\n\n        Example:\n\n        ```python\n        # Invoking a sub-strategy by branching over an opaque space.\n        y = yield from branch(sub_strategy(foo, bar).using(...))\n        # Invoking a sub-strategy via inlining (the signature and inner\n        # policy types of the sub strategy must be identical).\n        y = yield from sub_strategy(foo, bar).inline()\n        ```\n        \"\"\"\n        return self.run_generator()\n\n    ##### For internal use in `core` and in the standard library\n\n    def run_generator(self) -&gt; Strategy[N, P, T]:\n        \"\"\"\n        Run the coroutine associated with the strategy computation. This\n        method is mostly used by [`reify`][delphyne.core.reify] and\n        should not be needed outside of Delphyne's internals.\n        \"\"\"\n        return self._comp(*self._args, **self._kwargs)\n\n    def default_tags(self) -&gt; Sequence[Tag]:\n        \"\"\"\n        Return all default tags associated with the strategy\n        computation. Derived space builders are initialized with these\n        tags, which can later be changed (`tag` field of\n        `SpaceBuilder`).\n        \"\"\"\n        return self._tags\n\n    ### Inspection methods\n\n    def strategy_name(self) -&gt; str | None:\n        \"\"\"\n        Return the name of the instantiated strategy function, using the\n        `name` attribute if provided or using `comp.__name__` otherwise.\n        \"\"\"\n        if self._name is not None:\n            return self._name\n        return inspect.function_name(self._comp)\n\n    def strategy_arguments(self) -&gt; dict[str, Any]:\n        \"\"\"\n        Return the dictionary of arguments that was used to instantiate\n        the underlying strategy function (using inspection for naming\n        positional arguments).\n        \"\"\"\n        return inspect.function_args_dict(self._comp, self._args, self._kwargs)\n\n    def strategy_argument_types(\n        self,\n    ) -&gt; dict[str, TypeAnnot[Any] | NoTypeInfo]:\n        \"\"\"\n        Return a dictionary with the same keys as `strategy_arguments`\n        that maps every strategy argument to its type annotation (or\n        `NoTypeInfo` if none is provided).\n        \"\"\"\n        hints = typing.get_type_hints(self._comp)\n        return {\n            a: hints.get(a, NoTypeInfo()) for a in self.strategy_arguments()\n        }\n\n    def return_type(self) -&gt; TypeAnnot[T] | NoTypeInfo:\n        \"\"\"\n        Return the return type of the strategy computation, using the\n        provided metadata or using inspection otherwise (in case a type\n        annotation of the form `Strategy[..., ..., T]` is provided).\n\n        This information is useful for serializing success values after\n        running the strategy computation (see `run_strategy` command) or\n        for providing superior printing of values in the Delphyne tree\n        view.\n        \"\"\"\n        if not isinstance(self._return_type, NoTypeInfo):\n            return self._return_type\n        strategy_type = inspect.function_return_type(self._comp)\n        if isinstance(strategy_type, NoTypeInfo):\n            return NoTypeInfo()\n        return inspect.return_type_of_strategy_type(strategy_type)\n\n    def inner_policy_type(self) -&gt; TypeAnnot[T] | NoTypeInfo:\n        \"\"\"\n        Return the inner policy type of the strategy computation, using\n        inspection (when a type annotation of the form `Strategy[..., P,\n        ...]` is provided).\n\n        This information is not currently used but could be leveraged in\n        the future to dynamically check the compatibility of an\n        associated policy.\n        \"\"\"\n        strategy_type = inspect.function_return_type(self._comp)\n        if isinstance(strategy_type, NoTypeInfo):\n            return NoTypeInfo()\n        return inspect.inner_policy_type_of_strategy_type(strategy_type)\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.StrategyComp.inline","title":"inline","text":"<pre><code>inline() -&gt; Strategy[N, P, T]\n</code></pre> <p>Inline a strategy computation within another, by executing the underlying coroutine.</p> <p>Example:</p> <pre><code># Invoking a sub-strategy by branching over an opaque space.\ny = yield from branch(sub_strategy(foo, bar).using(...))\n# Invoking a sub-strategy via inlining (the signature and inner\n# policy types of the sub strategy must be identical).\ny = yield from sub_strategy(foo, bar).inline()\n</code></pre> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def inline(self) -&gt; Strategy[N, P, T]:\n    \"\"\"\n    Inline a strategy computation within another, by executing the\n    underlying coroutine.\n\n    Example:\n\n    ```python\n    # Invoking a sub-strategy by branching over an opaque space.\n    y = yield from branch(sub_strategy(foo, bar).using(...))\n    # Invoking a sub-strategy via inlining (the signature and inner\n    # policy types of the sub strategy must be identical).\n    y = yield from sub_strategy(foo, bar).inline()\n    ```\n    \"\"\"\n    return self.run_generator()\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.StrategyComp.run_generator","title":"run_generator","text":"<pre><code>run_generator() -&gt; Strategy[N, P, T]\n</code></pre> <p>Run the coroutine associated with the strategy computation. This method is mostly used by <code>reify</code> and should not be needed outside of Delphyne's internals.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def run_generator(self) -&gt; Strategy[N, P, T]:\n    \"\"\"\n    Run the coroutine associated with the strategy computation. This\n    method is mostly used by [`reify`][delphyne.core.reify] and\n    should not be needed outside of Delphyne's internals.\n    \"\"\"\n    return self._comp(*self._args, **self._kwargs)\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.StrategyComp.default_tags","title":"default_tags","text":"<pre><code>default_tags() -&gt; Sequence[Tag]\n</code></pre> <p>Return all default tags associated with the strategy computation. Derived space builders are initialized with these tags, which can later be changed (<code>tag</code> field of <code>SpaceBuilder</code>).</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def default_tags(self) -&gt; Sequence[Tag]:\n    \"\"\"\n    Return all default tags associated with the strategy\n    computation. Derived space builders are initialized with these\n    tags, which can later be changed (`tag` field of\n    `SpaceBuilder`).\n    \"\"\"\n    return self._tags\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.StrategyComp.strategy_name","title":"strategy_name","text":"<pre><code>strategy_name() -&gt; str | None\n</code></pre> <p>Return the name of the instantiated strategy function, using the <code>name</code> attribute if provided or using <code>comp.__name__</code> otherwise.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def strategy_name(self) -&gt; str | None:\n    \"\"\"\n    Return the name of the instantiated strategy function, using the\n    `name` attribute if provided or using `comp.__name__` otherwise.\n    \"\"\"\n    if self._name is not None:\n        return self._name\n    return inspect.function_name(self._comp)\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.StrategyComp.strategy_arguments","title":"strategy_arguments","text":"<pre><code>strategy_arguments() -&gt; dict[str, Any]\n</code></pre> <p>Return the dictionary of arguments that was used to instantiate the underlying strategy function (using inspection for naming positional arguments).</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def strategy_arguments(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Return the dictionary of arguments that was used to instantiate\n    the underlying strategy function (using inspection for naming\n    positional arguments).\n    \"\"\"\n    return inspect.function_args_dict(self._comp, self._args, self._kwargs)\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.StrategyComp.strategy_argument_types","title":"strategy_argument_types","text":"<pre><code>strategy_argument_types() -&gt; dict[str, TypeAnnot[Any] | NoTypeInfo]\n</code></pre> <p>Return a dictionary with the same keys as <code>strategy_arguments</code> that maps every strategy argument to its type annotation (or <code>NoTypeInfo</code> if none is provided).</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def strategy_argument_types(\n    self,\n) -&gt; dict[str, TypeAnnot[Any] | NoTypeInfo]:\n    \"\"\"\n    Return a dictionary with the same keys as `strategy_arguments`\n    that maps every strategy argument to its type annotation (or\n    `NoTypeInfo` if none is provided).\n    \"\"\"\n    hints = typing.get_type_hints(self._comp)\n    return {\n        a: hints.get(a, NoTypeInfo()) for a in self.strategy_arguments()\n    }\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.StrategyComp.return_type","title":"return_type","text":"<pre><code>return_type() -&gt; TypeAnnot[T] | NoTypeInfo\n</code></pre> <p>Return the return type of the strategy computation, using the provided metadata or using inspection otherwise (in case a type annotation of the form <code>Strategy[..., ..., T]</code> is provided).</p> <p>This information is useful for serializing success values after running the strategy computation (see <code>run_strategy</code> command) or for providing superior printing of values in the Delphyne tree view.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def return_type(self) -&gt; TypeAnnot[T] | NoTypeInfo:\n    \"\"\"\n    Return the return type of the strategy computation, using the\n    provided metadata or using inspection otherwise (in case a type\n    annotation of the form `Strategy[..., ..., T]` is provided).\n\n    This information is useful for serializing success values after\n    running the strategy computation (see `run_strategy` command) or\n    for providing superior printing of values in the Delphyne tree\n    view.\n    \"\"\"\n    if not isinstance(self._return_type, NoTypeInfo):\n        return self._return_type\n    strategy_type = inspect.function_return_type(self._comp)\n    if isinstance(strategy_type, NoTypeInfo):\n        return NoTypeInfo()\n    return inspect.return_type_of_strategy_type(strategy_type)\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.StrategyComp.inner_policy_type","title":"inner_policy_type","text":"<pre><code>inner_policy_type() -&gt; TypeAnnot[T] | NoTypeInfo\n</code></pre> <p>Return the inner policy type of the strategy computation, using inspection (when a type annotation of the form <code>Strategy[..., P, ...]</code> is provided).</p> <p>This information is not currently used but could be leveraged in the future to dynamically check the compatibility of an associated policy.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def inner_policy_type(self) -&gt; TypeAnnot[T] | NoTypeInfo:\n    \"\"\"\n    Return the inner policy type of the strategy computation, using\n    inspection (when a type annotation of the form `Strategy[..., P,\n    ...]` is provided).\n\n    This information is not currently used but could be leveraged in\n    the future to dynamically check the compatibility of an\n    associated policy.\n    \"\"\"\n    strategy_type = inspect.function_return_type(self._comp)\n    if isinstance(strategy_type, NoTypeInfo):\n        return NoTypeInfo()\n    return inspect.inner_policy_type_of_strategy_type(strategy_type)\n</code></pre>"},{"location":"reference/strategies/strategies/#reification","title":"Reification","text":""},{"location":"reference/strategies/strategies/#delphyne.reify","title":"reify","text":"<pre><code>reify(\n    strategy: StrategyComp[N, P, T],\n    monitor: TreeMonitor = TreeMonitor(),\n    allow_noncopyable_actions: bool = False,\n) -&gt; Tree[N, P, T]\n</code></pre> <p>Reify a strategy computation into a tree.</p> <p>The resulting tree raises <code>StrategyException</code> whenever the underlying strategy raises an uncaught exception.</p> <p>Internally, trees are implemented by having each node keep track of a sequence of actions leading to it. Calling <code>child</code> appends a new action to this path and replays the strategy computation from the start with the new, augmented path.</p> <p>Parameters:</p> Name Type Description Default <code>strategy</code> <code>StrategyComp[N, P, T]</code> <p>The strategy to reify.</p> required <code>monitor</code> <code>TreeMonitor</code> <p>An optional cache, along with node creation hooks.</p> <code>TreeMonitor()</code> <code>allow_noncopyable_actions</code> <code>bool</code> <p>Allow actions to be nonserializable objects (such as functions) that cannot be deepcopied. Allowing such actions opens the door to unsafe side effects corrupting the resulting tree, so it must be done with care. See discussion below on side effects.</p> <code>False</code> <p>On Side Effects in Strategies</p> <p>Strategy functions are allowed to have side effects (see <code>tests/example_strategies/imperative_strategy</code> for example). For this to be sound, actions are always deepcopied before being sent back to strategy coroutines. This requirement can be weakened by setting <code>allow_noncopyable_actions</code> to <code>True</code>. In this case, noncopyable actions must be immutable. For example, a pure function can be used as an action but a closure that captures a mutable piece of state cannot (in which case computing the child of a node could affect its siblings by mutating some actions in their paths).</p> <p>In addition, non-copyable strategy arguments must never be mutated. Copyable arguments such as lists of copyable values can be mutated, since <code>reify</code> automaticallt performs deepcopies. Noncopyable arguments such as functions are allowed (e.g., to enable implementing higher-order strategies) but they must be pure and not mutate any state.</p> <p>When <code>allow_noncopyable_actions</code> is set to <code>False</code>, a dynamic check is performed to ensure that actions are copyable: an action is considered copyable if it can be serialized into JSON by pydantic (this is necessary since calling <code>deepcopy</code> on a closure returns the same closure unchanged).</p> Source code in <code>src/delphyne/core/reification.py</code> <pre><code>def reify[N: Node, P, T](\n    strategy: StrategyComp[N, P, T],\n    monitor: TreeMonitor = TreeMonitor(),\n    allow_noncopyable_actions: bool = False,\n) -&gt; Tree[N, P, T]:\n    \"\"\"\n    Reify a strategy computation into a tree.\n\n    The resulting tree raises `StrategyException` whenever the\n    underlying strategy raises an uncaught exception.\n\n    Internally, trees are implemented by having each node keep track of\n    a sequence of actions leading to it. Calling `child` appends a new\n    action to this path and replays the strategy computation from the\n    start with the new, augmented path.\n\n    Arguments:\n        strategy: The strategy to reify.\n        monitor: An optional cache, along with node creation hooks.\n        allow_noncopyable_actions: Allow\n            actions to be nonserializable objects (such as functions)\n            that cannot be deepcopied. Allowing such actions opens the\n            door to unsafe side effects corrupting the resulting tree,\n            so it must be done with care. See discussion below on side\n            effects.\n\n    !!! note \"On Side Effects in Strategies\"\n        Strategy functions are allowed to have side effects (see\n        `tests/example_strategies/imperative_strategy` for example). For\n        this to be sound, actions are always deepcopied before being\n        sent back to strategy coroutines. This requirement can be\n        weakened by setting `allow_noncopyable_actions` to `True`. In\n        this case, noncopyable actions must be immutable. For example, a\n        pure function can be used as an action but a closure that\n        captures a mutable piece of state cannot (in which case\n        computing the child of a node could affect its siblings by\n        mutating some actions in their paths).\n\n        In addition, non-copyable strategy arguments must never be\n        mutated. Copyable arguments such as lists of copyable values can\n        be mutated, since `reify` automaticallt performs deepcopies.\n        Noncopyable arguments such as functions are allowed (e.g., to\n        enable implementing higher-order strategies) but they must be\n        pure and not mutate any state.\n\n        When `allow_noncopyable_actions` is set to `False`, a dynamic\n        check is performed to ensure that actions are copyable: an\n        action is considered copyable if it can be serialized into JSON\n        by pydantic (this is necessary since calling `deepcopy` on a\n        closure returns the same closure unchanged).\n    \"\"\"\n    return _reify(\n        strategy=strategy,\n        root_ref=None,\n        monitor=monitor,\n        allow_noncopyable_actions=allow_noncopyable_actions,\n    )\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.StrategyException","title":"StrategyException  <code>dataclass</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a strategy encounters an internal error (e.g. a failed assertion or an index-out-of-bounds error).</p> <p>Attributes:</p> Name Type Description <code>exn</code> <code>Exception</code> <p>The original exception that was raised.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass\nclass StrategyException(Exception):\n    \"\"\"\n    Raised when a strategy encounters an internal error (e.g. a failed\n    assertion or an index-out-of-bounds error).\n\n    Attributes:\n        exn: The original exception that was raised.\n    \"\"\"\n\n    exn: Exception\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.TreeMonitor","title":"TreeMonitor  <code>dataclass</code>","text":"<p>A record that gathers a tree cache along with a series of hooks to be called on node creation.</p> <p>When no monitor is passed to <code>reify</code>, the resulting tree is a pure, immutable datastructure. Passing a monitor allows adding limited side effects in the form of caching and hooks.</p> <p>Attributes:</p> Name Type Description <code>cache</code> <code>TreeCache | TreeCache | None</code> <p>a cache for never recomputing the same node twice.</p> <code>hooks</code> <code>Sequence[TreeHook]</code> <p>functions to be called every time a new node is created. For example, hooks can be used to automatically produce a trace that keeps track of all visited nodes (see <code>tracer_hook</code>).</p> Source code in <code>src/delphyne/core/reification.py</code> <pre><code>@dataclass(frozen=True)\nclass TreeMonitor:\n    \"\"\"\n    A record that gathers a tree cache along with a series of hooks to\n    be called on node creation.\n\n    When no monitor is passed to `reify`, the resulting tree is a pure,\n    immutable datastructure. Passing a monitor allows adding limited\n    side effects in the form of caching and hooks.\n\n    Attributes:\n        cache: a cache for never recomputing the same node twice.\n        hooks: functions to be called every time a new node is created.\n            For example, hooks can be used to automatically produce a\n            trace that keeps track of all visited nodes (see\n            `tracer_hook`).\n    \"\"\"\n\n    cache: TreeCache | TreeCache | None = None\n    hooks: Sequence[TreeHook] = ()\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.TreeCache","title":"TreeCache","text":"<pre><code>TreeCache = dict[GlobalNodePath, Tree[Any, Any, Any]]\n</code></pre> <p>A cache for never recomputing the same node twice.</p> <p>Each encountered subtree and (recursively) nested tree is stored, indexed by its global reference.</p>"},{"location":"reference/strategies/strategies/#delphyne.TreeHook","title":"TreeHook","text":"<pre><code>TreeHook = Callable[[Tree[Any, Any, Any]], None]\n</code></pre> <p>A function to be called every time a new tree node is created.</p>"},{"location":"reference/strategies/strategies/#internals","title":"Internals","text":""},{"location":"reference/strategies/strategies/#delphyne.core.trees.NestedTreeSpawner","title":"NestedTreeSpawner","text":"<p>               Bases: <code>Protocol</code></p> <p>A function providing the ability to spawn nested trees attached to a given node.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>class NestedTreeSpawner(Protocol):\n    \"\"\"\n    A function providing the ability to spawn nested trees attached to a\n    given node.\n    \"\"\"\n\n    def __call__[N: Node, P, T](\n        self, strategy: \"StrategyComp[N, P, T]\"\n    ) -&gt; \"NestedTree[N, P, T]\": ...\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.core.trees.QuerySpawner","title":"QuerySpawner","text":"<p>               Bases: <code>Protocol</code></p> <p>A function providing the ability to attach queries to a given node.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>class QuerySpawner(Protocol):\n    \"\"\"\n    A function providing the ability to attach queries to a given node.\n    \"\"\"\n\n    def __call__[T](self, query: AbstractQuery[T]) -&gt; \"AttachedQuery[T]\": ...\n</code></pre>"},{"location":"reference/strategies/strategies/#delphyne.core.trees.AbstractBuilderExecutor","title":"AbstractBuilderExecutor","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract class for builder executors.</p> <p>An executor implements the ability of converting space builders into actual spaces. The <code>reify</code> function relies on such an executor internally.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>class AbstractBuilderExecutor(ABC):\n    \"\"\"\n    Abstract class for builder executors.\n\n    An executor implements the ability of converting space builders into\n    actual spaces. The `reify` function relies on such an executor\n    internally.\n    \"\"\"\n\n    @abstractmethod\n    def parametric[S](\n        self,\n        space_name: SpaceName,\n        parametric_builder: Callable[..., SpaceBuilder[S]],\n    ) -&gt; Callable[..., S]: ...\n\n    @abstractmethod\n    def nonparametric[S](self, name: SpaceName, builder: SpaceBuilder[S]) -&gt; S:\n        return self.parametric(name, lambda: builder)()\n</code></pre>"},{"location":"reference/strategies/traces/","title":"References and Traces","text":""},{"location":"reference/strategies/traces/#references-summary","title":"References Summary","text":""},{"location":"reference/strategies/traces/#delphyne.core.refs","title":"delphyne.core.refs","text":"<p>References to nodes, values, spaces and space elements.</p> <p>References are serializable, immutable values that can be used to identify nodes, spaces and values in a tree (possibly deeply nested). References are useful for tooling and for representing serializable traces (<code>Trace</code>). Also, references are attached to success nodes and query answers (<code>Tracked</code>) so as to allow caching and enforce the locality invariant (see <code>Tree</code>).</p> <p>Local references identify a node, space or space element relative to a given tree node. Global references are expressed relative to a single, global origin.</p> <p>In addition, three kinds of references can be distinguished:</p> <ul> <li>Full references: the default kind of references produced by       <code>reify</code>. Query answers are stored as strings and elements of       spaces induced by strategies are denoted by sequences of value       references.</li> <li>Id-based references: shorter references, where query answers and       success values are identified by unique identifiers. This concise       format is used for exporting traces (see <code>Trace</code>).</li> <li>Hint-based references: query answers and success values are       identified by sequences of hints. This format is used in the       demonstration language (e.g. argument of test instruction <code>go       compare(['', 'foo bar'])</code>) and when visualizing traces resulting       from demonstrations.</li> </ul>"},{"location":"reference/strategies/traces/#query-answers","title":"Query Answers","text":""},{"location":"reference/strategies/traces/#delphyne.Answer","title":"Answer  <code>dataclass</code>","text":"<p>An answer to a query.</p> <p>It can serve as a space element reference if the space in question is a query and the proposed answer correctly parses.</p> <p>Attributes:</p> Name Type Description <code>mode</code> <code>AnswerMode</code> <p>The answer mode (see <code>AnswerMode</code>).</p> <code>content</code> <code>str | Structured</code> <p>The answer content, which can be a raw string or a structured answer (see <code>Structured</code>).</p> <code>tool_calls</code> <code>tuple[ToolCall, ...]</code> <p>An optional sequence of tool calls.</p> <code>justification</code> <code>str | None</code> <p>Additional explanations for the answers, which are not passed to the parser but can be appended at the end of the answer in examples. In particular, this is useful when defining queries for which the oracle is not asked to produce a justification for its answer, but justifications can still be provided in examples for the sake of few-shot prompting.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass Answer:\n    \"\"\"\n    An answer to a query.\n\n    It can serve as a _space element reference_ if the space in question\n    is a query and the proposed answer correctly parses.\n\n    Attributes:\n        mode: The answer mode (see `AnswerMode`).\n        content: The answer content, which can be a raw string or a\n            structured answer (see `Structured`).\n        tool_calls: An optional sequence of tool calls.\n        justification: Additional explanations for the answers, which\n            are not passed to the parser but can be appended at the end\n            of the answer in examples. In particular, this is useful\n            when defining queries for which the oracle is not asked to\n            produce a justification for its answer, but justifications\n            can still be provided in examples for the sake of few-shot\n            prompting.\n    \"\"\"\n\n    mode: AnswerMode\n    content: str | Structured\n    tool_calls: tuple[ToolCall, ...] = ()\n    justification: str | None = None\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.AnswerMode","title":"AnswerMode","text":"<pre><code>AnswerMode = str | None\n</code></pre> <p>A name for an answer mode, which can be a string or <code>None</code> (the latter is typically used for naming default modes).</p> <p>Queries are allowed to define multiple answer modes, each mode being possibly associated with different settings and with a different parser. An <code>Answer</code> value features the mode that must be used to parse it.</p>"},{"location":"reference/strategies/traces/#delphyne.Structured","title":"Structured  <code>dataclass</code>","text":"<p>Wrapper for structured LLM answers.</p> <p>Many LLM APIs allow producing JSON answers (sometimes following a given schema) instead of plain text.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass Structured:\n    \"\"\"\n    Wrapper for structured LLM answers.\n\n    Many LLM APIs allow producing JSON answers (sometimes following a\n    given schema) instead of plain text.\n    \"\"\"\n\n    structured: Any  # JSON object\n\n    def __hash__(self) -&gt; int:\n        # See `ToolCall.__hash__` for explanations.\n        import json\n\n        return hash(json.dumps(self.__dict__))\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.ToolCall","title":"ToolCall  <code>dataclass</code>","text":"<p>A tool call, usually produced by an LLM oracle.</p> <p>Tool calls can be attached to LLM answers (see <code>Answer</code>).</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass ToolCall:\n    \"\"\"\n    A tool call, usually produced by an LLM oracle.\n\n    Tool calls can be attached to LLM answers (see `Answer`).\n    \"\"\"\n\n    name: str\n    args: Mapping[str, Any]\n\n    def __hash__(self) -&gt; int:\n        # Tool calls need to be hashable since they are part of answers\n        # and references. However, they can feature arbitrary JSON\n        # objects. This, we compute a hash for the serialized value.\n        import json\n\n        return hash(json.dumps(self.__dict__))\n</code></pre>"},{"location":"reference/strategies/traces/#references","title":"References","text":""},{"location":"reference/strategies/traces/#delphyne.core.refs.NodeRef","title":"NodeRef","text":"<pre><code>NodeRef = NodePath | NodeId\n</code></pre> <p>A node reference is either a path or a node identifier.</p> <p>Only one of these forms may be allowed depending on the context (e.g. in the id-based references used for exporting traces, only node identifiers are used, while in the full references attached to trees by <code>reify</code>, only paths are used).</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.NodePath","title":"NodePath","text":"<pre><code>NodePath = tuple[ValueRef, ...]\n</code></pre> <p>Encodes a sequence of actions leading to a node with respect to a given root.</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.NodeId","title":"NodeId  <code>dataclass</code>","text":"<p>Global identifier of a node within a trace.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass NodeId:\n    \"\"\"\n    Global identifier of a node within a trace.\n    \"\"\"\n\n    id: int\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.refs.ValueRef","title":"ValueRef","text":"<pre><code>ValueRef = Assembly[AtomicValueRef]\n</code></pre> <p>A reference to a local value, which is obtained by combining elements of (possibly multiple) local spaces.</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.Assembly","title":"Assembly","text":"<pre><code>Assembly = T | None | tuple[Assembly[T], ...]\n</code></pre> <p>An S-expression whose atoms have type <code>T</code>.</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.AtomicValueRef","title":"AtomicValueRef","text":"<pre><code>AtomicValueRef = IndexedRef | SpaceElementRef\n</code></pre> <p>An atomic value reference is a space element reference that is indexed zero or a finite number of times: <code>space_elt_ref[i1][i2]...[in]</code>.</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.IndexedRef","title":"IndexedRef  <code>dataclass</code>","text":"<p>Indexing an atomic value reference.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass IndexedRef:\n    \"\"\"\n    Indexing an atomic value reference.\n    \"\"\"\n\n    ref: AtomicValueRef\n    index: int\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.refs.SpaceElementRef","title":"SpaceElementRef  <code>dataclass</code>","text":"<p>A reference to an element of a local space.</p> <p>When the <code>space</code> field is <code>None</code>, the primary field is considered instead (if it exists).</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass SpaceElementRef:\n    \"\"\"\n    A reference to an element of a local space.\n\n    When the `space` field is `None`, the primary field is considered\n    instead (if it exists).\n    \"\"\"\n\n    space: SpaceRef | None\n    element: AnswerRef | NodeRef | HintsRef\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.refs.SpaceRef","title":"SpaceRef  <code>dataclass</code>","text":"<p>A reference to a specific local space.</p> <p>The <code>arg</code> argument should be <code>()</code> for nonparametric spaces and a n-uple for spaces parametric in n arguments. This differs from Orakell where all parametric spaces have one argument.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass SpaceRef:\n    \"\"\"\n    A reference to a specific local space.\n\n    The `arg` argument should be `()` for nonparametric spaces and a\n    n-uple for spaces parametric in n arguments. This differs from\n    Orakell where all parametric spaces have one argument.\n    \"\"\"\n\n    name: SpaceName\n    args: tuple[ValueRef, ...]\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.refs.SpaceName","title":"SpaceName  <code>dataclass</code>","text":"<p>A name identifying a parametric space.</p> <p>This name can feature integer indices. For example, <code>subs[0]</code> denotes the first subgoal of a <code>Join</code> node.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass SpaceName:\n    \"\"\"\n    A name identifying a parametric space.\n\n    This name can feature integer indices. For example, `subs[0]`\n    denotes the first subgoal of a `Join` node.\n    \"\"\"\n\n    name: str\n    indices: tuple[int, ...]\n\n    def __getitem__(self, index: int) -&gt; \"SpaceName\":\n        return SpaceName(self.name, (*self.indices, index))\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.refs.AnswerRef","title":"AnswerRef","text":"<pre><code>AnswerRef = Answer | AnswerId\n</code></pre> <p>A reference to a query answer.</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.AnswerId","title":"AnswerId  <code>dataclass</code>","text":"<p>The identifier to an <code>Answer</code> object stored within a trace.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass AnswerId:\n    \"\"\"\n    The identifier to an `Answer` object stored within a trace.\n    \"\"\"\n\n    id: int\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.refs.HintsRef","title":"HintsRef  <code>dataclass</code>","text":"<p>References a local space element via a sequence of hints.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass HintsRef:\n    \"\"\"\n    References a local space element via a sequence of hints.\n    \"\"\"\n\n    hints: tuple[Hint, ...]\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.refs.Hint","title":"Hint  <code>dataclass</code>","text":"<p>A hint for selecting a query answer.</p> <p>A hint can be associated to a qualifier, which is the name of an imported demonstration defining the hint.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass Hint:\n    \"\"\"A hint for selecting a query answer.\n\n    A hint can be associated to a qualifier, which is the name of an\n    imported demonstration defining the hint.\n    \"\"\"\n\n    qualifier: str | None\n    hint: HintValue\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.refs.HintValue","title":"HintValue","text":"<pre><code>HintValue = str\n</code></pre> <p>A string that hints at a query answer.</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.GlobalNodePath","title":"GlobalNodePath","text":"<pre><code>GlobalNodePath = tuple[tuple[SpaceRef, NodePath], ...]\n</code></pre> <p>Path to a node from the global origin, as a sequence of (space to enter, path to follow) instruction pairs.</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.GlobalSpacePath","title":"GlobalSpacePath","text":"<pre><code>GlobalSpacePath = tuple[GlobalNodePath, SpaceRef]\n</code></pre> <p>A path to a global node</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.NodeOrigin","title":"NodeOrigin","text":"<pre><code>NodeOrigin = ChildOf | NestedTreeOf\n</code></pre> <p>Origin of a tree.</p> <p>A tree is either the child of another tree or the root of a nested tree. Traces can be exported as mappings from node identifiers to node origin information featuring id-based references (see <code>Trace</code>).</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.ChildOf","title":"ChildOf  <code>dataclass</code>","text":"<p>The tree of interest is the child of another one.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass ChildOf:\n    \"\"\"\n    The tree of interest is the child of another one.\n    \"\"\"\n\n    node: NodeId\n    action: ValueRef\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.refs.NestedTreeOf","title":"NestedTreeOf  <code>dataclass</code>","text":"<p>The tree of interest is the root of a tree that induces a given space.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass NestedTreeOf:\n    \"\"\"\n    The tree of interest is the root of a tree that induces a given\n    space.\n    \"\"\"\n\n    node: NodeId\n    space: SpaceRef\n</code></pre>"},{"location":"reference/strategies/traces/#tracked-values","title":"Tracked Values","text":""},{"location":"reference/strategies/traces/#delphyne.core.refs.Tracked","title":"Tracked  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[T]</code></p> <p>A tracked value, which pairs a value with a reference.</p> <p>Attributes:</p> Name Type Description <code>value</code> <code>T</code> <p>The value being tracked.</p> <code>ref</code> <code>AtomicValueRef</code> <p>A local reference to the value, relative to the node reference by the <code>node</code> field.</p> <code>node</code> <code>GlobalNodePath</code> <p>A global reference to the node to which the space that the value originates from is attached. In particular, this field is useful to check the locality invariant at runtime (e.g., when passing a tracked value to <code>Tree.child</code>).</p> <code>type_annot</code> <code>TypeAnnot[T] | NoTypeInfo</code> <p>An optional type annotation for the <code>value</code> field. This is mostly used for improving the rendering of values when exporting trace information for external tools.</p> <p>Tracked sequences (or pairs) can be indexed using <code>__getitem__</code>, resulting in tracked values with <code>IndexedRef</code> references. Since <code>__getitem__</code> is defined, tracked values are also iterable.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass Tracked(Generic[T]):\n    \"\"\"\n    A tracked value, which pairs a value with a reference.\n\n    Attributes:\n        value: The value being tracked.\n        ref: A local reference to the value, relative to the node\n            reference by the `node` field.\n        node: A global reference to the node to which the space that the\n            value originates from is attached. In particular, this field\n            is useful to check the locality invariant at runtime (e.g.,\n            when passing a tracked value to `Tree.child`).\n        type_annot: An optional type annotation for the `value` field.\n            This is mostly used for improving the rendering of values\n            when exporting trace information for external tools.\n\n    Tracked sequences (or pairs) can be indexed using `__getitem__`,\n    resulting in tracked values with `IndexedRef` references. Since\n    `__getitem__` is defined, tracked values are also iterable.\n    \"\"\"\n\n    value: T\n    ref: AtomicValueRef\n    node: GlobalNodePath\n    type_annot: TypeAnnot[T] | NoTypeInfo\n\n    @overload\n    def __getitem__[A, B](\n        self: \"Tracked[tuple[A, B]]\", index: Literal[0]\n    ) -&gt; \"Tracked[A]\": ...\n\n    @overload\n    def __getitem__[A, B](\n        self: \"Tracked[tuple[A, B]]\", index: Literal[1]\n    ) -&gt; \"Tracked[B]\": ...\n\n    @overload\n    def __getitem__[U](\n        self: \"Tracked[Sequence[U]]\", index: int\n    ) -&gt; \"Tracked[U]\": ...\n\n    def __getitem__[U](\n        self: \"Tracked[Sequence[U] | tuple[Any, ...]]\", index: int\n    ) -&gt; \"Tracked[U | Any]\":\n        return Tracked(\n            self.value[index],\n            IndexedRef(self.ref, index),\n            self.node,\n            insp.element_type_of_sequence_type(self.type_annot, index),\n        )\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.refs.Value","title":"Value","text":"<pre><code>Value = ExtAssembly[Tracked[Any]]\n</code></pre> <p>An assembly of local, tracked values.</p> <p>Values can serve as actions or space parameters.</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.ExtAssembly","title":"ExtAssembly","text":"<pre><code>ExtAssembly = T | None | Sequence[ExtAssembly[T]]\n</code></pre> <p>Generalizing <code>Assembly</code> to allow arbitrary sequences (and not just tuples). The distinction is important because <code>ValueRef</code> needs to be hashable and so cannot contain lists, while <code>Value</code> can contain lists.</p>"},{"location":"reference/strategies/traces/#delphyne.core.refs.check_local_value","title":"check_local_value","text":"<pre><code>check_local_value(val: Value, node: GlobalNodePath)\n</code></pre> <p>Raise a <code>LocalityError</code> exception if a given value is not a local value relative to a given node.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>def check_local_value(val: Value, node: GlobalNodePath):\n    \"\"\"\n    Raise a `LocalityError` exception if a given value is not a local\n    value relative to a given node.\n    \"\"\"\n    match val:\n        case None:\n            pass\n        case Sequence():\n            for v in val:\n                check_local_value(v, node)\n        case Tracked():\n            if val.node != node:\n                raise LocalityError(\n                    expected_node_ref=node,\n                    node_ref=val.node,\n                    local_ref=val.ref,\n                )\n        case _:\n            assert False\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.refs.LocalityError","title":"LocalityError  <code>dataclass</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when the locality invariant is violated.</p> <p>See <code>Tree</code> and <code>check_local_value</code>.</p> Source code in <code>src/delphyne/core/refs.py</code> <pre><code>@dataclass(frozen=True)\nclass LocalityError(Exception):\n    \"\"\"\n    Exception raised when the locality invariant is violated.\n\n    See `Tree` and `check_local_value`.\n    \"\"\"\n\n    expected_node_ref: GlobalNodePath\n    node_ref: GlobalNodePath\n    local_ref: AtomicValueRef\n</code></pre>"},{"location":"reference/strategies/traces/#traces","title":"Traces","text":""},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace","title":"Trace","text":"<p>A collection of reachable nodes and spaces, which is encoded in a concise way by introducing unique identifiers for answers and nodes.</p> <p>Traces are mutable. Methods are provided to convert full references into id-based references, creating fresh identifiers for new nodes and queries on the fly. Backward conversion methods are also provided for converting id-based references back into full references (assuming id-based references are valid, without which these methods fail with assertion errors).</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>dict[NodeId, NodeOrigin]</code> <p>a mapping from node identifiers to their origin.</p> <code>node_ids</code> <code>dict[NodeOrigin, NodeId]</code> <p>reverse map of <code>nodes</code>.</p> <code>answers</code> <code>dict[AnswerId, tuple[QueryOrigin, Answer]]</code> <p>a mapping from answer identifiers to actual answers, along with origin information on the associated query.</p> <code>answer_ids</code> <code>dict[QueryOrigin, dict[Answer, AnswerId]]</code> <p>reverse map of <code>answers</code>.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>class Trace:\n    \"\"\"\n    A collection of reachable nodes and spaces, which is encoded in a\n    concise way by introducing unique identifiers for answers and nodes.\n\n    Traces are mutable. Methods are provided to convert full references\n    into id-based references, creating fresh identifiers for new nodes\n    and queries on the fly. Backward conversion methods are also\n    provided for converting id-based references back into full\n    references (assuming id-based references are valid, without which\n    these methods fail with assertion errors).\n\n    Attributes:\n        nodes: a mapping from node identifiers to their origin.\n        node_ids: reverse map of `nodes`.\n        answers: a mapping from answer identifiers to actual answers,\n            along with origin information on the associated query.\n        answer_ids: reverse map of `answers`.\n    \"\"\"\n\n    GLOBAL_ORIGIN_ID = refs.NodeId(0)\n\n    def __init__(self):\n        \"\"\"\n        Create an empty trace.\n        \"\"\"\n        self.nodes: dict[refs.NodeId, refs.NodeOrigin] = {}\n        self.node_ids: dict[refs.NodeOrigin, refs.NodeId] = {}\n        self.answers: dict[refs.AnswerId, tuple[QueryOrigin, refs.Answer]] = {}\n        self.answer_ids: dict[\n            QueryOrigin, dict[refs.Answer, refs.AnswerId]\n        ] = {}\n        self._last_node_id: int = 0\n        self._last_answer_id: int = 0\n\n    def fresh_or_cached_node_id(self, origin: refs.NodeOrigin) -&gt; refs.NodeId:\n        \"\"\"\n        Obtain the identifier of a node described by its origin.\n        Create a new identifier on the fly if it does not exist yet.\n        \"\"\"\n        if origin in self.node_ids:\n            return self.node_ids[origin]\n        else:\n            self._last_node_id += 1\n            id = refs.NodeId(self._last_node_id)\n            self.nodes[id] = origin\n            self.node_ids[origin] = id\n            return id\n\n    def fresh_or_cached_answer_id(\n        self, answer: refs.Answer, origin: QueryOrigin\n    ) -&gt; refs.AnswerId:\n        \"\"\"\n        Obtain the identifier of an answer, given its content and the\n        origin of the query that it corresponds to. Create a new, fresh\n        identifier on the fly if it does not exist yet.\n        \"\"\"\n        if origin not in self.answer_ids:\n            self.answer_ids[origin] = {}\n        if answer in self.answer_ids[origin]:\n            return self.answer_ids[origin][answer]\n        else:\n            self._last_answer_id += 1\n            id = refs.AnswerId(self._last_answer_id)\n            self.answers[id] = (origin, answer)\n            self.answer_ids[origin][answer] = id\n            return id\n\n    def register_query(self, origin: QueryOrigin) -&gt; None:\n        \"\"\"\n        Ensure that a query appears in the trace, even if not answers\n        are associated with it yet.\n\n        This is particularly useful for the demonstration interpreter.\n        Indeed, when a test gets stuck on an unanswered query, it is\n        desirable for this query to be part of the returned trace so\n        that the user can visualize it.\n        \"\"\"\n        if origin not in self.answer_ids:\n            self.answer_ids[origin] = {}\n\n    def export(self) -&gt; ExportableTrace:\n        \"\"\"\n        Export a trace into a lightweight, serializable format.\n        \"\"\"\n        nodes = {\n            id.id: pprint.node_origin(origin)\n            for id, origin in self.nodes.items()\n        }\n        queries: list[ExportableQueryInfo] = []\n        for q, a in self.answer_ids.items():\n            ref = pprint.space_ref(q.ref)\n            answers = {id.id: value for value, id in a.items()}\n            queries.append(ExportableQueryInfo(q.node.id, ref, answers))\n        return ExportableTrace(nodes, queries)\n\n    def check_consistency(self) -&gt; None:\n        \"\"\"\n        Perform a sanity check on the trace.\n\n        Each node identifier is expanded into a full reference and then\n        converted back to an identifier, which must be equal to the\n        original one.\n        \"\"\"\n        for id in self.nodes:\n            expanded = self.expand_node_id(id)\n            assert id == self.convert_global_node_path(expanded)\n\n    ### Convert full references into id-based references\n\n    def convert_location(self, location: Location) -&gt; ShortLocation:\n        \"\"\"\n        Convert a full location into an id-based one.\n        \"\"\"\n        id = self.convert_global_node_path(location.node)\n        space = None\n        if location.space is not None:\n            space = self._convert_space_ref(id, location.space)\n        return ShortLocation(id, space)\n\n    def convert_query_origin(self, ref: refs.GlobalSpacePath) -&gt; QueryOrigin:\n        \"\"\"\n        Convert a full, global space reference denoting a quey origin\n        into an id-based reference.\n        \"\"\"\n        id = self.convert_global_node_path(ref[0])\n        space = self._convert_space_ref(id, ref[1])\n        origin = QueryOrigin(id, space)\n        self.register_query(origin)\n        return origin\n\n    def convert_answer_ref(\n        self, ref: tuple[refs.GlobalSpacePath, refs.Answer]\n    ) -&gt; refs.AnswerId:\n        \"\"\"\n        Convert a full answer reference into an answer id.\n        \"\"\"\n        node_path, space = ref[0]\n        id = self.convert_global_node_path(node_path)\n        space = self._convert_space_ref(id, space)\n        origin = QueryOrigin(id, space)\n        return self.fresh_or_cached_answer_id(ref[1], origin)\n\n    def convert_global_node_path(\n        self, path: refs.GlobalNodePath\n    ) -&gt; refs.NodeId:\n        \"\"\"\n        Convert a full, global node reference into an id-based one.\n        \"\"\"\n        id = Trace.GLOBAL_ORIGIN_ID\n        for space, node_path in path:\n            space_ref = self._convert_space_ref(id, space)\n            id = self.fresh_or_cached_node_id(refs.NestedTreeOf(id, space_ref))\n            id = self._convert_node_path(id, node_path)\n        return id\n\n    def convert_global_space_path(\n        self, path: refs.GlobalSpacePath\n    ) -&gt; refs.SpaceRef:\n        \"\"\"\n        Convert a full global space reference into an id-based one.\n        \"\"\"\n        node_path, space_ref = path\n        id = self.convert_global_node_path(node_path)\n        return self._convert_space_ref(id, space_ref)\n\n    def _convert_node_path(\n        self, id: refs.NodeId, path: refs.NodePath\n    ) -&gt; refs.NodeId:\n        \"\"\"\n        Convert a full local node path into an identifier, relative to a\n        given node.\n        \"\"\"\n        for a in path:\n            action_ref = self._convert_value_ref(id, a)\n            id = self.fresh_or_cached_node_id(refs.ChildOf(id, action_ref))\n        return id\n\n    def _convert_space_ref(\n        self, id: refs.NodeId, ref: refs.SpaceRef\n    ) -&gt; refs.SpaceRef:\n        \"\"\"\n        Convert a full local space reference into an id-based one, relative\n        to a given node.\n        \"\"\"\n        args = tuple(self._convert_value_ref(id, a) for a in ref.args)\n        return refs.SpaceRef(ref.name, args)\n\n    def _convert_atomic_value_ref(\n        self, id: refs.NodeId, ref: refs.AtomicValueRef\n    ) -&gt; refs.AtomicValueRef:\n        \"\"\"\n        Convert a full local atomic value reference into an id-based one,\n        relative to a given node.\n        \"\"\"\n        if isinstance(ref, refs.IndexedRef):\n            return refs.IndexedRef(\n                self._convert_atomic_value_ref(id, ref.ref), ref.index\n            )\n        else:\n            return self._convert_space_element_ref(id, ref)\n\n    def _convert_value_ref(\n        self, id: refs.NodeId, ref: refs.ValueRef\n    ) -&gt; refs.ValueRef:\n        \"\"\"\n        Convert a full local value reference into an id-based one,\n        relative to a given node.\n        \"\"\"\n        if ref is None:\n            return None\n        elif isinstance(ref, tuple):\n            return tuple(self._convert_value_ref(id, a) for a in ref)\n        else:\n            return self._convert_atomic_value_ref(id, ref)\n\n    def _convert_space_element_ref(\n        self, id: refs.NodeId, ref: refs.SpaceElementRef\n    ) -&gt; refs.SpaceElementRef:\n        \"\"\"\n        Convert a full local space element reference into an id-based one,\n        relative to a given node.\n        \"\"\"\n        space = None\n        if ref.space is not None:\n            space = self._convert_space_ref(id, ref.space)\n        match ref.element:\n            case refs.Answer():\n                assert space is not None\n                origin = QueryOrigin(id, space)\n                element = self.fresh_or_cached_answer_id(ref.element, origin)\n            case refs.AnswerId() | refs.NodeId():\n                element = ref.element\n            case refs.HintsRef():\n                assert False\n            case tuple():\n                assert space is not None\n                nested_root_orig = refs.NestedTreeOf(id, space)\n                nested_root = self.fresh_or_cached_node_id(nested_root_orig)\n                element = self._convert_node_path(nested_root, ref.element)\n        return refs.SpaceElementRef(space, element)\n\n    ### Reverse direction: expanding id-based references into full ones.\n\n    def expand_space_ref(\n        self, id: refs.NodeId, ref: refs.SpaceRef\n    ) -&gt; refs.SpaceRef:\n        \"\"\"\n        Convert a local id-based space reference into a full one,\n        relative to a given node.\n        \"\"\"\n        args = tuple(self.expand_value_ref(id, a) for a in ref.args)\n        return refs.SpaceRef(ref.name, args)\n\n    def expand_value_ref(\n        self, id: refs.NodeId, ref: refs.ValueRef\n    ) -&gt; refs.ValueRef:\n        \"\"\"\n        Convert a local id-based value reference into a full one,\n        relative to a given node.\n        \"\"\"\n        if ref is None:\n            return None\n        elif isinstance(ref, tuple):\n            return tuple(self.expand_value_ref(id, a) for a in ref)\n        else:\n            return self._expand_atomic_value_ref(id, ref)\n\n    def expand_node_id(self, id: refs.NodeId) -&gt; refs.GlobalNodePath:\n        \"\"\"\n        Convert a node identifier into a full, global node reference.\n        \"\"\"\n        rev_path: list[tuple[refs.SpaceRef, refs.NodePath]] = []\n        while id != Trace.GLOBAL_ORIGIN_ID:\n            id, space, path = self._recover_path(id)\n            rev_path.append((space, path))\n        return tuple(reversed(rev_path))\n\n    def _expand_atomic_value_ref(\n        self, id: refs.NodeId, ref: refs.AtomicValueRef\n    ) -&gt; refs.AtomicValueRef:\n        \"\"\"\n        Convert a local id-based atomic value reference into a full one,\n        relative to a given node.\n        \"\"\"\n        if isinstance(ref, refs.IndexedRef):\n            return refs.IndexedRef(\n                self._expand_atomic_value_ref(id, ref.ref), ref.index\n            )\n        else:\n            return self._expand_space_element_ref(id, ref)\n\n    def _expand_space_element_ref(\n        self, id: refs.NodeId, ref: refs.SpaceElementRef\n    ) -&gt; refs.SpaceElementRef:\n        \"\"\"\n        Convert a local id-based space element reference into a full\n        one, relative to a given node.\n        \"\"\"\n        assert isinstance(ref, refs.SpaceElementRef)\n        assert ref.space is not None\n        space = self.expand_space_ref(id, ref.space)\n        match ref.element:\n            case refs.AnswerId():\n                _orig, ans = self.answers[ref.element]\n                element = ans\n            case refs.NodeId():\n                orig, _, element = self._recover_path(ref.element)\n                assert orig == id\n            case _:\n                assert False\n        return refs.SpaceElementRef(space, element)\n\n    def _recover_path(\n        self, dst: refs.NodeId\n    ) -&gt; tuple[refs.NodeId, refs.SpaceRef, refs.NodePath]:\n        \"\"\"\n        Find the node from which the tree containing `dst` originates.\n\n        Return the node in which the full surrounding tree is nested,\n        the associated space reference, and a path to `dst` from the\n        root of the surrounding tree.\n        \"\"\"\n        rev_path: list[refs.ValueRef] = []\n        while True:\n            dst_origin = self.nodes[dst]\n            match dst_origin:\n                case refs.ChildOf(before, action):\n                    rev_path.append(self.expand_value_ref(before, action))\n                    dst = before\n                case refs.NestedTreeOf(orig, space):\n                    space = self.expand_space_ref(orig, space)\n                    return orig, space, tuple(reversed(rev_path))\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Create an empty trace.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Create an empty trace.\n    \"\"\"\n    self.nodes: dict[refs.NodeId, refs.NodeOrigin] = {}\n    self.node_ids: dict[refs.NodeOrigin, refs.NodeId] = {}\n    self.answers: dict[refs.AnswerId, tuple[QueryOrigin, refs.Answer]] = {}\n    self.answer_ids: dict[\n        QueryOrigin, dict[refs.Answer, refs.AnswerId]\n    ] = {}\n    self._last_node_id: int = 0\n    self._last_answer_id: int = 0\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.fresh_or_cached_node_id","title":"fresh_or_cached_node_id","text":"<pre><code>fresh_or_cached_node_id(origin: NodeOrigin) -&gt; NodeId\n</code></pre> <p>Obtain the identifier of a node described by its origin. Create a new identifier on the fly if it does not exist yet.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def fresh_or_cached_node_id(self, origin: refs.NodeOrigin) -&gt; refs.NodeId:\n    \"\"\"\n    Obtain the identifier of a node described by its origin.\n    Create a new identifier on the fly if it does not exist yet.\n    \"\"\"\n    if origin in self.node_ids:\n        return self.node_ids[origin]\n    else:\n        self._last_node_id += 1\n        id = refs.NodeId(self._last_node_id)\n        self.nodes[id] = origin\n        self.node_ids[origin] = id\n        return id\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.fresh_or_cached_answer_id","title":"fresh_or_cached_answer_id","text":"<pre><code>fresh_or_cached_answer_id(answer: Answer, origin: QueryOrigin) -&gt; AnswerId\n</code></pre> <p>Obtain the identifier of an answer, given its content and the origin of the query that it corresponds to. Create a new, fresh identifier on the fly if it does not exist yet.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def fresh_or_cached_answer_id(\n    self, answer: refs.Answer, origin: QueryOrigin\n) -&gt; refs.AnswerId:\n    \"\"\"\n    Obtain the identifier of an answer, given its content and the\n    origin of the query that it corresponds to. Create a new, fresh\n    identifier on the fly if it does not exist yet.\n    \"\"\"\n    if origin not in self.answer_ids:\n        self.answer_ids[origin] = {}\n    if answer in self.answer_ids[origin]:\n        return self.answer_ids[origin][answer]\n    else:\n        self._last_answer_id += 1\n        id = refs.AnswerId(self._last_answer_id)\n        self.answers[id] = (origin, answer)\n        self.answer_ids[origin][answer] = id\n        return id\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.register_query","title":"register_query","text":"<pre><code>register_query(origin: QueryOrigin) -&gt; None\n</code></pre> <p>Ensure that a query appears in the trace, even if not answers are associated with it yet.</p> <p>This is particularly useful for the demonstration interpreter. Indeed, when a test gets stuck on an unanswered query, it is desirable for this query to be part of the returned trace so that the user can visualize it.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def register_query(self, origin: QueryOrigin) -&gt; None:\n    \"\"\"\n    Ensure that a query appears in the trace, even if not answers\n    are associated with it yet.\n\n    This is particularly useful for the demonstration interpreter.\n    Indeed, when a test gets stuck on an unanswered query, it is\n    desirable for this query to be part of the returned trace so\n    that the user can visualize it.\n    \"\"\"\n    if origin not in self.answer_ids:\n        self.answer_ids[origin] = {}\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.export","title":"export","text":"<pre><code>export() -&gt; ExportableTrace\n</code></pre> <p>Export a trace into a lightweight, serializable format.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def export(self) -&gt; ExportableTrace:\n    \"\"\"\n    Export a trace into a lightweight, serializable format.\n    \"\"\"\n    nodes = {\n        id.id: pprint.node_origin(origin)\n        for id, origin in self.nodes.items()\n    }\n    queries: list[ExportableQueryInfo] = []\n    for q, a in self.answer_ids.items():\n        ref = pprint.space_ref(q.ref)\n        answers = {id.id: value for value, id in a.items()}\n        queries.append(ExportableQueryInfo(q.node.id, ref, answers))\n    return ExportableTrace(nodes, queries)\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.check_consistency","title":"check_consistency","text":"<pre><code>check_consistency() -&gt; None\n</code></pre> <p>Perform a sanity check on the trace.</p> <p>Each node identifier is expanded into a full reference and then converted back to an identifier, which must be equal to the original one.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def check_consistency(self) -&gt; None:\n    \"\"\"\n    Perform a sanity check on the trace.\n\n    Each node identifier is expanded into a full reference and then\n    converted back to an identifier, which must be equal to the\n    original one.\n    \"\"\"\n    for id in self.nodes:\n        expanded = self.expand_node_id(id)\n        assert id == self.convert_global_node_path(expanded)\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.convert_location","title":"convert_location","text":"<pre><code>convert_location(location: Location) -&gt; ShortLocation\n</code></pre> <p>Convert a full location into an id-based one.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def convert_location(self, location: Location) -&gt; ShortLocation:\n    \"\"\"\n    Convert a full location into an id-based one.\n    \"\"\"\n    id = self.convert_global_node_path(location.node)\n    space = None\n    if location.space is not None:\n        space = self._convert_space_ref(id, location.space)\n    return ShortLocation(id, space)\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.convert_query_origin","title":"convert_query_origin","text":"<pre><code>convert_query_origin(ref: GlobalSpacePath) -&gt; QueryOrigin\n</code></pre> <p>Convert a full, global space reference denoting a quey origin into an id-based reference.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def convert_query_origin(self, ref: refs.GlobalSpacePath) -&gt; QueryOrigin:\n    \"\"\"\n    Convert a full, global space reference denoting a quey origin\n    into an id-based reference.\n    \"\"\"\n    id = self.convert_global_node_path(ref[0])\n    space = self._convert_space_ref(id, ref[1])\n    origin = QueryOrigin(id, space)\n    self.register_query(origin)\n    return origin\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.convert_answer_ref","title":"convert_answer_ref","text":"<pre><code>convert_answer_ref(ref: tuple[GlobalSpacePath, Answer]) -&gt; AnswerId\n</code></pre> <p>Convert a full answer reference into an answer id.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def convert_answer_ref(\n    self, ref: tuple[refs.GlobalSpacePath, refs.Answer]\n) -&gt; refs.AnswerId:\n    \"\"\"\n    Convert a full answer reference into an answer id.\n    \"\"\"\n    node_path, space = ref[0]\n    id = self.convert_global_node_path(node_path)\n    space = self._convert_space_ref(id, space)\n    origin = QueryOrigin(id, space)\n    return self.fresh_or_cached_answer_id(ref[1], origin)\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.convert_global_node_path","title":"convert_global_node_path","text":"<pre><code>convert_global_node_path(path: GlobalNodePath) -&gt; NodeId\n</code></pre> <p>Convert a full, global node reference into an id-based one.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def convert_global_node_path(\n    self, path: refs.GlobalNodePath\n) -&gt; refs.NodeId:\n    \"\"\"\n    Convert a full, global node reference into an id-based one.\n    \"\"\"\n    id = Trace.GLOBAL_ORIGIN_ID\n    for space, node_path in path:\n        space_ref = self._convert_space_ref(id, space)\n        id = self.fresh_or_cached_node_id(refs.NestedTreeOf(id, space_ref))\n        id = self._convert_node_path(id, node_path)\n    return id\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.convert_global_space_path","title":"convert_global_space_path","text":"<pre><code>convert_global_space_path(path: GlobalSpacePath) -&gt; SpaceRef\n</code></pre> <p>Convert a full global space reference into an id-based one.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def convert_global_space_path(\n    self, path: refs.GlobalSpacePath\n) -&gt; refs.SpaceRef:\n    \"\"\"\n    Convert a full global space reference into an id-based one.\n    \"\"\"\n    node_path, space_ref = path\n    id = self.convert_global_node_path(node_path)\n    return self._convert_space_ref(id, space_ref)\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.expand_space_ref","title":"expand_space_ref","text":"<pre><code>expand_space_ref(id: NodeId, ref: SpaceRef) -&gt; SpaceRef\n</code></pre> <p>Convert a local id-based space reference into a full one, relative to a given node.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def expand_space_ref(\n    self, id: refs.NodeId, ref: refs.SpaceRef\n) -&gt; refs.SpaceRef:\n    \"\"\"\n    Convert a local id-based space reference into a full one,\n    relative to a given node.\n    \"\"\"\n    args = tuple(self.expand_value_ref(id, a) for a in ref.args)\n    return refs.SpaceRef(ref.name, args)\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.expand_value_ref","title":"expand_value_ref","text":"<pre><code>expand_value_ref(id: NodeId, ref: ValueRef) -&gt; ValueRef\n</code></pre> <p>Convert a local id-based value reference into a full one, relative to a given node.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def expand_value_ref(\n    self, id: refs.NodeId, ref: refs.ValueRef\n) -&gt; refs.ValueRef:\n    \"\"\"\n    Convert a local id-based value reference into a full one,\n    relative to a given node.\n    \"\"\"\n    if ref is None:\n        return None\n    elif isinstance(ref, tuple):\n        return tuple(self.expand_value_ref(id, a) for a in ref)\n    else:\n        return self._expand_atomic_value_ref(id, ref)\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Trace.expand_node_id","title":"expand_node_id","text":"<pre><code>expand_node_id(id: NodeId) -&gt; GlobalNodePath\n</code></pre> <p>Convert a node identifier into a full, global node reference.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def expand_node_id(self, id: refs.NodeId) -&gt; refs.GlobalNodePath:\n    \"\"\"\n    Convert a node identifier into a full, global node reference.\n    \"\"\"\n    rev_path: list[tuple[refs.SpaceRef, refs.NodePath]] = []\n    while id != Trace.GLOBAL_ORIGIN_ID:\n        id, space, path = self._recover_path(id)\n        rev_path.append((space, path))\n    return tuple(reversed(rev_path))\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.QueryOrigin","title":"QueryOrigin  <code>dataclass</code>","text":"<p>A global, id-based reference to the space induced by a query.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>@dataclass(frozen=True)\nclass QueryOrigin:\n    \"\"\"\n    A global, id-based reference to the space induced by a query.\n    \"\"\"\n\n    node: refs.NodeId\n    ref: refs.SpaceRef\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.ExportableTrace","title":"ExportableTrace  <code>dataclass</code>","text":"<p>A lightweight trace format that can be easily exported to JSON/YAML.</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>dict[int, NodeOriginStr]</code> <p>a mapping from node ids to serialized origin information.</p> <code>queries</code> <code>list[ExportableQueryInfo]</code> <p>a list of encountered queries with associated answers.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>@dataclass\nclass ExportableTrace:\n    \"\"\"\n    A lightweight trace format that can be easily exported to JSON/YAML.\n\n    Attributes:\n        nodes: a mapping from node ids to serialized origin information.\n        queries: a list of encountered queries with associated answers.\n    \"\"\"\n\n    nodes: dict[int, NodeOriginStr]\n    queries: list[ExportableQueryInfo]\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.ExportableQueryInfo","title":"ExportableQueryInfo  <code>dataclass</code>","text":"<p>Information about a query encountered in an exportable trace.</p> <p>Attributes:</p> Name Type Description <code>node</code> <code>int</code> <p>Identifier of the node that the query is attached to.</p> <code>space</code> <code>str</code> <p>Local, id-based reference of the space that the query belongs to. Serialized using <code>pprint.space_ref</code>.</p> <code>answers</code> <code>dict[int, Answer]</code> <p>Mapping from answer identifiers to actual answers. Answer identifiers are unique across a whole exportable trace (and not only across an <code>ExportableQueryInfo</code> value).</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>@dataclass\nclass ExportableQueryInfo:\n    \"\"\"\n    Information about a query encountered in an exportable trace.\n\n    Attributes:\n        node: Identifier of the node that the query is attached to.\n        space: Local, id-based reference of the space that the query\n            belongs to. Serialized using `pprint.space_ref`.\n        answers: Mapping from answer identifiers to actual answers.\n            Answer identifiers are unique across a whole exportable\n            trace (and not only across an `ExportableQueryInfo` value).\n    \"\"\"\n\n    node: int\n    space: str\n    answers: dict[int, refs.Answer]\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.NodeOriginStr","title":"NodeOriginStr","text":"<pre><code>NodeOriginStr = str\n</code></pre> <p>A concise, serialized representation for <code>NodeOrigin</code>.</p>"},{"location":"reference/strategies/traces/#delphyne.core.traces.Location","title":"Location  <code>dataclass</code>","text":"<p>A full, global reference to either a node or a space.</p> <p>This is useful in particular for attaching location information to logging messages.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>@dataclass(frozen=True)\nclass Location:\n    \"\"\"\n    A **full**, global reference to either a node or a space.\n\n    This is useful in particular for attaching location information to\n    logging messages.\n    \"\"\"\n\n    node: refs.GlobalNodePath\n    space: refs.SpaceRef | None\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.core.traces.ShortLocation","title":"ShortLocation  <code>dataclass</code>","text":"<p>An id-based, global reference to either a node or a space.</p> <p>This is the id-based counterpart of <code>Location</code>. Policies typically log messages with <code>Location</code> values attached (since trees feature full references), which are then converted into <code>ShortLocation</code> in the final exportable log.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>@dataclass(frozen=True)\nclass ShortLocation:\n    \"\"\"\n    An **id-based**, global reference to either a node or a space.\n\n    This is the id-based counterpart of `Location`. Policies typically\n    log messages with `Location` values attached (since trees feature\n    full references), which are then converted into `ShortLocation` in\n    the final exportable log.\n    \"\"\"\n\n    node: refs.NodeId\n    space: refs.SpaceRef | None\n</code></pre>"},{"location":"reference/strategies/traces/#tracers","title":"Tracers","text":""},{"location":"reference/strategies/traces/#delphyne.Tracer","title":"Tracer","text":"<p>A mutable trace along with a mutable list of log messages.</p> <p>Both components are protected by a lock to ensure thread-safety (some policies spawn multiple concurrent threads).</p> <p>Attributes:</p> Name Type Description <code>trace</code> <p>A mutable trace.</p> <code>messages</code> <code>list[LogMessage]</code> <p>A mutable list of log messages.</p> <code>lock</code> <p>A reentrant lock protecting access to the trace and log. The lock is publicly exposed so that threads can log several successive messages without other threads interleaving new messages in between (TODO: there are cleaner ways to achieve this).</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>class Tracer:\n    \"\"\"\n    A mutable trace along with a mutable list of log messages.\n\n    Both components are protected by a lock to ensure thread-safety\n    (some policies spawn multiple concurrent threads).\n\n    Attributes:\n        trace: A mutable trace.\n        messages: A mutable list of log messages.\n        lock: A reentrant lock protecting access to the trace and log.\n            The lock is publicly exposed so that threads can log several\n            successive messages without other threads interleaving new\n            messages in between (TODO: there are cleaner ways to achieve\n            this).\n    \"\"\"\n\n    def __init__(self):\n        self.trace = Trace()\n        self.messages: list[LogMessage] = []\n\n        # Different threads may be logging information or appending to\n        # the trace in parallel.\n        self.lock = threading.RLock()\n\n    def trace_node(self, node: refs.GlobalNodePath) -&gt; None:\n        \"\"\"\n        Ensure that a node at a given reference is present in the trace.\n\n        See `tracer_hook` for registering a hook that automatically\n        calls this method on all encountered nodes.\n        \"\"\"\n        with self.lock:\n            self.trace.convert_location(Location(node, None))\n\n    def trace_query(self, ref: refs.GlobalSpacePath) -&gt; None:\n        \"\"\"\n        Ensure that a query at a given reference is present in the\n        trace, even if no answer is provided for it.\n        \"\"\"\n        with self.lock:\n            self.trace.convert_query_origin(ref)\n\n    def trace_answer(\n        self, space: refs.GlobalSpacePath, answer: refs.Answer\n    ) -&gt; None:\n        \"\"\"\n        Ensure that a given query answer is present in the trace, even\n        it is is not used to reach a node.\n        \"\"\"\n        with self.lock:\n            self.trace.convert_answer_ref((space, answer))\n\n    def log(\n        self,\n        message: str,\n        metadata: dict[str, Any] | None = None,\n        location: Location | None = None,\n    ):\n        \"\"\"\n        Log a message, with optional metadata and location information.\n        The metadata must be a dictionary of JSON values.\n        \"\"\"\n        with self.lock:\n            short_location = None\n            if location is not None:\n                short_location = self.trace.convert_location(location)\n            self.messages.append(LogMessage(message, metadata, short_location))\n\n    def export_log(self) -&gt; Iterable[ExportableLogMessage]:\n        \"\"\"\n        Export the log into an easily serializable format.\n        \"\"\"\n        with self.lock:\n            for m in self.messages:\n                node = None\n                space = None\n                if (loc := m.location) is not None:\n                    node = loc.node.id\n                    if loc.space is not None:\n                        space = pprint.space_ref(loc.space)\n                yield ExportableLogMessage(m.message, node, space, m.metadata)\n\n    def export_trace(self) -&gt; ExportableTrace:\n        \"\"\"\n        Export the trace into an easily serializable format.\n        \"\"\"\n        with self.lock:\n            return self.trace.export()\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.Tracer.trace_node","title":"trace_node","text":"<pre><code>trace_node(node: GlobalNodePath) -&gt; None\n</code></pre> <p>Ensure that a node at a given reference is present in the trace.</p> <p>See <code>tracer_hook</code> for registering a hook that automatically calls this method on all encountered nodes.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def trace_node(self, node: refs.GlobalNodePath) -&gt; None:\n    \"\"\"\n    Ensure that a node at a given reference is present in the trace.\n\n    See `tracer_hook` for registering a hook that automatically\n    calls this method on all encountered nodes.\n    \"\"\"\n    with self.lock:\n        self.trace.convert_location(Location(node, None))\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.Tracer.trace_query","title":"trace_query","text":"<pre><code>trace_query(ref: GlobalSpacePath) -&gt; None\n</code></pre> <p>Ensure that a query at a given reference is present in the trace, even if no answer is provided for it.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def trace_query(self, ref: refs.GlobalSpacePath) -&gt; None:\n    \"\"\"\n    Ensure that a query at a given reference is present in the\n    trace, even if no answer is provided for it.\n    \"\"\"\n    with self.lock:\n        self.trace.convert_query_origin(ref)\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.Tracer.trace_answer","title":"trace_answer","text":"<pre><code>trace_answer(space: GlobalSpacePath, answer: Answer) -&gt; None\n</code></pre> <p>Ensure that a given query answer is present in the trace, even it is is not used to reach a node.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def trace_answer(\n    self, space: refs.GlobalSpacePath, answer: refs.Answer\n) -&gt; None:\n    \"\"\"\n    Ensure that a given query answer is present in the trace, even\n    it is is not used to reach a node.\n    \"\"\"\n    with self.lock:\n        self.trace.convert_answer_ref((space, answer))\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.Tracer.log","title":"log","text":"<pre><code>log(\n    message: str,\n    metadata: dict[str, Any] | None = None,\n    location: Location | None = None,\n)\n</code></pre> <p>Log a message, with optional metadata and location information. The metadata must be a dictionary of JSON values.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def log(\n    self,\n    message: str,\n    metadata: dict[str, Any] | None = None,\n    location: Location | None = None,\n):\n    \"\"\"\n    Log a message, with optional metadata and location information.\n    The metadata must be a dictionary of JSON values.\n    \"\"\"\n    with self.lock:\n        short_location = None\n        if location is not None:\n            short_location = self.trace.convert_location(location)\n        self.messages.append(LogMessage(message, metadata, short_location))\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.Tracer.export_log","title":"export_log","text":"<pre><code>export_log() -&gt; Iterable[ExportableLogMessage]\n</code></pre> <p>Export the log into an easily serializable format.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def export_log(self) -&gt; Iterable[ExportableLogMessage]:\n    \"\"\"\n    Export the log into an easily serializable format.\n    \"\"\"\n    with self.lock:\n        for m in self.messages:\n            node = None\n            space = None\n            if (loc := m.location) is not None:\n                node = loc.node.id\n                if loc.space is not None:\n                    space = pprint.space_ref(loc.space)\n            yield ExportableLogMessage(m.message, node, space, m.metadata)\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.Tracer.export_trace","title":"export_trace","text":"<pre><code>export_trace() -&gt; ExportableTrace\n</code></pre> <p>Export the trace into an easily serializable format.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def export_trace(self) -&gt; ExportableTrace:\n    \"\"\"\n    Export the trace into an easily serializable format.\n    \"\"\"\n    with self.lock:\n        return self.trace.export()\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.LogMessage","title":"LogMessage  <code>dataclass</code>","text":"<p>A log message.</p> <p>Attributes:</p> Name Type Description <code>message</code> <code>str</code> <p>The message to log.</p> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata associated with the message, as a dictionary mapping string keys to JSON values.</p> <code>location</code> <code>ShortLocation | None</code> <p>An optional location in the strategy tree where the message was logged, if applicable.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>@dataclass(frozen=True)\nclass LogMessage:\n    \"\"\"\n    A log message.\n\n    Attributes:\n        message: The message to log.\n        metadata: Optional metadata associated with the message, as a\n            dictionary mapping string keys to JSON values.\n        location: An optional location in the strategy tree where the\n            message was logged, if applicable.\n    \"\"\"\n\n    message: str\n    metadata: dict[str, Any] | None = None\n    location: ShortLocation | None = None\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.ExportableLogMessage","title":"ExportableLogMessage  <code>dataclass</code>","text":"<p>An exportable log message, as a dataclass whose fields are JSON values (as opposed to <code>LogMessage</code>) and is thus easier to export.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>@dataclass(frozen=True)\nclass ExportableLogMessage:\n    \"\"\"\n    An exportable log message, as a dataclass whose fields are JSON\n    values (as opposed to `LogMessage`) and is thus easier to export.\n    \"\"\"\n\n    message: str\n    node: int | None\n    space: str | None\n    metadata: dict[str, Any] | None = None\n</code></pre>"},{"location":"reference/strategies/traces/#delphyne.tracer_hook","title":"tracer_hook","text":"<pre><code>tracer_hook(tracer: Tracer) -&gt; Callable[[Tree[Any, Any, Any]], None]\n</code></pre> <p>Standard hook to be passed to <code>TreeMonitor</code> to automatically log visited nodes into a trace.</p> Source code in <code>src/delphyne/core/traces.py</code> <pre><code>def tracer_hook(tracer: Tracer) -&gt; Callable[[Tree[Any, Any, Any]], None]:\n    \"\"\"\n    Standard hook to be passed to `TreeMonitor` to automatically log\n    visited nodes into a trace.\n    \"\"\"\n    return lambda tree: tracer.trace_node(tree.ref)\n</code></pre>"},{"location":"reference/strategies/trees/","title":"Trees and Spaces","text":""},{"location":"reference/strategies/trees/#trees","title":"Trees","text":""},{"location":"reference/strategies/trees/#delphyne.Tree","title":"Tree  <code>dataclass</code>","text":"<p>               Bases: <code>Generic[N, P, T]</code></p> <p>Strategy Trees.</p> <p>A strategy tree can be obtained by reifying a strategy computation (see <code>reify</code>). Its type parameters are: a type signature <code>N</code>, an associated inner policy type <code>P</code>, and a return type <code>T</code>.</p> <p>Trees are immutable.</p> <p>Attributes:</p> Name Type Description <code>node</code> <code>N | Success[T]</code> <p>The current node of the tree, which is either a success leaf or a node of type compatible with signature <code>N</code>.</p> <code>child</code> <code>Callable[[Value], Tree[N, P, T]]</code> <p>A function that maps an action (i.e., a local value) to a child tree.</p> <code>ref</code> <code>GlobalNodePath</code> <p>A global reference to the node.</p> <p>Locality Invariant</p> <p>Only local values can be used as actions (passed to <code>child</code>) or as arguments of parametric local spaces. A local value consists in an assembly of elements of local spaces (see <code>Value</code>). This invariant is enforced at runtime and it guarantees that a policy can always make progress at any given node without being provided additional context. It is also a key assumption for establishing the completeness of the demonstration language (i.e., a demonstration with a single <code>run | success</code> test can always be extracted from a successful run of an oracular program).</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass(frozen=True)\nclass Tree(Generic[N, P, T]):\n    \"\"\"\n    Strategy Trees.\n\n    A strategy tree can be obtained by reifying a strategy computation\n    (see `reify`). Its type parameters are: a type signature `N`, an\n    associated inner policy type `P`, and a return type `T`.\n\n    Trees are **immutable**.\n\n    Attributes:\n        node: The current node of the tree, which is either a success\n            leaf or a node of type compatible with signature `N`.\n        child: A function that maps an action (i.e., a local value) to a\n            child tree.\n        ref: A global reference to the node.\n\n    !!! info \"Locality Invariant\"\n        Only *local values* can be used as actions (passed to `child`)\n        or as arguments of parametric local spaces. A *local value*\n        consists in an assembly of elements of local spaces (see\n        `Value`). This invariant is enforced at runtime and it\n        guarantees that a policy can always make progress at any given\n        node without being provided additional context. It is also a key\n        assumption for establishing the completeness of the\n        demonstration language (i.e., a demonstration with a single `run\n        | success` test can always be extracted from a successful run of\n        an oracular program).\n    \"\"\"\n\n    node: \"N | Success[T]\"\n    child: \"Callable[[Value], Tree[N, P, T]]\"\n    ref: GlobalNodePath\n\n    def transform[M: Node](\n        self,\n        node: \"M | Success[T]\",\n        transformer: \"AbstractTreeTransformer[N, M]\",\n    ) -&gt; \"Tree[M, P, T]\":\n        \"\"\"\n        Recursively apply a function to all embedded trees and subtrees\n        of a tree.\n\n        This is a pure method that does not modify its arguments. It is\n        useful to implement tree transformers such as `elim_compute`.\n        \"\"\"\n\n        def child(action: Value) -&gt; Tree[M, P, T]:\n            return transformer(self.child(action))\n\n        node = node.map_embedded(transformer)\n        return Tree(node, child, self.ref)\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Tree.transform","title":"transform","text":"<pre><code>transform(\n    node: M | Success[T], transformer: AbstractTreeTransformer[N, M]\n) -&gt; Tree[M, P, T]\n</code></pre> <p>Recursively apply a function to all embedded trees and subtrees of a tree.</p> <p>This is a pure method that does not modify its arguments. It is useful to implement tree transformers such as <code>elim_compute</code>.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def transform[M: Node](\n    self,\n    node: \"M | Success[T]\",\n    transformer: \"AbstractTreeTransformer[N, M]\",\n) -&gt; \"Tree[M, P, T]\":\n    \"\"\"\n    Recursively apply a function to all embedded trees and subtrees\n    of a tree.\n\n    This is a pure method that does not modify its arguments. It is\n    useful to implement tree transformers such as `elim_compute`.\n    \"\"\"\n\n    def child(action: Value) -&gt; Tree[M, P, T]:\n        return transformer(self.child(action))\n\n    node = node.map_embedded(transformer)\n    return Tree(node, child, self.ref)\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Success","title":"Success  <code>dataclass</code>","text":"<p>A success leaf, carrying a tracked value.</p> Implementation Note <p>Although it largely implements the same interface via duck typing, <code>Success</code> does not inherit <code>Node</code>. The reason is that <code>Tree[N, P, T].node</code> has type <code>Success[T] | N</code>. If <code>Success</code> inherited <code>Node</code>, it would be possible for <code>N</code> to include a value of type <code>Success[T2]</code> for some <code>T2 != T</code>, which we want to rule out.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass(frozen=True)\nclass Success[T]:\n    \"\"\"\n    A success leaf, carrying a tracked value.\n\n    ??? note \"Implementation Note\"\n        Although it largely implements the same interface via duck\n        typing, `Success` does not inherit `Node`. The reason is that\n        `Tree[N, P, T].node` has type `Success[T] | N`. If `Success`\n        inherited `Node`, it would be possible for `N` to include a\n        value of type `Success[T2]` for some `T2 != T`, which we want to\n        rule out.\n    \"\"\"\n\n    success: Tracked[T]\n\n    def leaf_node(self) -&gt; bool:\n        return True\n\n    def valid_action(self, action: object) -&gt; bool:\n        return False\n\n    def navigate(self) -&gt; Navigation:\n        assert False\n\n    def summary_message(self) -&gt; str | None:\n        return None\n\n    def primary_space(self) -&gt; None:\n        return None\n\n    def primary_space_ref(self) -&gt; None:\n        return None\n\n    def effect_name(self) -&gt; str:\n        return self.__class__.__name__\n\n    def get_tags(self) -&gt; Sequence[Tag]:\n        return ()\n\n    def nested_space(\n        self, name: refs.SpaceName, args: tuple[Value, ...]\n    ) -&gt; Space[Any] | None:\n        return None\n\n    def map_embedded(\n        self, trans: \"AbstractTreeTransformer[Any, Any]\"\n    ) -&gt; \"Success[T]\":\n        return self\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node","title":"Node","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract type for a tree node.</p> <p>New effects can be added to the strategy language by subclassing <code>Node</code> and then defining a triggering function that calls the <code>spawn</code> class method (manually defining such a wrapper allows providing users with precise type annotations: i.e., <code>branch</code> for <code>Branch</code>).</p> <p>Methods to override:</p> <ul> <li>The <code>navigate</code> method must be overriden for all node types.</li> <li>The <code>leaf_node</code> method must be overriden for all leaf nodes.</li> <li>The following methods are also frequently overriden:     <code>summary_message</code>, <code>valid_action</code>, <code>primary_space</code>, and     <code>get_extra_tags</code>.</li> </ul> <p>Other methods are implemented via inspection and are not typically overriden.</p> On the absence of type parameters <p>In order to precisely type the fields of node subclasses (e.g. <code>Branch</code>), <code>Node</code> would need to have type parameters standing for the surrounding inner policy type, the action type, etc. However, Python's type system is not expressive enough to properly constrain such type parameters in the definition of trees since it lacks GADTs and higher-kinded types. In particular, the way we express signatures as unions of subtypes of <code>Node</code> would not work if <code>Node</code> were parametric.</p> <p>As a result, types such as inner policy types and action types must be represented using <code>Any</code> in the definition of nodes (e.g. <code>Branch</code>) and the type safety of search policy implementations (e.g. <code>dfs</code>) cannot be fully enforced statically. However, effect triggering functions such as <code>branch</code> can typically be typed precisely, providing static type safety for strategy writers.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>class Node(ABC):\n    \"\"\"\n    Abstract type for a tree node.\n\n    New effects can be added to the strategy language by subclassing\n    `Node` and then defining a triggering function that calls the\n    `spawn` class method (manually defining such a wrapper allows\n    providing users with precise type annotations: i.e., `branch` for\n    `Branch`).\n\n    **Methods to override:**\n\n    - The `navigate` method must be overriden for all node types.\n    - The `leaf_node` method must be overriden for all leaf nodes.\n    - The following methods are also frequently overriden:\n        `summary_message`, `valid_action`, `primary_space`, and\n        `get_extra_tags`.\n\n    Other methods are implemented via inspection and are not typically\n    overriden.\n\n    ??? note \"On the absence of type parameters\"\n        In order to precisely type the fields of node subclasses (e.g.\n        `Branch`), `Node` would need to have type parameters standing\n        for the surrounding inner policy type, the action type, etc.\n        However, Python's type system is not expressive enough to\n        properly constrain such type parameters in the definition of\n        trees since it lacks GADTs and higher-kinded types. In\n        particular, the way we express signatures as unions of subtypes\n        of `Node` would not work if `Node` were parametric.\n\n        As a result, types such as inner policy types and action types\n        must be represented using `Any` in the definition of nodes (e.g.\n        `Branch`) and the type safety of search policy implementations\n        (e.g. `dfs`) cannot be fully enforced statically. However,\n        effect *triggering functions* such as `branch` can typically be\n        typed precisely, providing static type safety for strategy\n        writers.\n    \"\"\"\n\n    # Methods that **must** be overriden\n\n    @abstractmethod\n    def navigate(self) -&gt; \"Navigation\":\n        \"\"\"\n        The navigation method, to be defined for each node type.\n\n        It should only be called when `self.leaf_node()` returns False.\n\n        See `Navigation` for details.\n        \"\"\"\n        pass\n\n    # Methods that are _sometimes_ overriden\n\n    def summary_message(self) -&gt; str | None:\n        \"\"\"\n        Return an optional summary message for the node, to be\n        displayed in the Delphyne extension's Tree View.\n        \"\"\"\n        return None\n\n    def leaf_node(self) -&gt; bool:\n        \"\"\"\n        Return True if the node is a leaf node (e.g., `Fail`) and False\n        otherwise.\n\n        Leaf nodes do not have to define `navigate` and are treated\n        specially by the demonstration interpreter.\n        \"\"\"\n        return False\n\n    def valid_action(self, action: object) -&gt; bool:\n        \"\"\"\n        Return whether an action is valid.\n\n        This method is used to dynamically check actions passed to\n        `Tree.child`, **after** the `Tracked` wrapper is removed. By\n        default, it always returns `True` (unless the node is a leaf\n        node, in which case it returns `False`).\n        \"\"\"\n        return False if self.leaf_node() else True\n\n    def primary_space(self) -&gt; \"Space[object] | None\":\n        \"\"\"\n        Optionally return the node's primary space.\n\n        Primary spaces are useful to shorten space references,\n        especially when writing demonstration tests. For example, if\n        `cands` is the primary space of the current node, then\n        `compare([cands{''}, cands{'foo bar'}])` can be abbreviated into\n        `compare(['', 'foo bar'])`.\n\n        By default, all tags of a node's primary space are also\n        inherited by this node (see `get_tags` method).\n        \"\"\"\n        return None\n\n    def get_extra_tags(self) -&gt; Sequence[Tag]:\n        \"\"\"\n        Return the extra tags associated with the node, in addition to\n        the default ones inherited from the primary space (see\n        `get_tags` method).\n        \"\"\"\n        return []\n\n    # Inspecting the kinds of node fields\n\n    @classmethod\n    def fields(cls) -&gt; NodeFields:\n        \"\"\"\n        Return a dictionary mapping each field of the node to some\n        metadata (e.g., whether the field denotes a local space).\n\n        Such metadata is useful in particular to implement `spawn`.\n\n        The default implementation uses inspection, via\n        `detect_node_structure`. See the\n        [`node_fields`][delphyne.core.node_fields] module for details.\n        \"\"\"\n        f = detect_node_structure(\n            cls, embedded_class=EmbeddedTree, space_class=Space\n        )\n        if f is None:\n            msg = f\"Impossible to autodetect the structure of {cls}\"\n            assert False, msg\n        return f\n\n    # Methods with a sensible default behavior that are _rarely_ overriden\n\n    def effect_name(self) -&gt; str:\n        \"\"\"\n        Name of the associated effect.\n\n        Used for generating message errors and in the VSCode extension.\n        \"\"\"\n        return self.__class__.__name__\n\n    def get_tags(self) -&gt; Sequence[Tag]:\n        \"\"\"\n        Return all tags attached to the node.\n\n        Tags are leveraged by the demonstration language to identify\n        nodes (e.g., `at` test command).\n\n        By default, this method returns all tags from the primary space\n        (if any), along with any additional tag returned by\n        `get_extra_tags`.\n        \"\"\"\n        if (primary := self.primary_space()) is not None:\n            return [*primary.tags(), *self.get_extra_tags()]\n        return self.get_extra_tags()\n\n    # Methods that should not be overriden\n\n    @final\n    def primary_space_ref(self) -&gt; refs.SpaceRef | None:\n        \"\"\"\n        Convenience method for returning a reference to the node's\n        primary space, if it is defined.\n        \"\"\"\n        space = self.primary_space()\n        if space is None:\n            return None\n        return space.source().ref[1]\n\n    @final\n    def nested_space(\n        self, name: refs.SpaceName, args: tuple[Value, ...]\n    ) -&gt; Space[Any] | None:\n        \"\"\"\n        Dynamically retrieve a local space given its name and\n        parameters.\n\n        For nonparametric spaces, `args` should be the empty tuple.\n\n        This method is used by the demonstration interpreter.\n        \"\"\"\n        try:\n            f: Any = getattr(self, name.name)\n            for i in name.indices:\n                f = f[i]\n            if not args:\n                # TODO: we could check that the field is not supposed to be\n                # parametric\n                assert isinstance(f, Space)\n                return cast(Space[Any], f)\n            else:\n                assert isinstance(f, Callable)\n                f = cast(Callable[..., Space[Any]], f)\n                return f(*args)\n        except (TypeError, AttributeError):\n            return None\n\n    @final\n    @classmethod\n    def spawn(cls, spawner: \"AbstractBuilderExecutor\", **args: Any):\n        \"\"\"\n        Spawn an instance of the node type, using a dictionary of\n        arguments to populate its fields.\n\n        Arguments are processed according to their kind (see\n        [delphyne.core.node_fields][]). For example opaque space\n        builders (`Opaque`) are turned into opaque spaces\n        (`OpaqueSpace`) and strategy computations (`StrategyComp`) are\n        turned into embedded trees (`EmbeddedTree`).\n        \"\"\"\n\n        def convert(\n            name: refs.SpaceName, field: nf.FieldKind, obj: Any\n        ) -&gt; Any:\n            match field:\n                case nf.SpaceF():\n                    return spawner.nonparametric(name, obj)\n                case nf.ParametricF(nf.SpaceF()):\n                    return spawner.parametric(name, obj)\n                case nf.EmbeddedF():\n                    builder = EmbeddedTree.builder(obj)\n                    return spawner.nonparametric(name, builder)\n                case nf.ParametricF(nf.EmbeddedF()):\n                    parametric_builder = EmbeddedTree.parametric_builder(obj)\n                    return spawner.parametric(name, parametric_builder)\n                case nf.DataF():\n                    return obj\n                case nf.SequenceF(f):\n                    return [convert(name[i], f, x) for i, x in enumerate(obj)]\n                case nf.OptionalF(f):\n                    assert convert(name, f, obj) if obj is not None else None\n                case _:\n                    assert False\n\n        args_new = {\n            fname: convert(refs.SpaceName(fname, ()), fkind, args[fname])\n            for fname, fkind in cls.fields().items()\n        }\n        return cls(**args_new)\n\n    @final\n    def map_embedded[N: Node](\n        self: N, trans: \"AbstractTreeTransformer[Any, Any]\"\n    ) -&gt; N:\n        \"\"\"\n        Apply a function to all embedded trees.\n\n        This is a pure method that returns an updated node. It is useful\n        for implementing `Tree.transform`, which in turn is useful for\n        implementing standard tree transformers such as `elim_join` and\n        `elim_compute`.\n        \"\"\"\n\n        def convert_embedded(\n            emb: EmbeddedTree[Any, Any, Any],\n        ) -&gt; EmbeddedTree[Any, Any, Any]:\n            assert isinstance(emb, EmbeddedTree), (\n                f\"Expected an EmbeddedTree, got {type(emb)}\"\n            )\n            nested = NestedTree(\n                strategy=emb.nested.strategy,\n                ref=emb.nested.ref,\n                spawn_tree=lambda: trans(emb.nested.spawn_tree()),\n            )\n            return EmbeddedTree(nested, _tags=emb.tags())\n\n        def convert_parametric_embedded(obj: Any) -&gt; Callable[[Any], Any]:\n            return lambda arg: convert_embedded(obj(arg))\n\n        def convert(field: nf.FieldKind, obj: Any) -&gt; Any:\n            match field:\n                case nf.SpaceF() | nf.ParametricF(nf.SpaceF()) | nf.DataF():\n                    return obj\n                case nf.EmbeddedF():\n                    return convert_embedded(obj)\n                case nf.ParametricF(nf.EmbeddedF()):\n                    return convert_parametric_embedded(obj)\n                case nf.SequenceF(f):\n                    return [convert(f, x) for x in obj]\n                case nf.OptionalF(f):\n                    return convert(f, obj) if obj is not None else None\n                case _:\n                    assert False\n\n        args_new = {\n            fname: convert(fkind, getattr(self, fname))\n            for fname, fkind in self.fields().items()\n        }\n        return type(self)(**args_new)\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.navigate","title":"navigate  <code>abstractmethod</code>","text":"<pre><code>navigate() -&gt; Navigation\n</code></pre> <p>The navigation method, to be defined for each node type.</p> <p>It should only be called when <code>self.leaf_node()</code> returns False.</p> <p>See <code>Navigation</code> for details.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@abstractmethod\ndef navigate(self) -&gt; \"Navigation\":\n    \"\"\"\n    The navigation method, to be defined for each node type.\n\n    It should only be called when `self.leaf_node()` returns False.\n\n    See `Navigation` for details.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.summary_message","title":"summary_message","text":"<pre><code>summary_message() -&gt; str | None\n</code></pre> <p>Return an optional summary message for the node, to be displayed in the Delphyne extension's Tree View.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def summary_message(self) -&gt; str | None:\n    \"\"\"\n    Return an optional summary message for the node, to be\n    displayed in the Delphyne extension's Tree View.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.leaf_node","title":"leaf_node","text":"<pre><code>leaf_node() -&gt; bool\n</code></pre> <p>Return True if the node is a leaf node (e.g., <code>Fail</code>) and False otherwise.</p> <p>Leaf nodes do not have to define <code>navigate</code> and are treated specially by the demonstration interpreter.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def leaf_node(self) -&gt; bool:\n    \"\"\"\n    Return True if the node is a leaf node (e.g., `Fail`) and False\n    otherwise.\n\n    Leaf nodes do not have to define `navigate` and are treated\n    specially by the demonstration interpreter.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.valid_action","title":"valid_action","text":"<pre><code>valid_action(action: object) -&gt; bool\n</code></pre> <p>Return whether an action is valid.</p> <p>This method is used to dynamically check actions passed to <code>Tree.child</code>, after the <code>Tracked</code> wrapper is removed. By default, it always returns <code>True</code> (unless the node is a leaf node, in which case it returns <code>False</code>).</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def valid_action(self, action: object) -&gt; bool:\n    \"\"\"\n    Return whether an action is valid.\n\n    This method is used to dynamically check actions passed to\n    `Tree.child`, **after** the `Tracked` wrapper is removed. By\n    default, it always returns `True` (unless the node is a leaf\n    node, in which case it returns `False`).\n    \"\"\"\n    return False if self.leaf_node() else True\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.primary_space","title":"primary_space","text":"<pre><code>primary_space() -&gt; Space[object] | None\n</code></pre> <p>Optionally return the node's primary space.</p> <p>Primary spaces are useful to shorten space references, especially when writing demonstration tests. For example, if <code>cands</code> is the primary space of the current node, then <code>compare([cands{''}, cands{'foo bar'}])</code> can be abbreviated into <code>compare(['', 'foo bar'])</code>.</p> <p>By default, all tags of a node's primary space are also inherited by this node (see <code>get_tags</code> method).</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def primary_space(self) -&gt; \"Space[object] | None\":\n    \"\"\"\n    Optionally return the node's primary space.\n\n    Primary spaces are useful to shorten space references,\n    especially when writing demonstration tests. For example, if\n    `cands` is the primary space of the current node, then\n    `compare([cands{''}, cands{'foo bar'}])` can be abbreviated into\n    `compare(['', 'foo bar'])`.\n\n    By default, all tags of a node's primary space are also\n    inherited by this node (see `get_tags` method).\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.get_extra_tags","title":"get_extra_tags","text":"<pre><code>get_extra_tags() -&gt; Sequence[Tag]\n</code></pre> <p>Return the extra tags associated with the node, in addition to the default ones inherited from the primary space (see <code>get_tags</code> method).</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def get_extra_tags(self) -&gt; Sequence[Tag]:\n    \"\"\"\n    Return the extra tags associated with the node, in addition to\n    the default ones inherited from the primary space (see\n    `get_tags` method).\n    \"\"\"\n    return []\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.fields","title":"fields  <code>classmethod</code>","text":"<pre><code>fields() -&gt; NodeFields\n</code></pre> <p>Return a dictionary mapping each field of the node to some metadata (e.g., whether the field denotes a local space).</p> <p>Such metadata is useful in particular to implement <code>spawn</code>.</p> <p>The default implementation uses inspection, via <code>detect_node_structure</code>. See the <code>node_fields</code> module for details.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@classmethod\ndef fields(cls) -&gt; NodeFields:\n    \"\"\"\n    Return a dictionary mapping each field of the node to some\n    metadata (e.g., whether the field denotes a local space).\n\n    Such metadata is useful in particular to implement `spawn`.\n\n    The default implementation uses inspection, via\n    `detect_node_structure`. See the\n    [`node_fields`][delphyne.core.node_fields] module for details.\n    \"\"\"\n    f = detect_node_structure(\n        cls, embedded_class=EmbeddedTree, space_class=Space\n    )\n    if f is None:\n        msg = f\"Impossible to autodetect the structure of {cls}\"\n        assert False, msg\n    return f\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.effect_name","title":"effect_name","text":"<pre><code>effect_name() -&gt; str\n</code></pre> <p>Name of the associated effect.</p> <p>Used for generating message errors and in the VSCode extension.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def effect_name(self) -&gt; str:\n    \"\"\"\n    Name of the associated effect.\n\n    Used for generating message errors and in the VSCode extension.\n    \"\"\"\n    return self.__class__.__name__\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.get_tags","title":"get_tags","text":"<pre><code>get_tags() -&gt; Sequence[Tag]\n</code></pre> <p>Return all tags attached to the node.</p> <p>Tags are leveraged by the demonstration language to identify nodes (e.g., <code>at</code> test command).</p> <p>By default, this method returns all tags from the primary space (if any), along with any additional tag returned by <code>get_extra_tags</code>.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def get_tags(self) -&gt; Sequence[Tag]:\n    \"\"\"\n    Return all tags attached to the node.\n\n    Tags are leveraged by the demonstration language to identify\n    nodes (e.g., `at` test command).\n\n    By default, this method returns all tags from the primary space\n    (if any), along with any additional tag returned by\n    `get_extra_tags`.\n    \"\"\"\n    if (primary := self.primary_space()) is not None:\n        return [*primary.tags(), *self.get_extra_tags()]\n    return self.get_extra_tags()\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.primary_space_ref","title":"primary_space_ref","text":"<pre><code>primary_space_ref() -&gt; SpaceRef | None\n</code></pre> <p>Convenience method for returning a reference to the node's primary space, if it is defined.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@final\ndef primary_space_ref(self) -&gt; refs.SpaceRef | None:\n    \"\"\"\n    Convenience method for returning a reference to the node's\n    primary space, if it is defined.\n    \"\"\"\n    space = self.primary_space()\n    if space is None:\n        return None\n    return space.source().ref[1]\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.nested_space","title":"nested_space","text":"<pre><code>nested_space(name: SpaceName, args: tuple[Value, ...]) -&gt; Space[Any] | None\n</code></pre> <p>Dynamically retrieve a local space given its name and parameters.</p> <p>For nonparametric spaces, <code>args</code> should be the empty tuple.</p> <p>This method is used by the demonstration interpreter.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@final\ndef nested_space(\n    self, name: refs.SpaceName, args: tuple[Value, ...]\n) -&gt; Space[Any] | None:\n    \"\"\"\n    Dynamically retrieve a local space given its name and\n    parameters.\n\n    For nonparametric spaces, `args` should be the empty tuple.\n\n    This method is used by the demonstration interpreter.\n    \"\"\"\n    try:\n        f: Any = getattr(self, name.name)\n        for i in name.indices:\n            f = f[i]\n        if not args:\n            # TODO: we could check that the field is not supposed to be\n            # parametric\n            assert isinstance(f, Space)\n            return cast(Space[Any], f)\n        else:\n            assert isinstance(f, Callable)\n            f = cast(Callable[..., Space[Any]], f)\n            return f(*args)\n    except (TypeError, AttributeError):\n        return None\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.spawn","title":"spawn  <code>classmethod</code>","text":"<pre><code>spawn(spawner: AbstractBuilderExecutor, **args: Any)\n</code></pre> <p>Spawn an instance of the node type, using a dictionary of arguments to populate its fields.</p> <p>Arguments are processed according to their kind (see delphyne.core.node_fields). For example opaque space builders (<code>Opaque</code>) are turned into opaque spaces (<code>OpaqueSpace</code>) and strategy computations (<code>StrategyComp</code>) are turned into embedded trees (<code>EmbeddedTree</code>).</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@final\n@classmethod\ndef spawn(cls, spawner: \"AbstractBuilderExecutor\", **args: Any):\n    \"\"\"\n    Spawn an instance of the node type, using a dictionary of\n    arguments to populate its fields.\n\n    Arguments are processed according to their kind (see\n    [delphyne.core.node_fields][]). For example opaque space\n    builders (`Opaque`) are turned into opaque spaces\n    (`OpaqueSpace`) and strategy computations (`StrategyComp`) are\n    turned into embedded trees (`EmbeddedTree`).\n    \"\"\"\n\n    def convert(\n        name: refs.SpaceName, field: nf.FieldKind, obj: Any\n    ) -&gt; Any:\n        match field:\n            case nf.SpaceF():\n                return spawner.nonparametric(name, obj)\n            case nf.ParametricF(nf.SpaceF()):\n                return spawner.parametric(name, obj)\n            case nf.EmbeddedF():\n                builder = EmbeddedTree.builder(obj)\n                return spawner.nonparametric(name, builder)\n            case nf.ParametricF(nf.EmbeddedF()):\n                parametric_builder = EmbeddedTree.parametric_builder(obj)\n                return spawner.parametric(name, parametric_builder)\n            case nf.DataF():\n                return obj\n            case nf.SequenceF(f):\n                return [convert(name[i], f, x) for i, x in enumerate(obj)]\n            case nf.OptionalF(f):\n                assert convert(name, f, obj) if obj is not None else None\n            case _:\n                assert False\n\n    args_new = {\n        fname: convert(refs.SpaceName(fname, ()), fkind, args[fname])\n        for fname, fkind in cls.fields().items()\n    }\n    return cls(**args_new)\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Node.map_embedded","title":"map_embedded","text":"<pre><code>map_embedded(trans: AbstractTreeTransformer[Any, Any]) -&gt; N\n</code></pre> <p>Apply a function to all embedded trees.</p> <p>This is a pure method that returns an updated node. It is useful for implementing <code>Tree.transform</code>, which in turn is useful for implementing standard tree transformers such as <code>elim_join</code> and <code>elim_compute</code>.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@final\ndef map_embedded[N: Node](\n    self: N, trans: \"AbstractTreeTransformer[Any, Any]\"\n) -&gt; N:\n    \"\"\"\n    Apply a function to all embedded trees.\n\n    This is a pure method that returns an updated node. It is useful\n    for implementing `Tree.transform`, which in turn is useful for\n    implementing standard tree transformers such as `elim_join` and\n    `elim_compute`.\n    \"\"\"\n\n    def convert_embedded(\n        emb: EmbeddedTree[Any, Any, Any],\n    ) -&gt; EmbeddedTree[Any, Any, Any]:\n        assert isinstance(emb, EmbeddedTree), (\n            f\"Expected an EmbeddedTree, got {type(emb)}\"\n        )\n        nested = NestedTree(\n            strategy=emb.nested.strategy,\n            ref=emb.nested.ref,\n            spawn_tree=lambda: trans(emb.nested.spawn_tree()),\n        )\n        return EmbeddedTree(nested, _tags=emb.tags())\n\n    def convert_parametric_embedded(obj: Any) -&gt; Callable[[Any], Any]:\n        return lambda arg: convert_embedded(obj(arg))\n\n    def convert(field: nf.FieldKind, obj: Any) -&gt; Any:\n        match field:\n            case nf.SpaceF() | nf.ParametricF(nf.SpaceF()) | nf.DataF():\n                return obj\n            case nf.EmbeddedF():\n                return convert_embedded(obj)\n            case nf.ParametricF(nf.EmbeddedF()):\n                return convert_parametric_embedded(obj)\n            case nf.SequenceF(f):\n                return [convert(f, x) for x in obj]\n            case nf.OptionalF(f):\n                return convert(f, obj) if obj is not None else None\n            case _:\n                assert False\n\n    args_new = {\n        fname: convert(fkind, getattr(self, fname))\n        for fname, fkind in self.fields().items()\n    }\n    return type(self)(**args_new)\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Navigation","title":"Navigation","text":"<pre><code>Navigation = Generator[Space[Any], Tracked[Any], Value]\n</code></pre> <p>A navigation generator.</p> <p>A navigation generator is returned by the <code>navigate</code> method of non-leaf nodes. It yields local spaces and receives corresponding elements until an action is generated and returned.</p>"},{"location":"reference/strategies/trees/#delphyne.NavigationError","title":"NavigationError  <code>dataclass</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when an error occurs during navigation.</p> <p>For internal errors that should not occur within normal use, assertions shoule be used instead. This exception is meant to represent errors that can occur during normal use, and reported in the user interface. For an example, see <code>Abduction</code>.</p> <p>Attributes:</p> Name Type Description <code>message</code> <code>str</code> <p>A human-readable error message.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass(frozen=True)\nclass NavigationError(Exception):\n    \"\"\"\n    Exception raised when an error occurs during navigation.\n\n    For internal errors that should not occur within normal use,\n    assertions shoule be used instead. This exception is meant to\n    represent errors that can occur during normal use, and reported in\n    the user interface. For an example, see `Abduction`.\n\n    Attributes:\n        message: A human-readable error message.\n    \"\"\"\n\n    message: str\n</code></pre>"},{"location":"reference/strategies/trees/#node-fields","title":"Node Fields","text":""},{"location":"reference/strategies/trees/#delphyne.core.node_fields","title":"delphyne.core.node_fields","text":"<p>Classifying and inferring different kinds of node fields.</p> <p>When spawning a node via <code>Tree.spawn</code>, different field arguments must be processed differently. For example, an opaque space builder (<code>Opaque</code>) must be turned into an opaque space (<code>OpaqueSpace</code>) by providing an appropriate space reference. Other fields such as data fields must not be processed.</p> <p>This module defines a type for classifying node fields (<code>FieldType</code>) along with a utility function to automatically classify the fields of a custom node via inspection (<code>detect_node_structure</code>).</p>"},{"location":"reference/strategies/trees/#delphyne.core.node_fields.NodeFields","title":"NodeFields","text":"<pre><code>NodeFields = dict[str, FieldKind]\n</code></pre> <p>A dictionary mapping each field name to its kind.</p>"},{"location":"reference/strategies/trees/#delphyne.core.node_fields.FieldKind","title":"FieldKind","text":"<pre><code>FieldKind = LeafFieldKind | SequenceF | OptionalF\n</code></pre> <p>Kind of a node field.</p> <p>A node field can be an embedded tree, another local space, a parametric embedded tree or space, a sequence of such elements or an optional element.</p>"},{"location":"reference/strategies/trees/#delphyne.core.node_fields.FieldKind","title":"FieldKind","text":"<pre><code>FieldKind = LeafFieldKind | SequenceF | OptionalF\n</code></pre> <p>Kind of a node field.</p> <p>A node field can be an embedded tree, another local space, a parametric embedded tree or space, a sequence of such elements or an optional element.</p>"},{"location":"reference/strategies/trees/#delphyne.core.node_fields.LeafFieldKind","title":"LeafFieldKind","text":"<pre><code>LeafFieldKind = SpaceF | EmbeddedF | DataF | ParametricF\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.core.node_fields.SpaceF","title":"SpaceF  <code>dataclass</code>","text":"<p>A space field that does not correspond to an embedded nested tree.</p> Source code in <code>src/delphyne/core/node_fields.py</code> <pre><code>@dataclass\nclass SpaceF:\n    \"\"\"\n    A space field that does not correspond to an embedded nested tree.\n    \"\"\"\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.core.node_fields.EmbeddedF","title":"EmbeddedF  <code>dataclass</code>","text":"<p>A field corresponding to a nested embedded space.</p> <p>Recognizing this particular case is useful so that triggering functions can directly accept strategy computations as arguments (<code>StrategyComp</code>) instead of space builders (<code>SpaceBuilder</code>).</p> Source code in <code>src/delphyne/core/node_fields.py</code> <pre><code>@dataclass\nclass EmbeddedF:\n    \"\"\"\n    A field corresponding to a nested embedded space.\n\n    Recognizing this particular case is useful so that triggering\n    functions can directly accept strategy computations as arguments\n    (`StrategyComp`) instead of space builders (`SpaceBuilder`).\n    \"\"\"\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.core.node_fields.ParametricF","title":"ParametricF  <code>dataclass</code>","text":"<p>A field corresponding to a parametric space.</p> <p>Attributes:</p> Name Type Description <code>res</code> <code>SpaceF | EmbeddedF</code> <p>kind of the result space.</p> Source code in <code>src/delphyne/core/node_fields.py</code> <pre><code>@dataclass\nclass ParametricF:\n    \"\"\"\n    A field corresponding to a parametric space.\n\n    Attributes:\n        res: kind of the result space.\n    \"\"\"\n\n    res: SpaceF | EmbeddedF\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.core.node_fields.DataF","title":"DataF  <code>dataclass</code>","text":"<p>A field that corresponds to some other kind of data.</p> Source code in <code>src/delphyne/core/node_fields.py</code> <pre><code>@dataclass\nclass DataF:\n    \"\"\"\n    A field that corresponds to some other kind of data.\n    \"\"\"\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.core.node_fields.SequenceF","title":"SequenceF  <code>dataclass</code>","text":"<p>A field corresponding to a sequence of spaces.</p> Source code in <code>src/delphyne/core/node_fields.py</code> <pre><code>@dataclass\nclass SequenceF:\n    \"\"\"\n    A field corresponding to a sequence of spaces.\n    \"\"\"\n\n    element: \"FieldKind\"\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.core.node_fields.OptionalF","title":"OptionalF  <code>dataclass</code>","text":"<p>A field corresponding to a sequence of spaces.</p> Source code in <code>src/delphyne/core/node_fields.py</code> <pre><code>@dataclass\nclass OptionalF:\n    \"\"\"\n    A field corresponding to a sequence of spaces.\n    \"\"\"\n\n    element: \"FieldKind\"\n</code></pre>"},{"location":"reference/strategies/trees/#spaces","title":"Spaces","text":""},{"location":"reference/strategies/trees/#delphyne.Space","title":"Space","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract type for a space.</p> <p>Tree nodes feature local spaces (possibly parametric), that are backed by either queries or nested trees. Examples of spaces include <code>EmbeddedTree</code>, <code>OpaqueSpace</code> and <code>TransparentQuery</code>.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>class Space[T](ABC):\n    \"\"\"\n    Abstract type for a space.\n\n    Tree nodes feature local spaces (possibly parametric), that are\n    backed by either queries or nested trees. Examples of spaces\n    include `EmbeddedTree`, `OpaqueSpace` and `TransparentQuery`.\n    \"\"\"\n\n    @abstractmethod\n    def tags(self) -&gt; Sequence[Tag]:\n        \"\"\"\n        Return the tags associated with the space.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def source(self) -&gt; \"NestedTree[Any, Any, T] | AttachedQuery[T]\":\n        \"\"\"\n        Return the source of the space, which is either a nested tree\n        or an attached query.\n\n        This method is mostly useful to the demonstration interpreter.\n        It is not typically used in policies since it breaks\n        abstraction (e.g., whether or not an opaque space is defined via\n        a query or a strategy is irrelevant).\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Space.tags","title":"tags  <code>abstractmethod</code>","text":"<pre><code>tags() -&gt; Sequence[Tag]\n</code></pre> <p>Return the tags associated with the space.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@abstractmethod\ndef tags(self) -&gt; Sequence[Tag]:\n    \"\"\"\n    Return the tags associated with the space.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Space.source","title":"source  <code>abstractmethod</code>","text":"<pre><code>source() -&gt; NestedTree[Any, Any, T] | AttachedQuery[T]\n</code></pre> <p>Return the source of the space, which is either a nested tree or an attached query.</p> <p>This method is mostly useful to the demonstration interpreter. It is not typically used in policies since it breaks abstraction (e.g., whether or not an opaque space is defined via a query or a strategy is irrelevant).</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@abstractmethod\ndef source(self) -&gt; \"NestedTree[Any, Any, T] | AttachedQuery[T]\":\n    \"\"\"\n    Return the source of the space, which is either a nested tree\n    or an attached query.\n\n    This method is mostly useful to the demonstration interpreter.\n    It is not typically used in policies since it breaks\n    abstraction (e.g., whether or not an opaque space is defined via\n    a query or a strategy is irrelevant).\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.Tag","title":"Tag","text":"<pre><code>Tag = str\n</code></pre> <p>String tags for nodes and spaces.</p> <p>Nodes and spaces can be assigned string identifiers, which may be referenced in demonstration tests or when defining inner policies (e.g., <code>IPDict</code>). Tags should contain only alphanumeric characters, underscores, dots, and dashes.</p>"},{"location":"reference/strategies/trees/#delphyne.AttachedQuery","title":"AttachedQuery  <code>dataclass</code>","text":"<p>Wrapper for a query attached to a specific space.</p> <p>Attributes:</p> Name Type Description <code>query</code> <code>AbstractQuery[T]</code> <p>The wrapped query.</p> <code>ref</code> <code>GlobalSpacePath</code> <p>A global reference to the space to which the query is attached.</p> <code>parse_answer</code> <code>Callable[[Answer], Tracked[T] | ParseError]</code> <p>A wrapper around <code>self.query.parse_answer</code>, which attaches proper tracking information to answers.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass(frozen=True)\nclass AttachedQuery[T]:\n    \"\"\"\n    Wrapper for a query attached to a specific space.\n\n    Attributes:\n        query: The wrapped query.\n        ref: A global reference to the space to which the query is\n            attached.\n        parse_answer: A wrapper around `self.query.parse_answer`,\n            which attaches proper tracking information to answers.\n    \"\"\"\n\n    query: AbstractQuery[T]\n    ref: refs.GlobalSpacePath\n    parse_answer: Callable[[refs.Answer], Tracked[T] | ParseError]\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.NestedTree","title":"NestedTree  <code>dataclass</code>","text":"<p>Wrapper for a tree attached to a particular node.</p> <p>The <code>AttachedQuery</code> type plays an equivalent role for queries.</p> <p>Note</p> <p>One cannot count on the <code>strategy</code> field having the same node type as <code>spawn_tree</code> since nested trees can be applied tree transformers (see <code>Node.map_embedded</code>).</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass(frozen=True)\nclass NestedTree[N: Node, P, T]:\n    \"\"\"\n    Wrapper for a tree attached to a particular node.\n\n    The `AttachedQuery` type plays an equivalent role for queries.\n\n    !!! note\n        One cannot count on the `strategy` field having the same node\n        type as `spawn_tree` since nested trees can be applied tree\n        transformers (see `Node.map_embedded`).\n    \"\"\"\n\n    strategy: StrategyComp[Node, P, T]\n    ref: refs.GlobalSpacePath\n    spawn_tree: \"Callable[[], Tree[N, P, T]]\"\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.TransparentQuery","title":"TransparentQuery  <code>dataclass</code>","text":"<p>               Bases: <code>Space[T]</code></p> <p>A space that is defined by a single, transparent query.</p> <p>As opposed to <code>OpaqueSpace</code>, the query is meant to be directly exposed to policies. This is used to define <code>Compute</code> and <code>Flag</code> nodes for example.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass(frozen=True)\nclass TransparentQuery[T](Space[T]):\n    \"\"\"\n    A space that is defined by a single, *transparent* query.\n\n    As opposed to `OpaqueSpace`, the query is meant to be directly\n    exposed to policies. This is used to define `Compute` and `Flag`\n    nodes for example.\n    \"\"\"\n\n    attached: AttachedQuery[T]\n    _tags: \"Sequence[Tag]\"\n\n    @override\n    def source(self) -&gt; AttachedQuery[T]:\n        return self.attached\n\n    @override\n    def tags(self) -&gt; Sequence[Tag]:\n        return self._tags\n\n    @staticmethod\n    def build[T1](\n        query: AbstractQuery[T1],\n    ) -&gt; \"SpaceBuilder[TransparentQuery[T1]]\":\n        return SpaceBuilder(\n            build=lambda _, spawner, tags: TransparentQuery(\n                spawner(query), tags\n            ),\n            tags=query.default_tags(),\n        )\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.EmbeddedTree","title":"EmbeddedTree  <code>dataclass</code>","text":"<p>               Bases: <code>Space[T]</code></p> <p>Space defined by a nested tree with the same signature and inner policy as its surrounding tree.</p> <p>This is useful to define effects such as <code>Join</code>.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass(frozen=True)\nclass EmbeddedTree[N: Node, P, T](Space[T]):\n    \"\"\"\n    Space defined by a nested tree with the same signature and inner\n    policy as its surrounding tree.\n\n    This is useful to define effects such as `Join`.\n    \"\"\"\n\n    nested: NestedTree[N, P, T]\n    _tags: Sequence[Tag]\n\n    @staticmethod\n    def builder[N1: Node, P1, T1](\n        strategy: StrategyComp[N1, P1, T1],\n    ) -&gt; \"SpaceBuilder[EmbeddedTree[N1, P1, T1]]\":\n        return SpaceBuilder[EmbeddedTree[N1, P1, T1]](\n            build=lambda spawn, _, tags: EmbeddedTree(spawn(strategy), tags),\n            tags=strategy.default_tags(),\n        )\n\n    @staticmethod\n    def parametric_builder[A, N1: Node, P1, T1](\n        parametric_strategy: Callable[[A], StrategyComp[N1, P1, T1]],\n    ) -&gt; \"Callable[[A], SpaceBuilder[EmbeddedTree[N1, P1, T1]]]\":\n        return lambda arg: EmbeddedTree.builder(parametric_strategy(arg))\n\n    def source(self) -&gt; \"NestedTree[Any, Any, T]\":\n        return self.nested\n\n    def tags(self) -&gt; Sequence[Tag]:\n        return self._tags\n\n    def spawn_tree(self) -&gt; \"Tree[N, P, T]\":\n        return self.nested.spawn_tree()\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.SpaceBuilder","title":"SpaceBuilder  <code>dataclass</code>","text":"<p>Wrapper for a function that builds a space, given the ability to spawn nested trees and attached queries.</p> <p>Effect triggering functions such as <code>branch</code> do not directly take spaces as their arguments but space builders instead.</p> <p>Space builders are also equipped with modifiable tags, to be ultimately passed to the resulting space.</p> <p>Attributes:</p> Name Type Description <code>build</code> <code>Callable[[NestedTreeSpawner, QuerySpawner, Sequence[Tag]], S]</code> <p>Wrapped builder function</p> <code>tags</code> <code>Sequence[Tag]</code> <p>Tags to be assocaited to the space.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>@dataclass(frozen=True)\nclass SpaceBuilder[S]:\n    \"\"\"\n    Wrapper for a function that builds a space, given the ability to\n    spawn nested trees and attached queries.\n\n    Effect triggering functions such as `branch` do not directly take\n    spaces as their arguments but space builders instead.\n\n    Space builders are also equipped with modifiable tags, to be\n    ultimately passed to the resulting space.\n\n    Attributes:\n        build: Wrapped builder function\n        tags: Tags to be assocaited to the space.\n    \"\"\"\n\n    build: Callable[[NestedTreeSpawner, QuerySpawner, Sequence[Tag]], S]\n    tags: Sequence[Tag]\n\n    def tagged(self, *tags: Tag) -&gt; \"SpaceBuilder[S]\":\n        \"\"\"\n        Add new tags to the space builder.\n        \"\"\"\n        return replace(self, tags=(*self.tags, *tags))\n\n    def __call__(\n        self, spawner: NestedTreeSpawner, query_spawner: QuerySpawner\n    ) -&gt; S:\n        \"\"\"\n        Build a space, given the provided capabilities along with the\n        current set of tags.\n        \"\"\"\n        return self.build(spawner, query_spawner, self.tags)\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.SpaceBuilder.tagged","title":"tagged","text":"<pre><code>tagged(*tags: Tag) -&gt; SpaceBuilder[S]\n</code></pre> <p>Add new tags to the space builder.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def tagged(self, *tags: Tag) -&gt; \"SpaceBuilder[S]\":\n    \"\"\"\n    Add new tags to the space builder.\n    \"\"\"\n    return replace(self, tags=(*self.tags, *tags))\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.SpaceBuilder.__call__","title":"__call__","text":"<pre><code>__call__(spawner: NestedTreeSpawner, query_spawner: QuerySpawner) -&gt; S\n</code></pre> <p>Build a space, given the provided capabilities along with the current set of tags.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>def __call__(\n    self, spawner: NestedTreeSpawner, query_spawner: QuerySpawner\n) -&gt; S:\n    \"\"\"\n    Build a space, given the provided capabilities along with the\n    current set of tags.\n    \"\"\"\n    return self.build(spawner, query_spawner, self.tags)\n</code></pre>"},{"location":"reference/strategies/trees/#miscellaneous","title":"Miscellaneous","text":""},{"location":"reference/strategies/trees/#delphyne.ComputationNode","title":"ComputationNode","text":"<p>               Bases: <code>Node</code></p> <p>Abstract type for computation nodes.</p> <p>A computation node has an additional method that can be called to compute an answer. The demonstration interpreter uses this information to navigate computation nodes while accumulating implicit answers.</p> <p>The standard <code>Compute</code> node inherits this class.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>class ComputationNode(Node):\n    \"\"\"\n    Abstract type for computation nodes.\n\n    A computation node has an additional method that can be called to\n    compute an _answer_. The demonstration interpreter uses this\n    information to navigate computation nodes while accumulating\n    implicit answers.\n\n    The standard `Compute` node inherits this class.\n    \"\"\"\n\n    @abstractmethod\n    def run_computation(self) -&gt; str:\n        pass\n</code></pre>"},{"location":"reference/strategies/trees/#delphyne.AbstractTreeTransformer","title":"AbstractTreeTransformer","text":"<p>               Bases: <code>Protocol</code></p> <p>A function that transforms any tree with signature N into a tree with signature M, preserving its inner policy type and return type.</p> Source code in <code>src/delphyne/core/trees.py</code> <pre><code>class AbstractTreeTransformer[N: Node, M: Node](Protocol):\n    \"\"\"\n    A function that transforms any tree with signature N into a tree\n    with signature M, preserving its inner policy type and return type.\n    \"\"\"\n\n    def __call__[T, P](self, tree: \"Tree[N, P, T]\") -&gt; \"Tree[M, P, T]\": ...\n</code></pre>"}]}